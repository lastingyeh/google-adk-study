#!/usr/bin/env python3
# ç‰ˆæ¬Šæ‰€æœ‰ 2025 Google LLC
#
# æ ¹æ“š Apache License 2.0 ç‰ˆæœ¬ï¼ˆã€Œæœ¬æˆæ¬Šã€ï¼‰æˆæ¬Šï¼›
# é™¤ééµå®ˆæœ¬æˆæ¬Šï¼Œå¦å‰‡æ‚¨ä¸å¾—ä½¿ç”¨æ­¤æª”æ¡ˆã€‚
# æ‚¨å¯ä»¥åœ¨ä»¥ä¸‹ç¶²å€å–å¾—æˆæ¬Šå‰¯æœ¬ï¼š
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# é™¤éé©ç”¨æ³•å¾‹è¦æ±‚æˆ–æ›¸é¢åŒæ„ï¼Œå¦å‰‡æ ¹æ“šæœ¬æˆæ¬Šåˆ†ç™¼çš„è»Ÿé«”
# æ˜¯æŒ‰ã€Œç¾ç‹€ã€åŸºç¤åˆ†ç™¼çš„ï¼Œä¸é™„å¸¶ä»»ä½•æ˜ç¤ºæˆ–æš—ç¤ºçš„ä¿è­‰æˆ–æ¢ä»¶ã€‚
# è«‹åƒé–±æœ¬æˆæ¬Šä»¥ç­è§£ç®¡ç†æ¬Šé™å’Œé™åˆ¶çš„å…·é«”èªè¨€ã€‚

"""
ADK å¿«å–åˆ†æå¯¦é©— (Cache Performance Experiments)

æ­¤è…³æœ¬åŸ·è¡Œå…©å€‹å¯¦é©—ä¾†æ¯”è¼ƒå¿«å–æ•ˆèƒ½ï¼š
A. Gemini 2.0 Flashï¼šå•Ÿç”¨èˆ‡åœç”¨å¿«å–ï¼ˆé¡¯å¼å¿«å–æ¸¬è©¦ï¼‰
B. Gemini 2.5 Flashï¼šéš±å¼èˆ‡é¡¯å¼å¿«å–çš„æ¯”è¼ƒ
"""

import argparse
import asyncio
import copy
import json
import logging
import sys
import time
from typing import Any
from typing import Dict
from typing import List

try:
    # å„ªå…ˆå˜—è©¦ç›¸å°å°å…¥ï¼ˆä½œç‚ºæ¨¡çµ„åŸ·è¡Œæ™‚ï¼‰
    from .agent import app
    from .utils import get_test_prompts
    from .utils import run_experiment_batch
except ImportError:
    # å›é€€åˆ°ç›´æ¥å°å…¥ï¼ˆä½œç‚ºè…³æœ¬åŸ·è¡Œæ™‚ï¼‰
    from agent import app
    from utils import get_test_prompts
    from utils import run_experiment_batch

from google.adk.cli.utils import logs
from google.adk.runners import InMemoryRunner
from google.adk.utils.cache_performance_analyzer import CachePerformanceAnalyzer

APP_NAME = "cache_analysis_experiments"
USER_ID = "cache_researcher"

# --- æ ¸å¿ƒé‡é»æ‘˜è¦ ---
# - **æ ¸å¿ƒæ¦‚å¿µ**ï¼šé€éè‡ªå‹•åŒ–è…³æœ¬æ¯”è¼ƒä¸åŒæ¨¡å‹ï¼ˆGemini 2.0 vs 2.5ï¼‰èˆ‡å¿«å–æ©Ÿåˆ¶ï¼ˆé¡¯å¼ vs éš±å¼ï¼‰å°æ•ˆèƒ½èˆ‡ Token ä½¿ç”¨é‡çš„å½±éŸ¿ã€‚
# - **é—œéµæŠ€è¡“**ï¼š
#   - ä½¿ç”¨ Google ADK çš„ `ContextCacheConfig` é€²è¡Œé¡¯å¼å¿«å–é…ç½®ã€‚
#   - é€é `CachePerformanceAnalyzer` æ·±å…¥åˆ†æå¿«å–å‘½ä¸­ç‡ï¼ˆCache Hit Ratioï¼‰èˆ‡åˆ©ç”¨ç‡ï¼ˆUtilizationï¼‰ã€‚
#   - æ”¯æ´å¤šè¼ªå¯¦é©—å–å¹³å‡å€¼ï¼ˆAveraged Resultsï¼‰ï¼Œæé«˜æ•¸æ“šå¯é æ€§ã€‚
# - **é‡è¦çµè«–**ï¼šé¡¯å¼å¿«å–å¯æœ‰æ•ˆæ¸›å°‘é‡è¤‡ Prompt çš„ Token æ¶ˆè€—ï¼Œå„ªåŒ–å¤§å‹æ‡‰ç”¨çš„å»¶é²èˆ‡æˆæœ¬ã€‚
# - **è¡Œå‹•é …ç›®**ï¼šå¯èª¿æ•´ `min_tokens` èˆ‡ `ttl_seconds` åƒæ•¸ï¼Œé‡å°ç‰¹å®šæ¥­å‹™å ´æ™¯å„ªåŒ–å¿«å–ç­–ç•¥ã€‚


def create_agent_variant(base_app, model_name: str, cache_enabled: bool):
    """å»ºç«‹å…·æœ‰æŒ‡å®šæ¨¡å‹å’Œå¿«å–è¨­å®šçš„æ‡‰ç”¨ç¨‹å¼è®Šé«”ã€‚"""
    import datetime

    from google.adk.agents.context_cache_config import ContextCacheConfig
    from google.adk.apps.app import App

    # è¤‡è£½åŸå§‹ Agent ä¸¦ä¿®æ”¹å…¶æ¨¡å‹
    agent_copy = copy.deepcopy(base_app.root_agent)
    agent_copy.model = model_name

    # åœ¨æŒ‡ä»¤å‰åŠ ä¸Šå‹•æ…‹æ™‚é–“æˆ³è¨˜ï¼Œé¿å…å„æ¬¡åŸ·è¡Œé–“æ„å¤–é‡ç”¨éš±å¼å¿«å–
    current_timestamp = datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    dynamic_prefix = f"Current session started at: {current_timestamp}\n\n"
    agent_copy.instruction = dynamic_prefix + agent_copy.instruction

    # æ›´æ–° Agent åç¨±ä»¥åæ˜ å…¶é…ç½®
    cache_status = "cached" if cache_enabled else "no_cache"
    agent_copy.name = f"cache_analysis_{model_name.replace('.', '_').replace('-', '_')}_{cache_status}"

    if cache_enabled:
        # ä½¿ç”¨æ¨™æº–åŒ–çš„é¡¯å¼å¿«å–é…ç½®
        cache_config = ContextCacheConfig(
            min_tokens=4096,
            ttl_seconds=600,  # ç ”ç©¶å·¥ä½œéšæ®µè¨­å®šç‚º 10 åˆ†é˜
            cache_intervals=3,  # å¿«å–é‡æ–°æ•´ç†å‰çš„æœ€å¤§å‘¼å«æ¬¡æ•¸
        )
    else:
        # å°‡é…ç½®è¨­ç‚º None ä»¥åœç”¨å¿«å–
        cache_config = None

    # å»ºç«‹å…·æœ‰æ›´æ–°é…ç½®çš„æ–° App
    app_copy = App(
        name=f"{base_app.name}_{cache_status}",
        root_agent=agent_copy,
        context_cache_config=cache_config,
    )

    return app_copy


async def run_cache_comparison_experiment(
    model_name: str,
    description: str,
    cached_label: str,
    uncached_label: str,
    experiment_title: str,
    reverse_order: bool = False,
    request_delay: float = 2.0,
) -> Dict[str, Any]:
    """
    é‡å°ç‰¹å®šæ¨¡å‹åŸ·è¡Œå¿«å–æ•ˆèƒ½æ¯”è¼ƒå¯¦é©—ã€‚

    å¼•æ•¸:
        model_name: è¦æ¸¬è©¦çš„æ¨¡å‹ (ä¾‹å¦‚ "gemini-2.0-flash", "gemini-2.5-flash")
        description: å¯¦é©—æ¸¬è©¦å…§å®¹èªªæ˜
        cached_label: å·²å¿«å–è®Šé«”çš„æ¨™ç±¤
        uncached_label: æœªå¿«å–è®Šé«”çš„æ¨™ç±¤
        experiment_title: é¡¯ç¤ºçš„å¯¦é©—æ¨™é¡Œ

    å‚³å›:
        åŒ…å«å¯¦é©—çµæœèˆ‡æ•ˆèƒ½æ¯”è¼ƒçš„å­—å…¸
    """
    print("=" * 80)
    print(f"å¯¦é©— {model_name}: {experiment_title}")
    print("=" * 80)
    print(f"æ¸¬è©¦èªªæ˜: {description}")
    print(f"æ¨¡å‹: {model_name}")
    print()

    # 1. å»ºç«‹ App è®Šé«”
    app_cached = create_agent_variant(app, model_name, cache_enabled=True)
    app_uncached = create_agent_variant(app, model_name, cache_enabled=False)

    # 2. å–å¾—æ¸¬è©¦æç¤º (Prompts)
    prompts = get_test_prompts()

    # 3. å»ºç«‹åŸ·è¡Œå™¨ (Runners)
    runner_cached = InMemoryRunner(app=app_cached, app_name=None)
    runner_uncached = InMemoryRunner(app=app_uncached, app_name=None)

    # 4. ç‚ºæ¯å€‹å¯¦é©—å»ºç«‹ç¨ç«‹å·¥ä½œéšæ®µ (Sessions) ä»¥é¿å…äº¤å‰æ±¡æŸ“
    session_cached = await runner_cached.session_service.create_session(
        app_name=runner_cached.app_name, user_id=USER_ID
    )
    session_uncached = await runner_uncached.session_service.create_session(
        app_name=runner_uncached.app_name, user_id=USER_ID
    )

    # 5. åŸ·è¡Œå¯¦é©—æ‰¹æ¬¡
    if not reverse_order:  # é è¨­ï¼šå…ˆåŸ·è¡Œæœªå¿«å–ç‰ˆæœ¬
        print("â–¶ï¸ æ­£åœ¨æŒ‰é è¨­é †åºåŸ·è¡Œå¯¦é©— (å…ˆåŸ·è¡Œæœªå¿«å–ç‰ˆæœ¬)")
        print()

        # æ¸¬è©¦æœªå¿«å–ç‰ˆæœ¬
        results_uncached = await run_experiment_batch(
            app_uncached.root_agent.name,
            runner_uncached,
            USER_ID,
            session_uncached.id,
            prompts,
            f"Experiment {model_name} - {uncached_label}",
            request_delay=request_delay,
        )

        # å¯¦é©—é–“ç°¡çŸ­æš«åœ
        await asyncio.sleep(5)

        # æ¸¬è©¦å·²å¿«å–ç‰ˆæœ¬
        results_cached = await run_experiment_batch(
            app_cached.root_agent.name,
            runner_cached,
            USER_ID,
            session_cached.id,
            prompts,
            f"Experiment {model_name} - {cached_label}",
            request_delay=request_delay,
        )
    else:
        print("ğŸ”„ æ­£åœ¨æŒ‰äº¤æ›¿é †åºåŸ·è¡Œå¯¦é©— (å…ˆåŸ·è¡Œå·²å¿«å–ç‰ˆæœ¬)")
        print()

        # æ¸¬è©¦å·²å¿«å–ç‰ˆæœ¬
        results_cached = await run_experiment_batch(
            app_cached.root_agent.name,
            runner_cached,
            USER_ID,
            session_cached.id,
            prompts,
            f"Experiment {model_name} - {cached_label}",
            request_delay=request_delay,
        )

        # å¯¦é©—é–“ç°¡çŸ­æš«åœ
        await asyncio.sleep(5)

        # æ¸¬è©¦æœªå¿«å–ç‰ˆæœ¬
        results_uncached = await run_experiment_batch(
            app_uncached.root_agent.name,
            runner_uncached,
            USER_ID,
            session_uncached.id,
            prompts,
            f"Experiment {model_name} - {uncached_label}",
            request_delay=request_delay,
        )

    # 6. ä½¿ç”¨ CachePerformanceAnalyzer åˆ†æå¿«å–æ•ˆèƒ½
    performance_analysis = await analyze_cache_performance_from_sessions(
        runner_cached,
        session_cached,
        runner_uncached,
        session_uncached,
        model_name,
    )

    # 7. å¾åˆ†æå™¨æå–æŒ‡æ¨™ä»¥ä¿æŒå‘å¾Œç›¸å®¹æ€§
    cached_analysis = performance_analysis.get("cached_analysis", {})
    uncached_analysis = performance_analysis.get("uncached_analysis", {})

    cached_total_prompt_tokens = cached_analysis.get("total_prompt_tokens", 0)
    cached_total_cached_tokens = cached_analysis.get("total_cached_tokens", 0)
    cached_cache_hit_ratio = cached_analysis.get("cache_hit_ratio_percent", 0.0)
    cached_cache_utilization_ratio = cached_analysis.get(
        "cache_utilization_ratio_percent", 0.0
    )
    cached_avg_cached_tokens_per_request = cached_analysis.get(
        "avg_cached_tokens_per_request", 0.0
    )
    cached_requests_with_hits = cached_analysis.get("requests_with_cache_hits", 0)
    total_cached_requests = cached_analysis.get("total_requests", 0)

    uncached_total_prompt_tokens = uncached_analysis.get("total_prompt_tokens", 0)
    uncached_total_cached_tokens = uncached_analysis.get("total_cached_tokens", 0)
    uncached_cache_hit_ratio = uncached_analysis.get("cache_hit_ratio_percent", 0.0)
    uncached_cache_utilization_ratio = uncached_analysis.get(
        "cache_utilization_ratio_percent", 0.0
    )
    uncached_avg_cached_tokens_per_request = uncached_analysis.get(
        "avg_cached_tokens_per_request", 0.0
    )
    uncached_requests_with_hits = uncached_analysis.get("requests_with_cache_hits", 0)
    total_uncached_requests = uncached_analysis.get("total_requests", 0)

    summary = {
        "experiment": model_name,
        "description": description,
        "model": model_name,
        "cached_results": results_cached,
        "uncached_results": results_uncached,
        "cache_analysis": {
            "cached_experiment": {
                "cache_hit_ratio_percent": cached_cache_hit_ratio,
                "cache_utilization_ratio_percent": cached_cache_utilization_ratio,
                "total_prompt_tokens": cached_total_prompt_tokens,
                "total_cached_tokens": cached_total_cached_tokens,
                "avg_cached_tokens_per_request": (cached_avg_cached_tokens_per_request),
                "requests_with_cache_hits": cached_requests_with_hits,
                "total_requests": total_cached_requests,
            },
            "uncached_experiment": {
                "cache_hit_ratio_percent": uncached_cache_hit_ratio,
                "cache_utilization_ratio_percent": (uncached_cache_utilization_ratio),
                "total_prompt_tokens": uncached_total_prompt_tokens,
                "total_cached_tokens": uncached_total_cached_tokens,
                "avg_cached_tokens_per_request": (
                    uncached_avg_cached_tokens_per_request
                ),
                "requests_with_cache_hits": uncached_requests_with_hits,
                "total_requests": total_uncached_requests,
            },
        },
    }

    print(f"ğŸ“Š å¯¦é©— {model_name} å¿«å–åˆ†æçµæœï¼š")
    print(f"   ğŸ”¥ {cached_label}:")
    print(
        f"      å¿«å–å‘½ä¸­ç‡ (Hit Ratio): {cached_cache_hit_ratio:.1f}%"
        f" ({cached_total_cached_tokens:,} /"
        f" {cached_total_prompt_tokens:,} tokens)"
    )
    print(
        f"      å¿«å–åˆ©ç”¨ç‡ (Utilization): {cached_cache_utilization_ratio:.1f}%"
        f" ({cached_requests_with_hits}/{total_cached_requests} requests)"
    )
    print(
        "      å¹³å‡æ¯æ¬¡è«‹æ±‚å¿«å– Token æ•¸:"
        f" {cached_avg_cached_tokens_per_request:.0f}"
    )
    print(f"   â„ï¸  {uncached_label}:")
    print(
        f"      å¿«å–å‘½ä¸­ç‡ (Hit Ratio): {uncached_cache_hit_ratio:.1f}%"
        f" ({uncached_total_cached_tokens:,} /"
        f" {uncached_total_prompt_tokens:,} tokens)"
    )
    print(
        f"      å¿«å–åˆ©ç”¨ç‡ (Utilization): {uncached_cache_utilization_ratio:.1f}%"
        f" ({uncached_requests_with_hits}/{total_uncached_requests} requests)"
    )
    print(
        "      å¹³å‡æ¯æ¬¡è«‹æ±‚å¿«å– Token æ•¸:"
        f" {uncached_avg_cached_tokens_per_request:.0f}"
    )
    print()

    # å°‡è©³ç´°æ•ˆèƒ½åˆ†æåŠ å…¥æ‘˜è¦
    summary["performance_analysis"] = performance_analysis

    return summary


async def analyze_cache_performance_from_sessions(
    runner_cached,
    session_cached,
    runner_uncached,
    session_uncached,
    model_name: str,
) -> Dict[str, Any]:
    """ä½¿ç”¨ CachePerformanceAnalyzer åˆ†æå¿«å–æ•ˆèƒ½ã€‚"""
    print("ğŸ“Š æ­£åœ¨é€é CachePerformanceAnalyzer é€²è¡Œå¿«å–åˆ†æ...")

    analyzer_cached = CachePerformanceAnalyzer(runner_cached.session_service)
    analyzer_uncached = CachePerformanceAnalyzer(runner_uncached.session_service)

    # A. åˆ†æå·²å¿«å–å¯¦é©—
    try:
        cached_analysis = await analyzer_cached.analyze_agent_cache_performance(
            session_cached.id,
            USER_ID,
            runner_cached.app_name,
            f"cache_analysis_{model_name.replace('.', '_').replace('-', '_')}_cached",
        )
        print(f"  ğŸ”¥ å·²å¿«å–å¯¦é©—åˆ†æ (Cached Experiment):")
        print(f"     ç‹€æ…‹: {cached_analysis['status']}")
        if cached_analysis["status"] == "active":
            print(
                "     å¿«å–å‘½ä¸­ç‡:"
                f" {cached_analysis['cache_hit_ratio_percent']:.1f}%"
                f" ({cached_analysis['total_cached_tokens']:,} /"
                f" {cached_analysis['total_prompt_tokens']:,} tokens)"
            )
            print(
                "     å¿«å–åˆ©ç”¨ç‡:"
                f" {cached_analysis['cache_utilization_ratio_percent']:.1f}%"
                f" ({cached_analysis['requests_with_cache_hits']}/{cached_analysis['total_requests']} requests)"
            )
            print(
                "     å¹³å‡æ¯æ¬¡è«‹æ±‚å¿«å– Token æ•¸:"
                f" {cached_analysis['avg_cached_tokens_per_request']:.0f}"
            )
            print(f"     å¸¶å¿«å–çš„è«‹æ±‚æ•¸: {cached_analysis['requests_with_cache']}")
            print(
                "     å¹³å‡å·²ç”¨å‘¼å«æ¬¡æ•¸ (Avg invocations used):"
                f" {cached_analysis['avg_invocations_used']:.1f}"
            )
            print(f"     å¿«å–é‡æ–°æ•´ç†æ¬¡æ•¸: {cached_analysis['cache_refreshes']}")
            print(f"     ç¸½å‘¼å«æ¬¡æ•¸: {cached_analysis['total_invocations']}")
    except Exception as e:
        print(f"     âŒ åˆ†æå·²å¿«å–å¯¦é©—æ™‚å‡ºéŒ¯: {e}")
        cached_analysis = {"status": "error", "error": str(e)}

    # B. åˆ†ææœªå¿«å–å¯¦é©—
    try:
        uncached_analysis = await analyzer_uncached.analyze_agent_cache_performance(
            session_uncached.id,
            USER_ID,
            runner_uncached.app_name,
            f"cache_analysis_{model_name.replace('.', '_').replace('-', '_')}_no_cache",
        )
        print(f"  â„ï¸  æœªå¿«å–å¯¦é©—åˆ†æ (Uncached Experiment):")
        print(f"     ç‹€æ…‹: {uncached_analysis['status']}")
        if uncached_analysis["status"] == "active":
            print(
                "     å¿«å–å‘½ä¸­ç‡:"
                f" {uncached_analysis['cache_hit_ratio_percent']:.1f}%"
                f" ({uncached_analysis['total_cached_tokens']:,} /"
                f" {uncached_analysis['total_prompt_tokens']:,} tokens)"
            )
            print(
                "     å¿«å–åˆ©ç”¨ç‡:"
                f" {uncached_analysis['cache_utilization_ratio_percent']:.1f}%"
                f" ({uncached_analysis['requests_with_cache_hits']}/{uncached_analysis['total_requests']} requests)"
            )
            print(
                "     å¹³å‡æ¯æ¬¡è«‹æ±‚å¿«å– Token æ•¸:"
                f" {uncached_analysis['avg_cached_tokens_per_request']:.0f}"
            )
            print("     å¸¶å¿«å–çš„è«‹æ±‚æ•¸:" f" {uncached_analysis['requests_with_cache']}")
            print(
                "     å¹³å‡å·²ç”¨å‘¼å«æ¬¡æ•¸:"
                f" {uncached_analysis['avg_invocations_used']:.1f}"
            )
            print(f"     å¿«å–é‡æ–°æ•´ç†æ¬¡æ•¸: {uncached_analysis['cache_refreshes']}")
            print(f"     ç¸½å‘¼å«æ¬¡æ•¸: {uncached_analysis['total_invocations']}")
    except Exception as e:
        print(f"     âŒ åˆ†ææœªå¿«å–å¯¦é©—æ™‚å‡ºéŒ¯: {e}")
        uncached_analysis = {"status": "error", "error": str(e)}

    print()

    return {
        "cached_analysis": cached_analysis,
        "uncached_analysis": uncached_analysis,
    }


def get_experiment_labels(model_name: str) -> Dict[str, str]:
    """å–å¾—æŒ‡å®šæ¨¡å‹çš„å¯¦é©—æ¨™ç±¤å’Œæ¨™é¡Œã€‚"""
    # æ ¹æ“šæ¨¡å‹åç¨±åˆ¤æ–·å¯¦é©—é¡å‹
    if "2.5" in model_name:
        # Gemini 2.5 æ¨¡å‹å…·æœ‰éš±å¼å¿«å– (Implicit Caching)
        return {
            "description": "Google éš±å¼å¿«å– vs ADK é¡¯å¼å¿«å–",
            "cached_label": "é¡¯å¼å¿«å– (Explicit)",
            "uncached_label": "éš±å¼å¿«å– (Implicit)",
            "experiment_title": "éš±å¼èˆ‡é¡¯å¼å¿«å–æ¯”è¼ƒ",
        }
    else:
        # å…¶ä»–æ¨¡å‹ (2.0 ç­‰) æ¸¬è©¦å•Ÿç”¨é¡¯å¼å¿«å– vs åœç”¨å¿«å–
        return {
            "description": "ADK é¡¯å¼å¿«å–å•Ÿç”¨ vs åœç”¨",
            "cached_label": "å·²å¿«å– (Cached)",
            "uncached_label": "æœªå¿«å– (Uncached)",
            "experiment_title": "å¿«å–æ•ˆèƒ½æ¯”è¼ƒ",
        }


def calculate_averaged_results(
    all_results: List[Dict[str, Any]], model_name: str
) -> Dict[str, Any]:
    """è¨ˆç®—å¤šæ¬¡å¯¦é©—åŸ·è¡Œçš„å¹³å‡çµæœã€‚"""
    if not all_results:
        raise ValueError("æ²’æœ‰å¯è¨ˆç®—å¹³å‡å€¼çš„çµæœ")

    # è¨ˆç®—å¹³å‡å¿«å–æŒ‡æ¨™
    cache_hit_ratios = [
        r["cache_analysis"]["cache_hit_ratio_percent"] for r in all_results
    ]
    cache_utilization_ratios = [
        r["cache_analysis"]["cache_utilization_ratio_percent"] for r in all_results
    ]
    total_prompt_tokens = [
        r["cache_analysis"]["total_prompt_tokens"] for r in all_results
    ]
    total_cached_tokens = [
        r["cache_analysis"]["total_cached_tokens"] for r in all_results
    ]
    avg_cached_tokens_per_request = [
        r["cache_analysis"]["avg_cached_tokens_per_request"] for r in all_results
    ]
    requests_with_cache_hits = [
        r["cache_analysis"]["requests_with_cache_hits"] for r in all_results
    ]

    def safe_average(values):
        """è¨ˆç®—å¹³å‡å€¼ï¼Œè™•ç†ç©ºåˆ—è¡¨æƒ…æ³ã€‚"""
        return sum(values) / len(values) if values else 0.0

    # å»ºç«‹å¹³å‡çµæœ
    averaged_result = {
        "experiment": model_name,
        "description": all_results[0]["description"],
        "model": model_name,
        "individual_runs": (all_results),  # ä¿ç•™æ‰€æœ‰å€‹åˆ¥åŸ·è¡Œçµæœä¾›åƒè€ƒ
        "averaged_cache_analysis": {
            "cache_hit_ratio_percent": safe_average(cache_hit_ratios),
            "cache_utilization_ratio_percent": safe_average(cache_utilization_ratios),
            "total_prompt_tokens": safe_average(total_prompt_tokens),
            "total_cached_tokens": safe_average(total_cached_tokens),
            "avg_cached_tokens_per_request": safe_average(
                avg_cached_tokens_per_request
            ),
            "requests_with_cache_hits": safe_average(requests_with_cache_hits),
        },
        "statistics": {
            "runs_completed": len(all_results),
            "cache_hit_ratio_std": _calculate_std(cache_hit_ratios),
            "cache_utilization_std": _calculate_std(cache_utilization_ratios),
            "cached_tokens_per_request_std": _calculate_std(
                avg_cached_tokens_per_request
            ),
        },
    }

    # åˆ—å°å¹³å‡çµæœ
    print("\nğŸ“Š å¿«å–åˆ†æå¹³å‡çµæœï¼š")
    print("=" * 80)
    avg_cache = averaged_result["averaged_cache_analysis"]
    stats = averaged_result["statistics"]

    print(f"   å®Œæˆè¼ªæ•¸: {stats['runs_completed']}")
    print(
        f"   å¹³å‡å¿«å–å‘½ä¸­ç‡: {avg_cache['cache_hit_ratio_percent']:.1f}%"
        f" (Â±{stats['cache_hit_ratio_std']:.1f}%)"
    )
    print(
        "   å¹³å‡å¿«å–åˆ©ç”¨ç‡:"
        f" {avg_cache['cache_utilization_ratio_percent']:.1f}%"
        f" (Â±{stats['cache_utilization_std']:.1f}%)"
    )
    print(
        "   å¹³å‡æ¯æ¬¡è«‹æ±‚å¿«å– Token æ•¸:"
        f" {avg_cache['avg_cached_tokens_per_request']:.0f}"
        f" (Â±{stats['cached_tokens_per_request_std']:.0f})"
    )
    print()

    return averaged_result


def _calculate_std(values):
    """è¨ˆç®—æ¨™æº–å·®ã€‚"""
    if len(values) <= 1:
        return 0.0
    mean = sum(values) / len(values)
    variance = sum((x - mean) ** 2 for x in values) / len(values)
    return variance**0.5


def save_results(results: Dict[str, Any], filename: str):
    """å°‡å¯¦é©—çµæœå„²å­˜åˆ° JSON æª”æ¡ˆã€‚"""
    with open(filename, "w") as f:
        json.dump(results, f, indent=2)
    print(f"ğŸ’¾ çµæœå·²å„²å­˜è‡³: {filename}")


async def main():
    """é‡å°ç‰¹å®šæ¨¡å‹åŸ·è¡Œå¿«å–æ•ˆèƒ½å¯¦é©—ã€‚"""
    parser = argparse.ArgumentParser(description="ADK å¿«å–æ•ˆèƒ½å¯¦é©—å·¥å…·")
    parser.add_argument(
        "model",
        help="è¦æ¸¬è©¦çš„æ¨¡å‹ (ä¾‹å¦‚ gemini-2.5-flash, gemini-2.0-flash-001)",
    )
    parser.add_argument(
        "--output",
        help="çµæœçš„è¼¸å‡ºæª”å (é è¨­: cache_{model}_results.json)",
    )
    parser.add_argument(
        "--repeat",
        type=int,
        default=1,
        help=("æ¯å€‹å¯¦é©—é‡è¤‡åŸ·è¡Œçš„æ¬¡æ•¸ä»¥å–å¾—å¹³å‡çµæœ" " (é è¨­: 1)"),
    )
    parser.add_argument(
        "--cached-first",
        action="store_true",
        help="å„ªå…ˆåŸ·è¡Œå·²å¿«å–å¯¦é©— (é è¨­ï¼šå…ˆåŸ·è¡Œæœªå¿«å–å¯¦é©—)",
    )
    parser.add_argument(
        "--request-delay",
        type=float,
        default=2.0,
        help=("API è«‹æ±‚é–“çš„å»¶é²ç§’æ•¸ï¼Œé¿å…è¶…è¼‰ (é è¨­:" " 2.0)"),
    )
    parser.add_argument(
        "--log-level",
        choices=["DEBUG", "INFO", "WARNING", "ERROR"],
        default="INFO",
        help="è¨­å®šæ—¥èªŒç­‰ç´š (é è¨­: INFO)",
    )

    args = parser.parse_args()

    # è¨­å®šæŒ‡å®šç­‰ç´šçš„æ—¥èªŒè¨˜éŒ„å™¨
    log_level = getattr(logging, args.log_level.upper())
    logs.setup_adk_logger(log_level)

    # æ ¹æ“šæ¨¡å‹è¨­å®šé è¨­è¼¸å‡ºæª”å
    if not args.output:
        args.output = (
            f"cache_{args.model.replace('.', '_').replace('-', '_')}_results.json"
        )

    print("ğŸ§ª ADK ä¸Šä¸‹æ–‡å¿«å– (CONTEXT CACHE) æ•ˆèƒ½å¯¦é©—")
    print("=" * 80)
    print(f"é–‹å§‹æ™‚é–“: {time.strftime('%Y-%m-%d %H:%M:%S')}")
    print(f"æ¸¬è©¦æ¨¡å‹: {args.model}")
    print(f"é‡è¤‡è¼ªæ•¸: {args.repeat}")
    print()

    start_time = time.time()

    try:
        # å–å¾—æ¨¡å‹çš„å¯¦é©—æ¨™ç±¤
        labels = get_experiment_labels(args.model)

        # è‹¥ repeat > 1ï¼Œå‰‡åŸ·è¡Œå¤šæ¬¡å¯¦é©—
        if args.repeat == 1:
            # å–®æ¬¡åŸ·è¡Œ
            result = await run_cache_comparison_experiment(
                model_name=args.model,
                reverse_order=args.cached_first,
                request_delay=args.request_delay,
                **labels,
            )
        else:
            # å¤šæ¬¡åŸ·è¡Œä¸¦è¨ˆç®—å¹³å‡å€¼
            print(f"ğŸ”„ æ­£åœ¨åŸ·è¡Œå¯¦é©— {args.repeat} æ¬¡ä»¥å–å¾—å¹³å‡çµæœ")
            print("=" * 80)

            all_results = []
            for run_num in range(args.repeat):
                print(f"\nğŸƒ åŸ·è¡Œè¼ªæ¬¡ {run_num + 1}/{args.repeat}")
                print("-" * 40)

                run_result = await run_cache_comparison_experiment(
                    model_name=args.model,
                    reverse_order=args.cached_first,
                    request_delay=args.request_delay,
                    **labels,
                )
                all_results.append(run_result)

                # è¼ªæ¬¡é–“ç°¡çŸ­æš«åœ
                if run_num < args.repeat - 1:
                    print("â¸ï¸  è¼ªæ¬¡é–“æš«åœ 10 ç§’...")
                    await asyncio.sleep(10)

            # è¨ˆç®—å¹³å‡çµæœ
            result = calculate_averaged_results(all_results, args.model)

        # åŠ å…¥å®Œæˆå…ƒæ•¸æ“š (Metadata)
        result["end_time"] = time.strftime("%Y-%m-%d %H:%M:%S")
        result["total_duration"] = time.time() - start_time
        result["repetitions"] = args.repeat

    except KeyboardInterrupt:
        print("\nâš ï¸ å¯¦é©—è¢«ä½¿ç”¨è€…ä¸­æ–·")
        sys.exit(1)
    except Exception as e:
        print(f"\nâŒ å¯¦é©—å¤±æ•—: {e}")
        import traceback

        traceback.print_exc()
        sys.exit(1)

    # å„²å­˜çµæœ
    save_results(result, args.output)

    # åˆ—å°æœ€çµ‚æ‘˜è¦
    print("=" * 80)
    print("ğŸ‰ å¯¦é©—é †åˆ©å®Œæˆï¼")
    print("=" * 80)

    # è™•ç†å–®æ¬¡å’Œå¹³å‡çµæœçš„é¡¯ç¤º
    if args.repeat == 1:
        cached_exp = result["cache_analysis"]["cached_experiment"]
        uncached_exp = result["cache_analysis"]["uncached_experiment"]
        labels = get_experiment_labels(args.model)
        print(f"{args.model}:")
        print(f"  ğŸ”¥ {labels['cached_label']}:")
        print(f"    å¿«å–å‘½ä¸­ç‡: {cached_exp['cache_hit_ratio_percent']:.1f}%")
        print(
            "    å¿«å–åˆ©ç”¨ç‡:" f" {cached_exp['cache_utilization_ratio_percent']:.1f}%"
        )
        print(
            "    æ¯æ¬¡è«‹æ±‚å¿«å– Token æ•¸:"
            f" {cached_exp['avg_cached_tokens_per_request']:.0f}"
        )
        print(f"  â„ï¸  {labels['uncached_label']}:")
        print(f"    å¿«å–å‘½ä¸­ç‡: {uncached_exp['cache_hit_ratio_percent']:.1f}%")
        print(
            "    å¿«å–åˆ©ç”¨ç‡:" f" {uncached_exp['cache_utilization_ratio_percent']:.1f}%"
        )
        print(
            "    æ¯æ¬¡è«‹æ±‚å¿«å– Token æ•¸:"
            f" {uncached_exp['avg_cached_tokens_per_request']:.0f}"
        )
    else:
        # é‡å°å¹³å‡çµæœé¡¯ç¤ºæ‘˜è¦æ¯”è¼ƒ
        cached_exp = result["averaged_cache_analysis"]["cached_experiment"]
        uncached_exp = result["averaged_cache_analysis"]["uncached_experiment"]
        labels = get_experiment_labels(args.model)
        print(f"{args.model} (ç¶“ {args.repeat} è¼ªå¹³å‡):")
        print(f"  ğŸ”¥ {labels['cached_label']} vs â„ï¸  {labels['uncached_label']}:")
        print(
            f"    å¿«å–å‘½ä¸­ç‡: {cached_exp['cache_hit_ratio_percent']:.1f}% vs"
            f" {uncached_exp['cache_hit_ratio_percent']:.1f}%"
        )
        print(
            "    å¿«å–åˆ©ç”¨ç‡:"
            f" {cached_exp['cache_utilization_ratio_percent']:.1f}% vs"
            f" {uncached_exp['cache_utilization_ratio_percent']:.1f}%"
        )

    print(f"\nç¸½åŸ·è¡Œæ™‚é–“: {result['total_duration']:.2f} ç§’")
    print(f"çµæœå·²å„²å­˜è‡³: {args.output}")


if __name__ == "__main__":
    asyncio.run(main())
