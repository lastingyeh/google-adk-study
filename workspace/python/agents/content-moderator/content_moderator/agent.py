"""
å…§å®¹å¯©æŸ¥åŠ©ç†ï¼ˆContent Moderation Assistantï¼‰- ç¤ºç¯„å›å‘¼ï¼ˆCallbacksï¼‰èˆ‡é˜²è­·æªæ–½ï¼ˆGuardrailsï¼‰

æœ¬ä»£ç†ï¼ˆagentï¼‰ä½¿ç”¨å„é¡å›å‘¼é”æˆä»¥ä¸‹ç›®çš„ï¼š
1. é˜²è­·ï¼ˆGuardrailsï¼‰ï¼šé˜»æ“‹ä¸ç•¶å…§å®¹ï¼ˆ`before_model_callback`ï¼‰
2. åƒæ•¸é©—è­‰ï¼ˆValidationï¼‰ï¼šæª¢æŸ¥å·¥å…·åƒæ•¸ï¼ˆ`before_tool_callback`ï¼‰
3. è¨˜éŒ„ï¼ˆLoggingï¼‰ï¼šè¿½è¹¤æ‰€æœ‰æ“ä½œï¼ˆå¤šå€‹å›å‘¼ï¼‰
4. æŒ‡ä»¤å¢è£œï¼ˆModificationï¼‰ï¼šé™„åŠ å®‰å…¨èªªæ˜ï¼ˆ`before_model_callback`ï¼‰
5. å€‹è³‡éæ¿¾ï¼ˆFiltering / PII Removalï¼‰ï¼šå›æ‡‰ä¸­ç§»é™¤å€‹äººè­˜åˆ¥è³‡è¨Šï¼ˆ`after_model_callback`ï¼‰
6. æŒ‡æ¨™çµ±è¨ˆï¼ˆMetrics Trackingï¼‰ï¼šè¿½è¹¤ä½¿ç”¨çµ±è¨ˆï¼ˆç‹€æ…‹ç®¡ç† state managementï¼‰

è¨­è¨ˆç›®æ¨™ï¼šæä¾›å¯å»¶ä¼¸ã€æ˜“å¯©æ ¸ã€å…·ç”Ÿç”¢ç’°å¢ƒé¢¨æ ¼çš„å…§å®¹å¯©æŸ¥æµç¨‹ã€‚é¦–æ¬¡å‡ºç¾ä¹‹è‹±æ–‡å°ˆæœ‰åè©æ–¼æ‹¬è™Ÿä¸­ä¿ç•™ï¼Œä»¥åˆ©æŠ€è¡“ç²¾æº–æ€§ã€‚
"""

from google.adk.agents import Agent
from google.adk.agents.callback_context import CallbackContext
from google.adk.tools.tool_context import ToolContext
from google.adk.models.llm_response import LlmResponse
from google.genai import types
from typing import Dict, Any, Optional
import re
import logging

# è¨­å®š loggingï¼ˆç´€éŒ„ç³»çµ±ï¼‰ï¼Œä»¥ INFO ç‚ºé è¨­å±¤ç´šä¾¿æ–¼è§€å¯Ÿè¡Œç‚º
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# ============================================================================
# å°é–è©æ¸…å–®é…ç½®ï¼ˆBLOCKLIST CONFIGURATIONï¼‰
# ============================================================================

# ç°¡åŒ–å°é–è©æ¸…å–®ï¼ˆBlocklistï¼‰ä¾›ç¤ºç¯„ï¼›å¯¦å‹™ä¸Šè«‹æ›¿æ›ç‚ºæ›´å®Œæ•´è©å½™
# ğŸ”‘ é‡é»ï¼šé€™æ˜¯ç¬¬ä¸€é“é˜²ç·šï¼Œé˜»æ“‹æ˜é¡¯ä¸ç•¶å…§å®¹
BLOCKED_WORDS = [
    "profanity1",      # é«’è©±1ï¼ˆå¯¦éš›ä½¿ç”¨æ™‚æ›¿æ›ç‚ºçœŸå¯¦è©å½™ï¼‰
    "profanity2",      # é«’è©±2
    "hate-speech",     # ä»‡æ¨è¨€è«–
    "offensive-term",  # å†’çŠ¯æ€§è©å½™
    "inappropriate-word",  # ä¸ç•¶ç”¨èª
]

# å€‹äººè­˜åˆ¥è³‡è¨Šï¼ˆPII, Personally Identifiable Informationï¼‰ä¹‹æ­£è¦è¡¨ç¤ºå¼æ¨£å¼ï¼Œç”¨æ–¼å¾Œè™•ç†éæ¿¾
# ğŸ”‘ é‡é»ï¼šä¿è­·ä½¿ç”¨è€…éš±ç§ï¼Œè‡ªå‹•ç§»é™¤æ•æ„Ÿå€‹è³‡
PII_PATTERNS = {
    "email": r"\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\.[A-Z|a-z]{2,}\b",  # é›»å­éƒµä»¶
    "phone": r"\b\d{3}[-.]?\d{3}[-.]?\d{4}\b",  # é›»è©±è™Ÿç¢¼ï¼ˆç¾å¼æ ¼å¼ï¼‰
    "ssn": r"\b\d{3}-\d{2}-\d{4}\b",  # ç¤¾æœƒå®‰å…¨è™Ÿç¢¼ï¼ˆSSNï¼‰
    "credit_card": r"\b\d{4}[-\s]?\d{4}[-\s]?\d{4}[-\s]?\d{4}\b",  # ä¿¡ç”¨å¡è™Ÿ
}

# ============================================================================
# å›å‘¼å‡½å¼ï¼ˆCALLBACK FUNCTIONSï¼‰
# ============================================================================


def before_agent_callback(callback_context: CallbackContext) -> Optional[types.Content]:
    """
    æ–¼ä»£ç†é–‹å§‹è™•ç†ä½¿ç”¨è€…è«‹æ±‚ä¹‹å‰å‘¼å«ã€‚

    ğŸ”‘ é‡é»ï¼šé€™æ˜¯æœ€æ—©åŸ·è¡Œçš„å›å‘¼ï¼Œç”¨æ–¼å…¨åŸŸæª¢æŸ¥èˆ‡åˆå§‹åŒ–

    ä½¿ç”¨æƒ…å¢ƒï¼š
      - æª¢æŸ¥æ˜¯å¦é€²å…¥ç¶­è­·æ¨¡å¼ï¼ˆmaintenance modeï¼‰
      - å¢åŠ ä½¿ç”¨è€…è«‹æ±‚æ¬¡æ•¸çµ±è¨ˆï¼ˆrequest_countï¼‰
      - å¯æ“´å……ç‚ºé€Ÿç‡é™åˆ¶ã€ä½¿ç”¨è€…é©—è­‰ç­‰

    å›å‚³ï¼ˆReturnsï¼‰ï¼š
      - Noneï¼šå…è¨±å¾ŒçºŒè™•ç†
      - Contentï¼šç›´æ¥å›è¦†ä½¿ç”¨è€…ä¸¦è·³éå¾ŒçºŒä»£ç†åŸ·è¡Œï¼ˆçŸ­è·¯æ©Ÿåˆ¶ï¼‰
    """
    logger.info(f"[ä»£ç†å•Ÿå‹• AGENT START] æœƒè©±ç·¨è™Ÿ Session: {callback_context.invocation_id}")

    # ğŸ”‘ é‡é»ï¼šç¶­è­·æ¨¡å¼æª¢æŸ¥ â€” è‹¥ç³»çµ±ç¶­è­·ä¸­å‰‡ç«‹å³è¿”å›ï¼Œä¸åŸ·è¡Œä»»ä½•ä»£ç†é‚è¼¯
    if callback_context.state.get("app:maintenance_mode", False):
        logger.warning("[ä»£ç†å°é– AGENT BLOCKED] ç¶­è­·æ¨¡å¼å•Ÿç”¨ä¸­ Maintenance mode active")
        return types.Content(
            parts=[
                types.Part(
                    text="ç³»çµ±ç›®å‰æ­£åœ¨ç¶­è­·ä¸­ï¼Œè«‹ç¨å¾Œå†è©¦ã€‚System is currently under maintenance. Please try again later."
                )
            ],
            role="model",
        )

    # ğŸ”‘ é‡é»ï¼šä½¿ç”¨è€…è«‹æ±‚æ¬¡æ•¸éå¢ï¼ˆä»¥ user: å‰ç¶´æ¨™ç¤ºä½¿ç”¨è€…å±¤ç´šçš„ç‹€æ…‹ï¼‰
    count = callback_context.state.get("user:request_count", 0)
    callback_context.state["user:request_count"] = count + 1

    return None  # å…è¨±ä»£ç†ç¹¼çºŒè™•ç† Allow agent to proceed


def after_agent_callback(callback_context: CallbackContext) -> Optional[types.Content]:
    """
    æ–¼ä»£ç†å®Œæˆä¸»è¦è™•ç†å¾Œå‘¼å«ã€‚

    ğŸ”‘ é‡é»ï¼šæœ€å¾ŒåŸ·è¡Œçš„å›å‘¼ï¼Œç”¨æ–¼æ”¶å°¾èˆ‡æœ€çµ‚ä¿®æ”¹

    ä½¿ç”¨æƒ…å¢ƒï¼š
        - å¯ä»¥åœ¨æ­¤è¿½åŠ å¾Œç½®æ¨™è¨˜ï¼ˆä¾‹å¦‚ï¼šå®Œæˆæ——æ¨™ã€ç‰ˆæ¬Šå®£å‘Šã€çµ±ä¸€å°¾è¨»ï¼‰
        - å¯é€²è¡Œæœ€çµ‚å›æ‡‰æ ¼å¼é©—è­‰
        - è¨˜éŒ„å®Œæˆç‹€æ…‹ä¾›å¾ŒçºŒåˆ†æ

    å›å‚³ï¼š
        - Noneï¼šæ²¿ç”¨åŸå§‹çµæœ
        - Contentï¼šä»¥è‡ªè¨‚å…§å®¹å–ä»£æœ€çµ‚å›æ‡‰
    """
    logger.info(f"[ä»£ç†å®Œæˆ AGENT COMPLETE] æœƒè©±ç·¨è™Ÿ Session: {callback_context.invocation_id}")

    # è¿½è¹¤æˆåŠŸå®Œæˆæ¬¡æ•¸ Track successful completions
    callback_context.state["temp:agent_completed"] = True

    # å¯åœ¨æ­¤åŠ å…¥æ¨™æº–è²æ˜ï¼ˆç¯„ä¾‹ç•¥ï¼‰
    # ğŸ”‘ é‡é»ï¼šå¯ç”¨æ–¼æ·»åŠ å…è²¬è²æ˜æˆ–ç‰ˆæ¬Šè³‡è¨Š
    # return types.Content(
    #     parts=[types.Part(text="\n\n[æ­¤ç‚º AI ç”Ÿæˆå…§å®¹ This is AI-generated content]")]
    # )

    return None  # ä½¿ç”¨åŸå§‹è¼¸å‡º Use original output


def before_model_callback(
    callback_context: CallbackContext, llm_request: types._GenerateContentParameters
) -> Optional[types.GenerateContentResponse]:
    """
    åœ¨å³å°‡é€å‡º LLMï¼ˆå¤§å‹èªè¨€æ¨¡å‹ï¼‰è«‹æ±‚å‰å‘¼å«ã€‚

    ğŸ”‘ é‡é»ï¼šé€™æ˜¯å…§å®¹å®‰å…¨çš„æ ¸å¿ƒæª¢æŸ¥é»ï¼Œå¯æ””æˆªä¸ç•¶è«‹æ±‚ä¸¦ä¿®æ”¹æç¤ºè©

    ä½¿ç”¨æƒ…å¢ƒï¼š
      1. é˜²è­·ï¼ˆGuardrailsï¼‰ï¼šé˜»æ“‹å«å°é–è©çš„è«‹æ±‚
      2. æŒ‡ä»¤å¢è£œï¼ˆModificationï¼‰ï¼šé™„åŠ é¡å¤–å®‰å…¨è¦ç¯„ï¼ˆsystem instructionï¼‰
      3. å¿«å–ï¼ˆCachingï¼‰ï¼šå¯åœ¨æ­¤ç›´æ¥å›å‚³å¿«å–çµæœï¼ˆç›®å‰ç¤ºç¯„ç•¥éï¼‰
      4. ä½¿ç”¨è¿½è¹¤ï¼ˆLogging / Metricsï¼‰ï¼šè¨˜éŒ„ LLM å‘¼å«æ¬¡æ•¸

    å›å‚³ï¼š
      - Noneï¼šå…è¨±å¾ŒçºŒå‘¼å« LLMï¼ˆå¯èƒ½å·²è¢«ä¿®æ”¹ï¼‰
      - GenerateContentResponseï¼šç•¥éçœŸæ­£ LLM å‘¼å«ï¼Œç›´æ¥ä½¿ç”¨æ­¤å›æ‡‰ï¼ˆä¾‹å¦‚å°é–æ™‚ï¼‰
    """
    # æå–ä½¿ç”¨è€…è¼¸å…¥æ–‡å­— Extract user input
    user_text = ""
    for content in llm_request.contents:
        for part in content.parts:
            if part.text:
                user_text += part.text

    logger.info(f"[LLM è«‹æ±‚ LLM REQUEST] é•·åº¦ Length: {len(user_text)} å­—å…ƒ chars")

    # ğŸ”‘ é‡é»ï¼šé˜²è­·æ­¥é©Ÿ â€” æª¢æŸ¥æ˜¯å¦åŒ…å«å°é–è©ï¼ˆBlocklistï¼‰
    # è‹¥å‘½ä¸­å‰‡å›å‚³å°é–è¨Šæ¯ä¸¦åŠ ç¸½ blocked_requestsï¼Œå®Œå…¨è·³é LLM å‘¼å«
    for word in BLOCKED_WORDS:
        if word.lower() in user_text.lower():
            logger.warning(f"[LLM å°é– LLM BLOCKED] ç™¼ç¾å°é–è© Found blocked word: {word}")

            # è¿½è¹¤è¢«å°é–çš„è«‹æ±‚æ¬¡æ•¸ Track blocked requests
            blocked_count = callback_context.state.get("user:blocked_requests", 0)
            callback_context.state["user:blocked_requests"] = blocked_count + 1

            # å›å‚³éŒ¯èª¤å›æ‡‰ï¼ˆè·³é LLM å‘¼å«ï¼‰Return error response (skip LLM call)
            return types.GenerateContentResponse(
                candidates=[
                    types.Candidate(
                        content=types.Content(
                            parts=[
                                types.Part(
                                    text="ç„¡æ³•è™•ç†æ­¤è«‹æ±‚ï¼Œå› ç‚ºåŒ…å«ä¸ç•¶å…§å®¹ã€‚è«‹ä»¥å°Šé‡çš„æ–¹å¼é‡æ–°è¡¨é”ã€‚I cannot process this request as it contains inappropriate content. Please rephrase respectfully."
                                )
                            ],
                            role="model",
                        )
                    )
                ]
            )

    # ğŸ”‘ é‡é»ï¼šæŒ‡ä»¤å¢è£œ â€” æ–¼ system_instruction æœ«ç«¯æ·»åŠ å®‰å…¨æç¤ºèª
    # é€™æœƒå½±éŸ¿æ¨¡å‹çš„æ‰€æœ‰å›æ‡‰ï¼Œé¿å…ç”Ÿæˆæœ‰å®³æˆ–åè¦‹å…§å®¹
    safety_instruction = "\n\né‡è¦æç¤ºï¼šä¸è¦ç”Ÿæˆæœ‰å®³ã€åè¦‹æˆ–ä¸ç•¶å…§å®¹ã€‚è‹¥è«‹æ±‚ä¸æ¸…æ¥šï¼Œè«‹è¦æ±‚æ¾„æ¸…ã€‚IMPORTANT: Do not generate harmful, biased, or inappropriate content. If the request is unclear, ask for clarification."

    # ä¿®æ”¹ç³»çµ±æŒ‡ä»¤ Modify system instruction
    if llm_request.config and llm_request.config.system_instruction:
        llm_request.config.system_instruction += safety_instruction

    # è¨˜éŒ„ LLM å‘¼å«æ¬¡æ•¸ï¼ˆuser ç¯„ç–‡ï¼‰
    llm_count = callback_context.state.get("user:llm_calls", 0)
    callback_context.state["user:llm_calls"] = llm_count + 1

    return None  # å…è¨±é€²è¡Œ LLM å‘¼å«ï¼ˆå«ä¿®æ”¹ï¼‰Allow LLM call with modifications


def after_model_callback(
    callback_context: CallbackContext, llm_response: LlmResponse
) -> Optional[LlmResponse]:
    """
    åœ¨å–å¾— LLM å›æ‡‰å¾Œå‘¼å«ã€‚

    ğŸ”‘ é‡é»ï¼šé€™æ˜¯è¼¸å‡ºéæ¿¾çš„é—œéµé»ï¼Œç¢ºä¿å›æ‡‰å…§å®¹ç¬¦åˆéš±ç§èˆ‡å®‰å…¨æ¨™æº–

    ä½¿ç”¨æƒ…å¢ƒï¼š
      1. éæ¿¾ï¼ˆFilteringï¼‰ï¼šç§»é™¤å€‹è³‡ï¼ˆPIIï¼‰æˆ–æ•æ„Ÿè³‡è¨Š
      2. æ ¼å¼åŒ–ï¼ˆFormattingï¼‰ï¼šå¯çµ±ä¸€è¼¸å‡ºæ ¼å¼ï¼ˆæ­¤ç¤ºç¯„é›†ä¸­æ–¼ PII éæ¿¾ï¼‰
      3. è³‡è¨Šè¨˜éŒ„ï¼ˆLoggingï¼‰ï¼šè¨˜éŒ„å›æ‡‰é•·åº¦æˆ–å“è³ªè©•ä¼°æŒ‡æ¨™
      4. å…§å®¹å¯©æŸ¥ï¼šå¯åŠ å…¥äºŒæ¬¡å®‰å…¨æª¢æŸ¥

    å›å‚³ï¼š
      - Noneï¼šä½¿ç”¨åŸå§‹å›æ‡‰
      - LlmResponseï¼šä»¥ä¿®æ”¹å¾Œå…§å®¹å–ä»£ï¼ˆä¾‹å¦‚å·²é€²è¡Œ PII éæ¿¾ï¼‰
    """
    # æå–å›æ‡‰æ–‡å­— Extract response text
    response_text = ""
    if llm_response.content and llm_response.content.parts:
        for part in llm_response.content.parts:
            if part.text:
                response_text += part.text

    logger.info(f"[LLM å›æ‡‰ LLM RESPONSE] é•·åº¦ Length: {len(response_text)} å­—å…ƒ chars")

    # ğŸ”‘ é‡é»ï¼šéæ¿¾æ­¥é©Ÿ â€” å°æ¯ä¸€ç¨® PII æ¨¡å¼é€²è¡Œæœå°‹èˆ‡æ›¿æ›ï¼Œä¸¦è¨˜éŒ„å‘½ä¸­æ¬¡æ•¸
    # é€™ä¿è­·äº†å¯èƒ½æ„å¤–å‡ºç¾åœ¨å›æ‡‰ä¸­çš„å€‹äººè³‡è¨Š
    filtered_text = response_text
    for pii_type, pattern in PII_PATTERNS.items():
        matches = re.findall(pattern, filtered_text)
        if matches:
            logger.warning(f"[å·²éæ¿¾ FILTERED] ç™¼ç¾ Found {len(matches)} å€‹ {pii_type} å¯¦ä¾‹ instances")
            filtered_text = re.sub(
                pattern, f"[{pii_type.upper()}_å·²éš±è”½_REDACTED]", filtered_text
            )

    # å¦‚æœæœ‰éæ¿¾ä»»ä½•å…§å®¹ï¼Œå›å‚³ä¿®æ”¹å¾Œçš„å›æ‡‰ If we filtered anything, return modified response
    if filtered_text != response_text:
        # å»ºç«‹ä¿®æ”¹å¾Œçš„å…§å®¹ Create modified content
        modified_content = types.Content(
            parts=[types.Part(text=filtered_text)],
            role=llm_response.content.role if llm_response.content else "model",
        )

        # å›å‚³ä¿®æ”¹å¾Œçš„ LlmResponse Return modified LlmResponse
        return llm_response.model_copy(update={"content": modified_content})

    return None  # ä½¿ç”¨åŸå§‹å›æ‡‰ Use original response


def before_tool_callback(
    callback_context: CallbackContext, tool_name: str, args: Dict[str, Any]
) -> Optional[Dict[str, Any]]:
    """
    åœ¨å·¥å…·åŸ·è¡Œå‰å‘¼å«ã€‚

    ğŸ”‘ é‡é»ï¼šå·¥å…·å±¤ç´šçš„å®‰å…¨é–˜é–€ï¼Œç¢ºä¿åƒæ•¸åˆæ³•ä¸”ä½¿ç”¨é‡åœ¨é™åˆ¶å…§

    ä½¿ç”¨æƒ…å¢ƒï¼š
      1. åƒæ•¸é©—è­‰ï¼ˆValidationï¼‰ï¼šæª¢æŸ¥è¼¸å…¥æ˜¯å¦åœ¨å…è¨±ç¯„åœ
      2. æˆæ¬Šæª¢æŸ¥ï¼ˆAuthorizationï¼‰ï¼šå¯æ“´å……ä»¥æª¢æŸ¥ä½¿ç”¨è€…æ¬Šé™
      3. é€Ÿç‡é™åˆ¶ï¼ˆRate Limitingï¼‰ï¼šæ§åˆ¶å·¥å…·ä½¿ç”¨æ¬¡æ•¸
      4. ä½¿ç”¨è¨˜éŒ„ï¼ˆLogging / Metricsï¼‰ï¼šçµ±è¨ˆå·¥å…·å‘¼å«é »ç‡

    å›å‚³ï¼š
      - Noneï¼šå…è¨±å·¥å…·åŸ·è¡Œ
      - dictï¼šç•¥éå·¥å…·åŸ·è¡Œï¼Œç›´æ¥å›å‚³æ­¤çµæœï¼ˆä¾‹å¦‚åƒæ•¸éŒ¯èª¤ï¼‰
    """
    logger.info(f"[å·¥å…·å‘¼å« TOOL CALL] {tool_name} åƒæ•¸ with args: {args}")

    # ğŸ”‘ é‡é»ï¼šåƒæ•¸é©—è­‰ â€” å° generate_text å·¥å…·çš„ word_count é€²è¡Œç¯„åœæª¢æŸ¥
    # é˜²æ­¢æƒ¡æ„æˆ–éŒ¯èª¤çš„å¤§é‡æ–‡å­—ç”Ÿæˆè«‹æ±‚
    if tool_name == "generate_text":
        word_count = args.get("word_count", 0)
        if word_count <= 0 or word_count > 5000:
            logger.warning(f"[å·¥å…·å°é– TOOL BLOCKED] ç„¡æ•ˆçš„å­—æ•¸ Invalid word_count: {word_count}")
            return {
                "status": "error",
                "message": f"ç„¡æ•ˆçš„å­—æ•¸ Invalid word_count: {word_count}. å¿…é ˆä»‹æ–¼ 1 åˆ° 5000 ä¹‹é–“ Must be between 1 and 5000.",
            }

    # ğŸ”‘ é‡é»ï¼šé€Ÿç‡é™åˆ¶ â€” æª¢æŸ¥æŸå·¥å…·å‘¼å«æ¬¡æ•¸æ˜¯å¦å·²é”ä¸Šé™ï¼ˆç¤ºç¯„ç”¨ 100 æ¬¡ï¼‰
    # é˜²æ­¢æ¿«ç”¨èˆ‡è³‡æºè€—ç›¡
    tool_count = callback_context.state.get(f"user:tool_{tool_name}_count", 0)
    if tool_count >= 100:  # ç¯„ä¾‹é™åˆ¶ Example limit
        logger.warning(f"[å·¥å…·å°é– TOOL BLOCKED] {tool_name} è¶…å‡ºé€Ÿç‡é™åˆ¶ Rate limit exceeded")
        return {
            "status": "error",
            "message": f"{tool_name} è¶…å‡ºé€Ÿç‡é™åˆ¶ã€‚è«‹ç¨å¾Œå†è©¦ã€‚Rate limit exceeded for {tool_name}. Please try again later.",
        }

    # ç´€éŒ„å·¥å…·ä½¿ç”¨æ¬¡æ•¸ + æœ€è¿‘ä½¿ç”¨å·¥å…·åç¨±ï¼ˆtemp ç¯„ç–‡ç‚ºæš«æ™‚æ€§ï¼‰
    callback_context.state[f"user:tool_{tool_name}_count"] = tool_count + 1
    callback_context.state["temp:last_tool"] = tool_name

    return None  # å…è¨±å·¥å…·åŸ·è¡Œ Allow tool execution


def after_tool_callback(
    callback_context: CallbackContext, tool_name: str, tool_response: Dict[str, Any]
) -> Optional[Dict[str, Any]]:
    """
    åœ¨å·¥å…·åŸ·è¡ŒçµæŸå¾Œå‘¼å«ã€‚

    ğŸ”‘ é‡é»ï¼šå·¥å…·çµæœçš„å¾Œè™•ç†èˆ‡è¨˜éŒ„é»

    ä½¿ç”¨æƒ…å¢ƒï¼š
      1. çµæœè¨˜éŒ„ï¼ˆLoggingï¼‰ï¼šä¿å­˜å·¥å…·å›å‚³æ¦‚è¦
      2. çµ±ä¸€æ ¼å¼ï¼ˆTransformationï¼‰ï¼šå¯çµ±ä¸€å›å‚³çµæ§‹ï¼ˆæ­¤ç¤ºç¯„æœªå¼·åˆ¶ï¼‰
      3. å¿«å–ï¼ˆCachingï¼‰ï¼šå¯åœ¨æ­¤ä¿å­˜å·¥å…·çµæœä¾›å¾ŒçºŒä½¿ç”¨
      4. éŒ¯èª¤è™•ç†ï¼šå¯åŒ…è£æˆ–ç¾åŒ–éŒ¯èª¤è¨Šæ¯

    å›å‚³ï¼š
      - Noneï¼šä½¿ç”¨åŸå§‹å·¥å…·çµæœ
      - dictï¼šä»¥ä¿®æ”¹å¾Œçµæœå–ä»£
    """
    logger.info(f"[å·¥å…·çµæœ TOOL RESULT] {tool_name}: {tool_response.get('status', 'unknown')}")

    # å„²å­˜æœ€å¾Œå·¥å…·çµæœä¾›é™¤éŒ¯ä½¿ç”¨ Store last tool result for debugging
    callback_context.state["temp:last_tool_result"] = str(tool_response)

    # å¯åœ¨æ­¤æ¨™æº–åŒ–æ‰€æœ‰å·¥å…·å›æ‡‰ Could standardize all tool responses here
    # ğŸ”‘ é‡é»ï¼šç¢ºä¿æ‰€æœ‰å·¥å…·å›æ‡‰éƒ½æœ‰ä¸€è‡´çš„çµæ§‹
    # if 'status' not in tool_response:
    #     tool_response['status'] = 'success'

    return None  # ä½¿ç”¨åŸå§‹çµæœ Use original result


# ============================================================================
# å·¥å…·å®šç¾©ï¼ˆTOOLSï¼‰
# ============================================================================


def generate_text(
    topic: str, word_count: int, tool_context: ToolContext
) -> Dict[str, Any]:
    """
    ä¾æŒ‡å®šä¸»é¡Œèˆ‡å­—æ•¸ç”Ÿæˆæ–‡å­—ï¼ˆç¤ºç¯„ç‰ˆæœªä¸²æ¥çœŸæ­£æ¨¡å‹ï¼‰ã€‚

    ğŸ”‘ é‡é»ï¼šå¯¦éš›æ‡‰ç”¨ä¸­æ‡‰å‘¼å«æ–‡å­—ç”Ÿæˆ API æˆ–æ¨¡å‹

    åƒæ•¸ï¼ˆArgsï¼‰ï¼š
      - topicï¼šä¸»é¡Œ
      - word_countï¼šæœŸæœ›å­—æ•¸ï¼ˆ1-5000ï¼‰
    """
    # å¯¦éš›ä¸Šå·¥å…·æ‡‰åœ¨æ­¤ç”Ÿæˆæ–‡å­— Tool would normally generate text here
    # ç¤ºç¯„ç‰ˆåƒ…å›å‚³ä¸­ç¹¼è³‡æ–™ For demo, just return metadata

    return {
        "status": "success",
        "topic": topic,
        "word_count": word_count,
        "message": f'å·²ç”Ÿæˆé—œæ–¼ã€Œ{topic}ã€çš„ {word_count} å­—æ–‡ç«  Generated {word_count}-word article on "{topic}"',
    }


def check_grammar(text: str, tool_context: ToolContext) -> Dict[str, Any]:
    """
    æª¢æŸ¥èªæ³•ä¸¦æä¾›å¯èƒ½éŒ¯èª¤æ•¸ï¼ˆç°¡åŒ–ç¤ºç¯„ï¼šæ¯ 10 å€‹å­—è¦–ç‚º 1 å€‹æ½›åœ¨å•é¡Œï¼‰ã€‚

    ğŸ”‘ é‡é»ï¼šå¯¦éš›æ‡‰ç”¨æ‡‰æ•´åˆèªæ³•æª¢æŸ¥ APIï¼ˆå¦‚ LanguageToolã€Grammarlyï¼‰

    åƒæ•¸ï¼š
      - textï¼šè¦æª¢æŸ¥çš„æ–‡å­—
    """
    # æ¨¡æ“¬èªæ³•æª¢æŸ¥ Simulate grammar checking
    issues_found = len(text.split()) // 10  # å‡è¨­ï¼šæ¯ 10 å­— 1 å€‹å•é¡Œ Fake: 1 issue per 10 words

    return {
        "status": "success",
        "issues_found": issues_found,
        "message": f"ç™¼ç¾ {issues_found} å€‹æ½›åœ¨èªæ³•å•é¡Œ Found {issues_found} potential grammar issues",
    }


def get_usage_stats(tool_context: ToolContext) -> Dict[str, Any]:
    """
    å¾ç‹€æ…‹ï¼ˆstateï¼‰ä¸­å–å¾—ä½¿ç”¨è€…çµ±è¨ˆè³‡æ–™ï¼Œç¤ºç¯„å›å‘¼å¦‚ä½•ç´¯ç©æŒ‡æ¨™ã€‚

    ğŸ”‘ é‡é»ï¼šé€™å±•ç¤ºäº†ç‹€æ…‹ç®¡ç†åœ¨è¿½è¹¤ä½¿ç”¨æ¨¡å¼ä¸Šçš„æ‡‰ç”¨ï¼Œå¯æ“´å……ä»¥åŠ å…¥æ›´å¤šç¶­åº¦ã€‚
    """
    return {
        "status": "success",
        "request_count": tool_context.state.get("user:request_count", 0),  # ç¸½è«‹æ±‚æ¬¡æ•¸
        "llm_calls": tool_context.state.get("user:llm_calls", 0),  # LLM å‘¼å«æ¬¡æ•¸
        "blocked_requests": tool_context.state.get("user:blocked_requests", 0),  # è¢«å°é–è«‹æ±‚æ•¸
        "tool_generate_text_count": tool_context.state.get(
            "user:tool_generate_text_count", 0
        ),  # æ–‡å­—ç”Ÿæˆå·¥å…·ä½¿ç”¨æ¬¡æ•¸
        "tool_check_grammar_count": tool_context.state.get(
            "user:tool_check_grammar_count", 0
        ),  # èªæ³•æª¢æŸ¥å·¥å…·ä½¿ç”¨æ¬¡æ•¸
    }


# ============================================================================
# ä»£ç†å®šç¾©ï¼ˆAGENT DEFINITIONï¼‰
# ============================================================================

# ğŸ”‘ é‡é»ï¼šé€™æ˜¯æ•´å€‹ç³»çµ±çš„æ ¸å¿ƒé…ç½®ï¼Œå°‡æ‰€æœ‰å›å‘¼èˆ‡å·¥å…·çµ„åˆæˆå®Œæ•´çš„ä»£ç†
root_agent = Agent(
    name="content_moderator",  # ä»£ç†åç¨±
    model="gemini-2.0-flash",  # ä½¿ç”¨çš„æ¨¡å‹
    description="""
    å…·å‚™å®‰å…¨é˜²è­·ã€é©—è­‰èˆ‡ç›£æ§åŠŸèƒ½çš„å…§å®¹å¯©æŸ¥åŠ©ç†ã€‚
    å±•ç¤ºé©ç”¨æ–¼ç”Ÿç”¢ç’°å¢ƒçš„å›å‘¼æ¨¡å¼ã€‚
    """,
    instruction="""
    ä½ æ˜¯ä¸€å€‹å”åŠ©ä½¿ç”¨è€…å‰µä½œèˆ‡ç²¾ç…‰å…§å®¹çš„å¯«ä½œåŠ©ç†ã€‚

    åŠŸèƒ½ï¼ˆCAPABILITIESï¼‰ï¼š
    - ä¾ä»»ä½•ä¸»é¡Œèˆ‡æŒ‡å®šå­—æ•¸ç”Ÿæˆæ–‡å­—
    - æª¢æŸ¥èªæ³•ä¸¦æä¾›ä¿®æ­£å»ºè­°
    - æä¾›ä½¿ç”¨çµ±è¨ˆè³‡æ–™

    å®‰å…¨æ€§ï¼ˆSAFETYï¼‰ï¼š
    - ä½ åœ¨åš´æ ¼çš„å…§å®¹å¯©æŸ¥æ”¿ç­–ä¸‹é‹ä½œ
    - ä¸ç•¶è«‹æ±‚å°‡è¢«è‡ªå‹•å°é–
    - æ‰€æœ‰äº’å‹•éƒ½æœƒè¢«è¨˜éŒ„ä»¥ç¢ºä¿å“è³ª

    å·¥ä½œæµç¨‹ï¼ˆWORKFLOWï¼‰ï¼š
    1. å°æ–¼ç”Ÿæˆè«‹æ±‚ï¼Œä½¿ç”¨ generate_text ä¸¦æŒ‡å®šä¸»é¡Œèˆ‡å­—æ•¸
    2. å°æ–¼èªæ³•æª¢æŸ¥ï¼Œä½¿ç”¨ check_grammar ä¸¦æä¾›æ–‡å­—
    3. å°æ–¼çµ±è¨ˆè³‡æ–™ï¼Œä½¿ç”¨ get_usage_stats

    å§‹çµ‚ä¿æŒæœ‰å¹«åŠ©ã€å°ˆæ¥­ä¸”å°Šé‡çš„æ…‹åº¦ã€‚
    """,
    tools=[generate_text, check_grammar, get_usage_stats],  # è¨»å†Šçš„å·¥å…·
    # ============================================================================
    # å›å‘¼é…ç½®ï¼ˆCALLBACKS CONFIGURATIONï¼‰
    # ğŸ”‘ é‡é»ï¼šé€™äº›å›å‘¼å½¢æˆäº†å®Œæ•´çš„å®‰å…¨èˆ‡ç›£æ§éˆ
    # ============================================================================
    before_agent_callback=before_agent_callback,    # ä»£ç†å•Ÿå‹•å‰ï¼ˆç¶­è­·æ¨¡å¼æª¢æŸ¥ï¼‰
    after_agent_callback=after_agent_callback,      # ä»£ç†å®Œæˆå¾Œï¼ˆæ”¶å°¾è™•ç†ï¼‰
    before_model_callback=before_model_callback,    # LLM å‘¼å«å‰ï¼ˆå…§å®¹é˜²è­·èˆ‡æŒ‡ä»¤å¢è£œï¼‰
    after_model_callback=after_model_callback,      # LLM å›æ‡‰å¾Œï¼ˆPII éæ¿¾ï¼‰
    before_tool_callback=before_tool_callback,      # å·¥å…·åŸ·è¡Œå‰ï¼ˆåƒæ•¸é©—è­‰èˆ‡é€Ÿç‡é™åˆ¶ï¼‰
    after_tool_callback=after_tool_callback,        # å·¥å…·åŸ·è¡Œå¾Œï¼ˆçµæœè¨˜éŒ„ï¼‰
    output_key="last_response",  # è¼¸å‡ºé‡‘é‘°
)
