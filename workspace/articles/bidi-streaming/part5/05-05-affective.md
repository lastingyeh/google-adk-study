歡迎來到這堂關於 **ADK 雙向串流 (Bidi-streaming)** 的進階配置課程。我是你們的資深技術導師。

在我們討論過如何建立基礎連線與處理事件後，現在我們要進入最能賦予 AI 代理程式「靈魂」的核心領域：**進階感知功能**。在 `RunConfig` 的配置背景下，這包含了**「主動性 (Proactivity)」**與**「情感對話 (Affective Dialogue)」**。這些功能不再讓 AI 只是被動的回應機器，而是轉化為具備「主動建議」能力且能「讀懂情緒」的類人代理程式。

---

### 📌 進階感知：RunConfig 學習地圖

1.  **核心架構定義**：從「被動回應」到「主動同理」的技術轉型。
2.  **硬性技術約束**：為什麼「原生音訊模型 (Native Audio)」是唯一解？。
3.  **場景驅動教學**：三種重塑使用者體驗的實戰演練。
4.  **代碼即真理**：在 `RunConfig` 中精準宣告進階感知。
5.  **導師點評與收斂**：測試策略與最佳實踐。

---

### 一、 核心定義：賦予 AI 「主動權」與「同理心」

在更大的 `RunConfig` 配置脈絡下，這兩項進階功能代表了對話互動模式的根本轉變：

*   **主動性 (Proactivity)**：模型可以根據當前對話上下文或視覺感知，「主動」發起回應或提供建議，而無需使用者明確下達指令。這代表什麼？這意味著 AI 具備了預測使用者需求的能力。
*   **情感對話 (Affective Dialogue)**：模型能夠偵測並適應使用者在語音語調、內容中所傳遞的情感背景。模型會根據偵測到的情緒（如沮喪、開心或困惑），動態調整其回應的風格、正式程度與語氣。

---

### 二、 邏輯具象化：模型架構與進階感知相容性

並非所有的模型都能支援這些「類人」功能。根據來源資料，選擇正確的模型架構是啟用的先決條件。

| 功能特性                          | 原生音訊模型 (Native Audio)      | 半串聯模型 (Half-Cascade)    |
| :-------------------------------- | :------------------------------- | :--------------------------- |
| **主動式音訊 (Proactive Audio)**  | ✅ **支援**                       | ❌ 不支援                     |
| **情感對話 (Affective Dialogue)** | ✅ **支援**                       | ❌ 不支援                     |
| **情緒線索偵測**                  | 端到端直接處理音訊，保留情緒細節 | 音訊轉文字處理，遺失語音特徵 |
| **對話自然度**                    | 極高，如同與真人對談             | 穩定但基於 TTS，較具機械感   |

**導師關鍵點評**：這代表如果你在 `RunConfig` 中啟用了這些功能，但使用的卻是半串聯模型（如 `gemini-live-2.5-flash`），ADK 雖然不會崩潰，但會直接忽略這些設定。

---

### 三、 場景驅動教學：重塑體驗的實戰對話

讓我們透過三個實際開發場景，看看進階感知如何將抽象概念轉化為具體的解決方案。

#### 💡 場景 1：主動式購物管家（視覺感知融合）
**提問：** 「當使用者打開鏡頭，展示他們凌亂的書桌時，AI 該如何發揮主動性？」
**解析：** 這是 *Shopper's Concierge* 展示的核心能力。
*   **對話表現**：AI 辨識出桌上的筆電與空間配置，主動說出：「我看到一個居家辦公室的配置，桌上有筆電... 你可能會對螢幕架或檯燈有興趣」。
*   **技術關鍵**：啟用 `proactive_audio=True`，讓模型不必等待提問，就能根據視覺上下文主動介入。

#### 💡 場景 2：具備同理心的客戶服務
**提問：** 「如果使用者用憤怒且沮喪的語調說：『這東西根本沒用！』，情感對話如何發揮作用？」
**解析：**
*   **對話表現**：模型偵測到語調中的「沮喪」訊號。
*   **行為調整**：AI 不會生硬地回覆「請提供錯誤代碼」，而是會以溫和的語調調整回應，例如：「我很抱歉讓您感到不便，我明白這很令人沮喪，讓我們一起解決它」。

#### 💡 場景 3：智慧噪音過濾（無視無關輸入）
**提問：** 「在喧鬧環境中，背景有人在聊天但不是在對 AI 說話，主動性功能如何處理？」
**解析：**
*   **關鍵機制**：具備主動性的模型能智慧判斷何時該回應，以及何時該「忽略無關或離題的輸入」。這能顯著降低 AI 因背景噪音而產生錯誤回應的機率。

---

### 四、 代碼即真理：在 `RunConfig` 中配置進階感知

以下是來源資料中 `bidi-demo` 的核心實作。請注意導師對這段代碼的重點註解。

```python
# [導師點評]：這是 Phase 2 的核心，根據模型名稱自動判定功能支援。
# 關鍵在於：進階感知功能必須搭配「原生音訊模型」與「AUDIO 回應模式」。

model_name = agent.model
is_native_audio = "native-audio" in model_name.lower() # 偵測是否為原生音訊模型

if is_native_audio:
    # 原生音訊模型支援 AUDIO 回應與進階感知
    run_config = RunConfig(
        streaming_mode=StreamingMode.BIDI,
        response_modalities=["AUDIO"], # [關鍵] 原生模型必須使用 AUDIO 模式
        input_audio_transcription=types.AudioTranscriptionConfig(),
        output_audio_transcription=types.AudioTranscriptionConfig(),
        session_resumption=types.SessionResumptionConfig(),

        # [重點標記]：啟用主動性配置
        proactivity=(
            types.ProactivityConfig(proactive_audio=True)
            if proactivity else None
        ),

        # [重點標記]：啟用情感對話功能
        enable_affective_dialog=affective_dialog if affective_dialog else None,
    )
    logger.debug(f"原生音訊模型已偵測，啟用主動性與情感對話。")
else:
    # 半串聯模型僅支援基礎功能，將忽略進階感知
    run_config = RunConfig(
        streaming_mode=StreamingMode.BIDI,
        response_modalities=["TEXT"],
        session_resumption=types.SessionResumptionConfig(),
    )
```

---

### 五、 知識延伸與收斂：實戰導師總結

掌握進階感知功能是從開發「聊天機器人」晉升為開發「AI 代理程式」的關鍵一步。

*   **測試策略**：要驗證主動性，你可以提供資訊但不提問（例如：「我下個月要去日本」），觀察模型是否會主動詢問或提供建議。
*   **情感驗證**：嘗試用不同的情緒語氣說話，觀察模型是否在轉錄內容或語音輸出中展現出適應性的風格調整。
*   **停用時機**：在需要「高度確定性」或「正式專業背景」的任務中（例如法律諮詢或技術維修步驟），應考慮停用情感對話，以維持一致且嚴謹的行為。

**總結而言**，透過 `RunConfig` 設定主動性與情感對話，是將 Gemini 模型強大的跨模態理解能力轉化為「專業導購」或「同理心客服」的最佳利器。

🏷️ `bidi-streaming`, `native-audio`, `affective-dialogue`, `proactive-ai`, `run-config`

**延伸學習連結**：
*   關於如何處理這些進階功能的下游事件，請參閱《[第 3 部分：處理 Event]》。
*   關於音訊規格的詳細定義，請參閱《[第 5 部分：音訊規格]》。

---

[← 上一頁](./05-04-audio-model.md) | [下一頁 (Part 6) →](../part6/06-00-scenario.md) | [課程首頁 ↩](../COURSE_PLAN.md)