歡迎來到這堂深度技術實作課。我是你們的資深技術導師。

在 **ADK 雙向串流 (Bidi-streaming)** 的開發過程中，許多團隊面臨的最大工程挑戰之一就是「對話的長度限制」。如果你正在打造一個虛擬教師或長期的心理諮詢代理程式，你一定不希望 AI 在聊到 10 或 15 分鐘時突然「斷片」。

今天，我們要聚焦在 **RunConfig** 配置中最強大的生產級功能：**上下文視窗壓縮 (Context Window Compression)**。這項技術是實現「無限對話持續時間」的關鍵鑰匙。

---

### 📌 實現無限持續時間：學習地圖

1.  **時間與空間的雙重瓶頸**：為什麼會話會在中途終止？
2.  **滑動視窗機制**：拆解「觸發」與「目標」的運作邏輯。
3.  **場景驅動教學**：透過對話場景選擇最佳壓縮參數。
4.  **代碼即真理**：如何在 `RunConfig` 中注入壓縮配置。
5.  **戰略權衡矩陣**：細節保留 vs. 持續時間的取捨。

---

### 一、 雙重瓶頸：為什麼你的會話會結束？

在 ADK 生命週期的背景下，Live API 會話面臨兩個硬性的物理限制：

1.  **會話持續時間限制 (Time Caps)**：
    *   **Gemini Live API**：僅音訊會話限制為 15 分鐘，音訊+影片僅 2 分鐘。
    *   **Vertex AI Live API**：所有會話硬性限制為 10 分鐘。
2.  **上下文視窗限制 (Token Limits)**：模型具有有限的 Token 容量（如 12.8 萬個 Token），一旦填滿，對話就無法繼續。

**關鍵在於：** 啟用「上下文視窗壓縮」能同時解決這兩個問題。**這代表什麼？** 一旦開啟此功能，Live API 會自動移除上述的 15 分鐘或 10 分鐘硬性時間限制，讓會話持續時間變為「無限」。

---

### 二、 邏輯具象化：滑動視窗與壓縮矩陣

上下文視窗壓縮採用「滑動視窗」的方法：當對話累積的 Token 達到某個閾值時，系統會自動摘要或壓縮較早的歷史紀錄。

#### 📊 壓縮策略對比表
| 維度           | 未啟用壓縮         | 啟用壓縮                     |
| :------------- | :----------------- | :--------------------------- |
| **持續時間**   | 受限 (15m/10m)     | **無限制 (Unlimited)**       |
| **歷史紀錄**   | 完整保留逐字細節   | 舊內容會被轉化為「壓縮摘要」 |
| **Token 管理** | 隨對話增長直到溢位 | 自動維持在有界範圍內         |
| **延遲表現**   | 無額外開銷         | 摘要期間會產生細微的運算延遲 |

---

### 三、 場景驅動教學：參數調優實戰

在 `RunConfig` 中，我們需要設定兩個核心參數：`trigger_tokens`（觸發點）與 `target_tokens`（目標點）。

**提問：** 「導師，我該如何設定這些數字？設得太近會發生什麼？」

**解析：**
**關鍵在於緩衝空間。** 如果這兩個數字設得太近，系統會頻繁觸發壓縮，造成不必要的延遲；如果設得太遠，則可能在壓縮完成前就撞上模型的硬性 Token 上限。

*   **建議策略 (78% / 62%)**：
    *   **觸發點 (78%)**：設定在模型容量的 78%。這能提供足夠的緩衝，確保模型在當前回合完成前，不會因為正在生成回應而突然中斷去進行壓縮。
    *   **目標點 (62%)**：壓縮後留下約 62% 的空間。這代表每次壓縮能釋放約 16% 的空間，足以讓對話在下一次壓縮前再持續多輪互動。

**提問：** 「如果我的對話需要精確記得十分鐘前的一個細節怎麼辦？」

**解析：**
這就是壓縮的權衡。對於精確度至上的任務（如程式碼除錯），建議**不使用壓縮**，並保持在時間限制內；但對於一般性對話（如輔導或客服），壓縮帶來的「無限持續時間」價值遠高於細節的輕微遺失。

---

### 四、 代碼即真理：RunConfig 配置實作

讓我們看看來源資料中如何在 `RunConfig` 中實現這項配置。請注意我對參數設定的點評：

```python
# [導師點評]：這是 Phase 2 的核心配置。
# 若要實現長達數小時的對話，必須注入 ContextWindowCompressionConfig。

run_config = RunConfig(
    streaming_mode=StreamingMode.BIDI,
    # [關鍵在此]：啟用自動會話恢復，讓連線在 10 分鐘自動重連時不會中斷
    session_resumption=types.SessionResumptionConfig(),

    # [這代表什麼？]：下方的配置將會話持續時間解鎖為「無限」
    context_window_compression=types.ContextWindowCompressionConfig(
        # 建議：將 trigger 設為模型視窗的 70-80%，target 設為 60-70%
        trigger_tokens=100000,
        target_tokens=80000
    ),

    response_modalities=["AUDIO"],
    input_audio_transcription=types.AudioTranscriptionConfig(),
    output_audio_transcription=types.AudioTranscriptionConfig(),
)
```
*(參考來源：)*

---

### 五、 知識延伸與收斂

在更大的生產架構脈絡下，實現「無限持續時間」不僅僅是設定兩個數字。

**實戰導向總結：**
1.  **連線 vs. 會話**：上下文壓縮解決了「會話」的邏輯限制，但你仍需配合 `session_resumption`（會話恢復）來解決「連線」層級的 10 分鐘自動斷線問題。
2.  **品質監控**：啟用壓縮後，請監控模型對早期歷史的理解力。如果 AI 開始胡言亂語，代表你的 `target_tokens` 設得太低，導致摘要遺失過多資訊。
3.  **適用性判斷**：只有當你的對話確定會超過 15 分鐘時，才建議啟用壓縮。對於短暫的快速問答，關閉壓縮能保持最高的歷史紀錄精確度。

掌握了這項配置，你就能建構出一個真正具備「長時記憶」且永不斷線的 AI 夥伴。

🏷️ `context-compression`, `infinite-session`, `run-config`, `adk-streaming`, `token-management`

---

[← 上一頁](./05-02-session-resumption.md) | [下一頁 →](./05-04-audio-model.md) | [課程首頁 ↩](../COURSE_PLAN.md)