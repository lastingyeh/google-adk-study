# æ•™å­¸ 32ï¼šStreamlit + ADK - ä½¿ç”¨ç´” Python æ§‹å»ºæ•¸æ“šåˆ†ææ‡‰ç”¨ç¨‹å¼ (Streamlit + ADK Integration - Python Data Apps)

**æ™‚é–“**ï¼š45 åˆ†é˜ | **ç´šåˆ¥**ï¼šä¸­ç´š | **èªè¨€**ï¼šåƒ…é™ Python

---

## ç‚ºä»€éº¼é€™å¾ˆé‡è¦ (Why This Matters)

æ§‹å»ºæ•¸æ“šæ‡‰ç”¨ç¨‹å¼ä¸æ‡‰è©²éœ€è¦å­¸ç¿’ JavaScriptã€React æˆ–ç®¡ç†ç¨ç«‹çš„å‰ç«¯/å¾Œç«¯æœå‹™ã€‚**Streamlit + ADK** è®“æ‚¨èƒ½å¤ ä½¿ç”¨ç´” Python æ§‹å»ºç”Ÿç”¢ç´šçš„æ•¸æ“šåˆ†ææ‡‰ç”¨ç¨‹å¼ã€‚

### æ‚¨æ­£åœ¨è§£æ±ºçš„å•é¡Œ (The Problem You're Solving)
**æ²’æœ‰é€™ç¨®æ–¹æ³•æ™‚ï¼š**
- éœ€è¦å­¸ç¿’ React/Vue/Angular
- è¨­å®š TypeScript
- ç®¡ç†ç¨ç«‹çš„å¾Œç«¯ API
- éƒ¨ç½²å…©å€‹æœå‹™
- è™•ç† CORSã€é©—è­‰ç­‰å•é¡Œ
- éœ€è¦æ•¸é€±æ™‚é–“æ‰èƒ½å®Œæˆ ğŸ˜«

**ä½¿ç”¨ Streamlit + ADKï¼š**
- åƒ…éœ€ç´” Python
- ç¨‹åºå…§ AI Agent (ç„¡ HTTP é–‹éŠ·)
- å–®ä¸€æª”æ¡ˆ = å®Œæ•´æ‡‰ç”¨ç¨‹å¼
- 2 åˆ†é˜å…§éƒ¨ç½²
- ç«‹å³é‹ä½œ ğŸš€

---
### æ‚¨å°‡æ§‹å»ºä»€éº¼ (What You'll Build)

ä¸€å€‹ **æ•¸æ“šåˆ†æèŠå¤©æ©Ÿå™¨äºº**ï¼Œå®ƒå¯ä»¥ï¼š

- æ¥å— CSV æª”æ¡ˆä¸Šå‚³
- èˆ‡æ‚¨çš„æ•¸æ“šé€²è¡Œè‡ªç„¶å°è©±
- ä½¿ç”¨ matplotlib/plotly ç”Ÿæˆåœ–è¡¨
- ä¸€å€‹æŒ‡ä»¤éƒ¨ç½²åˆ°é›²ç«¯
- å®Œå…¨åœ¨ Python ä¸­é‹è¡Œ

**è¦–è¦ºé è¦½ï¼š**

```
User: "æˆ‘çš„å‰ 5 å¤§å®¢æˆ¶æ˜¯èª°ï¼Ÿ"
      â†“
[ğŸ” è™•ç†ä¸­... åˆ†ææ•¸æ“š...]
      â†“
Bot: "æ ¹æ“šæ‚¨çš„æ•¸æ“šï¼š

      æŒ‰ç‡Ÿæ”¶æ’åçš„å‰ 5 å¤§å®¢æˆ¶ï¼š
      1. Acme Corp - $125,000
      2. Tech Inc - $98,500
      ..."
```

## é‹ä½œåŸç† (How It Works)

### æŠ€è¡“å †ç–Š (The Tech Stack)

ä¸‰å€‹ç°¡å–®çš„éƒ¨åˆ†ï¼š

```mermaid
graph TD
    A[Streamlit UI æ¡†æ¶<br/>- èŠå¤©ä»‹é¢<br/>- æª”æ¡ˆä¸Šå‚³<br/>- åœ–è¡¨èˆ‡æ•¸æ“šé¡¯ç¤º] -->|ç¨‹åºå…§å‘¼å«| B[Google ADK Agent æ¡†æ¶<br/>- ç·¨æ’åˆ†æ<br/>- å‘¼å«å·¥å…·<br/>- ç”Ÿæˆç¨‹å¼ç¢¼]
    B -->|HTTPS| C[Gemini 2.0 Flash LLM<br/>- ç†è§£æ‚¨çš„æ•¸æ“š<br/>- ç”Ÿæˆ Python ç¨‹å¼ç¢¼<br/>- å‰µå»ºæ´å¯Ÿ]
```

### ç‚ºä»€éº¼é¸æ“‡é€™ç¨®æ–¹æ³•ï¼Ÿ (Why This Approach?)

| éœ€æ±‚ | è§£æ±ºæ–¹æ¡ˆ | å„ªå‹¢ |
| :--- | :--- | :--- |
| **UI** | Streamlit | ç„¡ HTML/CSSï¼Œç´” Python |
| **AI é‚è¼¯** | ADK | ç„¡ HTTP é–‹éŠ· |
| **LLM** | Gemini | æ¥µå¿«ï¼Œæ™ºæ…§ |
| **éƒ¨ç½²** | å–®ä¸€æœå‹™ | ç°¡å–®ï¼Œå¯é  |

---

## é–‹å§‹ä½¿ç”¨ (5 åˆ†é˜) (Getting Started)

### å…ˆæ±ºæ¢ä»¶ (Prerequisites)

```bash
# æª¢æŸ¥ Python ç‰ˆæœ¬
python --version  # æ‡‰ç‚º 3.9 æˆ–æ›´é«˜ç‰ˆæœ¬
```

éœ€è¦ Google API é‡‘é‘°ï¼Ÿ

1. è¨ªå• [Google AI Studio](https://makersuite.google.com/app/apikey)
2. é»æ“Š "Get API key"
3. è¤‡è£½å®ƒ (è«‹å¦¥å–„ä¿ç®¡ï¼)

### åŸ·è¡Œç¯„ä¾‹ (Run the Demo)

```bash
cd tutorial_implementation/tutorial32

# è¨­å®šä¸€æ¬¡
make setup

# å»ºç«‹è¨­å®šæª”
cp .env.example .env
# ç·¨è¼¯ .env ä¸¦è²¼ä¸Šæ‚¨çš„ API é‡‘é‘°

# å•Ÿå‹•
make dev
```

**æ‰“é–‹ [http://localhost:8501](http://localhost:8501)** å°±å®Œæˆäº†ï¼ ğŸš€

---

## æ§‹å»ºæ‚¨çš„æ‡‰ç”¨ç¨‹å¼ (Building Your App)

### æœ€å°ç¯„ä¾‹ (The Minimal Example)

é€™æ˜¯é–‹å§‹æ‰€éœ€çš„æœ€ä½é™åº¦ç¨‹å¼ç¢¼ (`app.py`)ï¼š

```python
import os
import streamlit as st
import pandas as pd
from google import genai

# è¨­å®š
st.set_page_config(page_title="Data Analyzer", page_icon="ğŸ“Š", layout="wide")
client = genai.Client(api_key=os.getenv("GOOGLE_API_KEY"))

# ç‹€æ…‹
if "messages" not in st.session_state:
    st.session_state.messages = []
if "df" not in st.session_state:
    st.session_state.df = None

# UI
st.title("ğŸ“Š æ•¸æ“šåˆ†æå™¨")

# ä¸Šå‚³
with st.sidebar:
    file = st.file_uploader("CSV æª”æ¡ˆ", type=["csv"])
    if file:
        st.session_state.df = pd.read_csv(file)

# é¡¯ç¤ºè¨Šæ¯
for msg in st.session_state.messages:
    with st.chat_message(msg["role"]):
        st.markdown(msg["content"])

# èŠå¤©
if prompt := st.chat_input("è©¢å•æœ‰é—œæ‚¨çš„æ•¸æ“š..."):
    st.session_state.messages.append({"role": "user", "content": prompt})

    with st.chat_message("user"):
        st.markdown(prompt)

    # å–å¾—å›æ‡‰
    with st.chat_message("assistant"):
        with st.status("åˆ†æä¸­...", expanded=False) as status:
            status.write("è®€å–æ•¸æ“š...")

            # åŠ å…¥æ•¸æ“šä¸Šä¸‹æ–‡
            context = f"Dataset: {st.session_state.df.shape[0]} rows, "
            context += f"{st.session_state.df.shape[1]} columns"

            status.write("æ€è€ƒä¸­...")

            response = client.models.generate_content_stream(
                model="gemini-2.0-flash",
                contents=[{"role": "user", "parts": [{"text": context}]}],
            )

            full_text = ""
            for chunk in response:
                if chunk.text:
                    full_text += chunk.text

            status.update(label="å®Œæˆï¼", state="complete", expanded=False)

        st.markdown(full_text)
        st.session_state.messages.append({"role": "assistant", "content": full_text})
```

**å°±æ˜¯é€™æ¨£ï¼** åŸ·è¡Œ `streamlit run app.py`ï¼Œæ‚¨å°±æœ‰ä¸€å€‹å¯é‹ä½œçš„æ•¸æ“šåˆ†æå™¨äº†ã€‚ ğŸ‰

---

## é—œéµæ¦‚å¿µ (Key Concepts)

### 1. Streamlit å¿«å– (Streamlit Caching)

é¿å…é‡æ–°è¨ˆç®—æ˜‚è²´çš„æ“ä½œï¼š

```python
@st.cache_resource  # è¨ˆç®—ä¸€æ¬¡ï¼Œæ°¸ä¹…é‡è¤‡ä½¿ç”¨
def get_client():
    return genai.Client(api_key=os.getenv("GOOGLE_API_KEY"))

@st.cache_data  # æ•¸æ“šè®Šæ›´æ™‚é‡æ–°è¨ˆç®—
def load_csv(uploaded_file):
    return pd.read_csv(uploaded_file)
```

### 2. Session ç‹€æ…‹ (Session State)

å„²å­˜è·¨è¶Šé‡æ–°åŸ·è¡Œçš„æ•¸æ“šï¼š

```python
# é¦–æ¬¡åŸ·è¡Œæ™‚åˆå§‹åŒ–
if "messages" not in st.session_state:
    st.session_state.messages = []

# åœ¨æ•´å€‹æ‡‰ç”¨ç¨‹å¼ä¸­ä½¿ç”¨
st.session_state.messages.append({"role": "user", "content": prompt})
```

### 3. ç‹€æ…‹å®¹å™¨ (Status Container)

å‘ä½¿ç”¨è€…é¡¯ç¤ºé€²åº¦ (Streamlit æœ€ä½³å¯¦è¸)ï¼š

```python
with st.status("è™•ç†ä¸­...", expanded=False) as status:
    status.write("æ­¥é©Ÿ 1ï¼šè¼‰å…¥æ•¸æ“š")
    # ... åŸ·è¡Œå·¥ä½œ ...

    status.write("æ­¥é©Ÿ 2ï¼šåˆ†æä¸­")
    # ... æ›´å¤šå·¥ä½œ ...

    status.update(label="å®Œæˆï¼", state="complete")
```

---

## ç†è§£æ¶æ§‹ (Understanding the Architecture)

### çµ„ä»¶åœ– (Component Diagram)

```mermaid
graph TD
    A["ä½¿ç”¨è€…çš„ç€è¦½å™¨<br/><br/>Streamlit æ‡‰ç”¨ç¨‹å¼ (Port 8501)<br/>- èŠå¤©ä»‹é¢ (st.chat_message, st.chat_input)<br/>- æª”æ¡ˆä¸Šå‚³ (st.file_uploader)<br/>- è³‡æ–™é¡¯ç¤º (st.dataframe)<br/>- Session ç‹€æ…‹ (st.session_state)"]
        -->|"WebSocket<br/>(Streamlit protocol)"| B
    subgraph STREAMLIT_SERVER [Streamlit ä¼ºæœå™¨]
        B["Streamlit ä¼ºæœå™¨ (Python Process)<br/><br/>app.py<br/>- UI Rendering (UI ç¹ªè£½)<br/>- Session ç®¡ç†<br/>- Event Handling (äº‹ä»¶è™•ç†)"]
            -->|"ç¨‹åºå…§å‘¼å« (In-Process Call)"| C

    end
        C["Google Gemini Client<br/>- ç›´æ¥ API å‘¼å«<br/>- ä¸éœ€è¦é¡å¤– HTTP ä¼ºæœå™¨ï¼<br/>- æ”¯æ´ä¸²æµå›æ‡‰ (Streaming responses)"]
            -->|HTTPS| D

    D[Gemini 2.0 Flash API<br/>- æ–‡å­—ç”Ÿæˆ<br/>- ä¸²æµå›æ‡‰<br/>- ä¸Šä¸‹æ–‡ç†è§£]
```

**èˆ‡ Next.js/Vite çš„ä¸»è¦å€åˆ¥ï¼š**

| é¢å‘ | Streamlit | Next.js/Vite |
| :--- | :--- | :--- |
| **æ¶æ§‹** | å–®ä¸€ Python ç¨‹åº | å‰ç«¯ + å¾Œç«¯ |
| **é€šè¨Š** | ç¨‹åºå…§å‡½æ•¸å‘¼å« | HTTP/WebSocket |
| **å»¶é²** | ~0ms (ç¨‹åºå…§) | ~50-100ms (ç¶²è·¯) |
| **éƒ¨ç½²** | å–®ä¸€æœå‹™ | å…©å€‹æœå‹™ |
| **è¤‡é›œåº¦** | ç°¡å–® (1 å€‹æª”æ¡ˆ) | ä¸­ç­‰ (å¤šå€‹æª”æ¡ˆ) |
| **ä½¿ç”¨æ¡ˆä¾‹** | æ•¸æ“šå·¥å…·ï¼Œå…§éƒ¨æ‡‰ç”¨ç¨‹å¼ | ç”Ÿç”¢ç´š Web æ‡‰ç”¨ç¨‹å¼ |

---

### è«‹æ±‚æµç¨‹ (Request Flow)

#### 1. ä½¿ç”¨è€…ä¸Šå‚³ CSV æª”æ¡ˆ

```python
# Streamlit è™•ç†æª”æ¡ˆä¸Šå‚³
uploaded_file = st.file_uploader("Upload CSV")

# è¼‰å…¥åˆ° pandas
df = pd.read_csv(uploaded_file)

# å„²å­˜åœ¨ session state (è·¨é‡æ–°åŸ·è¡ŒæŒä¹…åŒ–)
st.session_state.dataframe = df
```

#### 2. ä½¿ç”¨è€…ç™¼é€è¨Šæ¯ã€ŒæŒ‰ç‡Ÿæ”¶æ’åçš„å‰ 5 å¤§å®¢æˆ¶æ˜¯èª°ï¼Ÿã€

#### 3. Streamlit æ‡‰ç”¨ç¨‹å¼

```python
# æ§‹å»ºåŒ…å«æ•¸æ“šé›†è³‡è¨Šçš„ä¸Šä¸‹æ–‡
context = f"""
Dataset available:
- Columns: {df.columns.tolist()}
- First rows: {df.head(3)}
"""

# ç›´æ¥å‘¼å« Gemini (ç¨‹åºå…§ï¼)
response = client.models.generate_content_stream(
    model="gemini-2.0-flash-exp",
    contents=[...],
    config=GenerateContentConfig(
        system_instruction=f"You are a data analyst. {context}"
    )
)
```

#### 4. Gemini API

```text
ç³»çµ±ï¼šä½ æ˜¯ä¸€ä½æ•¸æ“šåˆ†æå¸«ã€‚è³‡æ–™é›†åŒ…å«æ¬„ä½ï¼šcustomer, revenue...
ä½¿ç”¨è€…ï¼šæŒ‰ç‡Ÿæ”¶æ’åçš„å‰ 5 å¤§å®¢æˆ¶æ˜¯èª°ï¼Ÿ
æ¨¡å‹ï¼šæ ¹æ“šæ‚¨çš„æ•¸æ“šï¼Œå‰ 5 å¤§å®¢æˆ¶æ˜¯ï¼š
1. Acme Corp - $125,000
2. Tech Inc - $98,500
...
```

#### 5. å›æ‡‰ä¸²æµå›å‚³

```python
# ä¸²æµå€å¡Šåˆ°é”æ™‚è™•ç†
for chunk in response:
    full_response += chunk.text
    message_placeholder.markdown(full_response + "â–Œ")
```

#### 6. ä½¿ç”¨è€…å³æ™‚çœ‹åˆ°å›æ‡‰æ‰“å­—æ•ˆæœï¼ âš¡

---

## ç†è§£ ADK (Agent Development Kit)

é€™å°±æ˜¯ Streamlit + ADK ç™¼å…‰ç™¼ç†±çš„åœ°æ–¹ã€‚æ‚¨å¯èƒ½æœƒå•ï¼š**ã€Œç‚ºä»€éº¼è¦ä½¿ç”¨ ADK è€Œä¸æ˜¯ç›´æ¥å‘¼å« Geminiï¼Ÿã€**

å¥½å•é¡Œï¼è®“æˆ‘å€‘ä¾†æ¢ç´¢æ¶æ§‹ã€‚

### ç›´æ¥ API vs ADK æ¶æ§‹

#### ç›´æ¥ Gemini API (è¼ƒç°¡å–®ä½†å—é™)

```python
# æˆ‘å€‘åœ¨ä¸Šé¢çš„è«‹æ±‚æµç¨‹ä¸­å±•ç¤ºçš„å…§å®¹
client = genai.Client(api_key=...)
response = client.models.generate_content(
    model="gemini-2.0-flash",
    contents=[...]
)
```

**å„ªé»**ï¼š

- âœ… ç°¡å–®ï¼Œç›´æ¥ï¼Œæœ€å°‘è¨­å®š
- âœ… éå¸¸é©åˆåŸºæœ¬èŠå¤©
- âœ… å®Œå…¨æ§åˆ¶æç¤º

**ç¼ºé»**ï¼š

- âŒ æ²’æœ‰å·¥å…·/å‡½æ•¸å‘¼å«ç·¨æ’
- âŒ æ²’æœ‰ç¨‹å¼ç¢¼åŸ·è¡Œèƒ½åŠ›
- âŒ æ‰‹å‹•æç¤ºå·¥ç¨‹
- âŒ æ²’æœ‰å¯é‡ç”¨çš„ Agent æ¨¡å¼

#### ADK æ¶æ§‹ (å¼·å¤§ä¸”åŠŸèƒ½æ›´å¤š)

```python
# ä½¿ç”¨ ADK Agents
from google.adk.agents import Agent
from google.adk.runners import Runner

# å®šç¾©æ‚¨çš„ agent èˆ‡å·¥å…·
agent = Agent(
    name="data_analysis_agent",
    model="gemini-2.0-flash",
    tools=[analyze_column, calculate_correlation, filter_data]
)

# å‰µå»º runner ä¾†ç·¨æ’å®ƒ
runner = Runner(agent=agent, app_name="my_app")

# åœ¨ Streamlit ä¸­åŸ·è¡Œ
async for event in runner.run_async(
    user_id="streamlit_user",
    session_id=session_id,
    new_message=message
):
    # è™•ç† agent å›æ‡‰
    process_event(event)
```

**å„ªé»**ï¼š

- âœ… è‡ªå‹•å·¥å…·/å‡½æ•¸ç·¨æ’
- âœ… ç”¨æ–¼å‹•æ…‹è¦–è¦ºåŒ–çš„ç¨‹å¼ç¢¼åŸ·è¡Œ
- âœ… å¤š Agent å”ä½œ
- âœ… è·¨ Session çš„ç‹€æ…‹ç®¡ç†
- âœ… éŒ¯èª¤è™•ç†å’Œé‡è©¦
- âœ… å¯é‡ç”¨çš„ Agent çµ„ä»¶

**ç¼ºé»**ï¼š

- âŒ è¨­å®šç¨å¤š
- âŒ éœ€è¦æ­£ç¢ºçµæ§‹åŒ– Agents

### ä½•æ™‚ä½¿ç”¨å“ªç¨® (When to Use Each)

| ä½¿ç”¨æ¡ˆä¾‹ | æ–¹æ³• | åŸå›  |
| :--- | :--- | :--- |
| **é—œæ–¼æ•¸æ“šçš„ç°¡å–®èŠå¤©** | ç›´æ¥ API | å¿«é€Ÿï¼Œæœ€å°‘è¨­å®š |
| **éœ€è¦å·¥å…·å‘¼å«** | ADK | è‡ªå‹•ç·¨æ’ |
| **å¸¶å·¥å…·çš„æ•¸æ“šåˆ†æ** | ADK | æ›´å¥½çš„çµæ§‹ |
| **å‹•æ…‹ç¨‹å¼ç¢¼åŸ·è¡Œ** | ADK | æ”¯æ´ BuiltInCodeExecutor |
| **å¤š Agent å·¥ä½œæµç¨‹** | ADK | å¤š Agent è·¯ç”± |
| **ç”Ÿç”¢ç´šæ‡‰ç”¨ç¨‹å¼** | ADK | æ›´å¥½çš„éŒ¯èª¤è™•ç† |

**ğŸ¯ æœ¬æ•™å­¸å…©è€…çš†ç”¨**ï¼šLevel 1-2 å±•ç¤ºç”¨æ–¼å­¸ç¿’çš„ç›´æ¥ APIï¼ŒLevel 3+ å±•ç¤ºç”¨æ–¼ç”Ÿç”¢æ¨¡å¼çš„ ADKã€‚

### ADK æ ¸å¿ƒæ¦‚å¿µ (ADK Core Concepts)

#### 1. Agents

ä¸€å€‹ **Agent** æ˜¯ä¸€å€‹ AI å¯¦é«”ï¼Œå®ƒå¯ä»¥ï¼š

- ç†è§£ä½¿ç”¨è€…è«‹æ±‚
- å‘¼å«å·¥å…· (æ‚¨æä¾›çš„å‡½æ•¸)
- æ¨ç†çµæœ
- ç”Ÿæˆç¨‹å¼ç¢¼ä¸¦åŸ·è¡Œå®ƒ

```python
from google.adk.agents import Agent

agent = Agent(
    name="analyzer",
    model="gemini-2.0-flash",
    description="åˆ†ææ•¸æ“š",
    instruction="ä½ æ˜¯ä¸€ä½æ•¸æ“šåˆ†æå¸«ã€‚å¹«åŠ©ä½¿ç”¨è€…ç†è§£ä»–å€‘çš„æ•¸æ“šé›†ã€‚",
    tools=[tool1, tool2, tool3]  # Agent å¯ä»¥å‘¼å«çš„å‡½æ•¸åˆ—è¡¨
)
```

#### 2. å·¥å…· (Tools)

**å·¥å…·** æ˜¯ Agents å¯ä»¥å‘¼å«çš„ Python å‡½æ•¸ï¼š

```python
def analyze_column(column_name: str, analysis_type: str) -> dict:
    """Analyze a specific column."""
    # æ‚¨çš„é‚è¼¯åœ¨é€™è£¡
    return {
        "status": "success",
        "report": "analysis results",
        "data": {...}
    }

# è¨»å†Šåˆ° agent
agent = Agent(
    tools=[analyze_column, calculate_correlation, filter_data]
)
```

#### 3. Runners

ä¸€å€‹ **Runner** åœ¨ Streamlit ä¸­ç·¨æ’ Agent åŸ·è¡Œï¼š

```python
from google.adk.runners import Runner
from google.adk.sessions import InMemorySessionService

session_service = InMemorySessionService()
runner = Runner(
    agent=agent,
    app_name="è³‡æ–™åˆ†æåŠ©ç†",
    session_service=session_service
)

# åœ¨ Streamlit ä¸­åŸ·è¡Œ
async for event in runner.run_async(
    user_id="streamlit_user",
    session_id=session_id,
    new_message=message
):
    handle_event(event)
```

#### 4. ç¨‹å¼ç¢¼åŸ·è¡Œ (Code Execution)

ADK æ”¯æ´ **BuiltInCodeExecutor** é€²è¡Œå‹•æ…‹è¦–è¦ºåŒ–ï¼š

```python
from google.adk.code_executors import BuiltInCodeExecutor

code_executor = BuiltInCodeExecutor()

visualization_agent = Agent(
    name="visualization_agent",
    model="gemini-2.0-flash",
    description="ç”Ÿæˆæ•¸æ“šè¦–è¦ºåŒ–",
    instruction="""ä½ æ˜¯ä¸€ä½æ•¸æ“šè¦–è¦ºåŒ–å°ˆå®¶ã€‚
        ä½ çš„è§’è‰²æ˜¯å‰µå»ºæ¸…æ™°ã€è³‡è¨Šè±å¯Œçš„è¦–è¦ºåŒ–ä¾†å¹«åŠ©ä½¿ç”¨è€…ç†è§£ä»–å€‘çš„æ•¸æ“šã€‚
        ä½ å¿…é ˆç”Ÿæˆ Python ç¨‹å¼ç¢¼ä¾†å‰µå»ºè¦–è¦ºåŒ–ã€‚""",
    code_executor=code_executor, # å•Ÿç”¨ç¨‹å¼ç¢¼åŸ·è¡Œï¼
)
```

é€™è®“ Agents å¯ä»¥ï¼š

- ç”Ÿæˆ Python ç¨‹å¼ç¢¼
- åœ¨æ²™ç›’ä¸­å®‰å…¨åŸ·è¡Œ
- ä»¥å…§åµŒåœ–ç‰‡å›å‚³è¦–è¦ºåŒ–çµæœ
- å„ªé›…åœ°è™•ç†éŒ¯èª¤

### ADK æ¶æ§‹åœ– (ADK Architecture Diagram)

```mermaid
graph TD
    subgraph UI [Streamlit UI]
        ChatInterface[èŠå¤©ä»‹é¢<br/>- ä½¿ç”¨è€…è¨Šæ¯è¼¸å…¥<br/>- è¨Šæ¯é¡¯ç¤º<br/>- Session ç‹€æ…‹ç®¡ç†]
    end

    subgraph Runner [ADK Runner]
        Orchestration[ç·¨æ’å±¤<br/>- è¨Šæ¯è·¯ç”±<br/>- å·¥å…·å‘¼å«<br/>- ç¨‹å¼ç¢¼åŸ·è¡Œ<br/>- ç‹€æ…‹ç®¡ç†]
    end

    subgraph Agents [Agents]
        Agent1[Agent 1: åˆ†æ<br/>Tools:<br/>- åˆ†æ<br/>- éæ¿¾<br/>- è¨ˆç®—]
        Agent2[Agent 2: è¦–è¦ºåŒ–<br/>CodeExec:<br/>- ç”Ÿæˆè¦–è¦ºåŒ–<br/>- åŸ·è¡Œ<br/>- å›å‚³]
    end

    ChatInterface -->|ç¨‹åºå…§å‘¼å«| Runner
    Orchestration -->|åŸ·è¡Œå·¥å…·| Agent1
    Orchestration -->|åŸ·è¡Œå·¥å…·| Agent2
```

### ADK ç‚ºæ‚¨æä¾›ä»€éº¼ (What ADK Gives You)

**ä½¿ç”¨ ADKï¼Œæ‚¨å¯ä»¥ç²å¾—ï¼š**

1. **è‡ªå‹•å·¥å…·å‘¼å«**ï¼šAgent åˆ¤æ–·ä½¿ç”¨å“ªäº›å·¥å…·
2. **ä¸²æµå›æ‡‰**ï¼šäº‹ä»¶åœ¨ Agent æ€è€ƒæ™‚ä¸²æµå›å‚³
3. **ç¨‹å¼ç¢¼åŸ·è¡Œ**ï¼šAgents å¯ä»¥ç·¨å¯«ä¸¦åŸ·è¡Œ Python
4. **å¤š Agent**ï¼šå”èª¿å¤šå€‹å°ˆé–€çš„ Agents
5. **ç‹€æ…‹ç®¡ç†**ï¼šç„¡éœ€é¡å¤–ç¨‹å¼ç¢¼çš„ Session æŒä¹…åŒ–
6. **éŒ¯èª¤è™•ç†**ï¼šè‡ªå‹•é‡è©¦å’Œå›é€€
7. **é¡å‹å®‰å…¨**ï¼šå¸¶æœ‰é©—è­‰çš„å·¥å…·åƒæ•¸

---

## æ§‹å»ºæ‚¨çš„æ‡‰ç”¨ç¨‹å¼ - æ¼¸é€²å¼ç¯„ä¾‹ (Building Your App - Progressive Examples)

ç¾åœ¨æ‚¨å·²ç¶“äº†è§£äº†åŸºç¤çŸ¥è­˜å’Œ ADK æ¶æ§‹ï¼Œè®“æˆ‘å€‘é€æ­¥å¢åŠ è¤‡é›œåº¦ã€‚

### Level 1ï¼šåŸºæœ¬èŠå¤© (èµ·é») âœ“

æ‚¨å·²ç¶“æœ‰äº†é€™å€‹ - ä¸€å€‹ 50 è¡Œçš„æ‡‰ç”¨ç¨‹å¼ï¼Œå¯ä»¥è«‡è«–æ‚¨çš„æ•¸æ“šã€‚

---

### Level 2ï¼šåŠ å…¥éŒ¯èª¤è™•ç†èˆ‡æ›´å¥½çš„ä¸Šä¸‹æ–‡

è®“æˆ‘å€‘æ”¹é€²æœ€å°ç¯„ä¾‹ï¼ŒåŠ å…¥æ›´å¥½çš„éŒ¯èª¤è™•ç†å’Œæ•¸æ“šé›†ä¸Šä¸‹æ–‡ï¼š

```python
import os
import streamlit as st
import pandas as pd
from google import genai

st.set_page_config(page_title="Data Analyzer", page_icon="ğŸ“Š", layout="wide")
client = genai.Client(api_key=os.getenv("GOOGLE_API_KEY"))

# ç‹€æ…‹åˆå§‹åŒ–
if "messages" not in st.session_state:
    st.session_state.messages = []
if "df" not in st.session_state:
    st.session_state.df = None

# å´é‚Šæ¬„ï¼šæª”æ¡ˆä¸Šå‚³
with st.sidebar:
    uploaded_file = st.file_uploader("Upload CSV", type=["csv"])
    if uploaded_file is not None:
        try:
            st.session_state.df = pd.read_csv(uploaded_file)
            st.success(f"âœ“ Loaded {len(st.session_state.df)} rows")
        except Exception as e:
            st.error(f"Error loading file: {e}")

# ä¸»èŠå¤©ä»‹é¢
st.title("ğŸ“Š æ•¸æ“šåˆ†æå™¨")

# é¡¯ç¤ºå°è©±
for msg in st.session_state.messages:
    with st.chat_message(msg["role"]):
        st.markdown(msg["content"])

# èŠå¤©è¼¸å…¥
if prompt := st.chat_input("Ask about your data..."):
    st.session_state.messages.append({"role": "user", "content": prompt})

    with st.chat_message("user"):
        st.markdown(prompt)

    if st.session_state.df is None:
        with st.chat_message("assistant"):
            response = "è«‹å…ˆä¸Šå‚³ CSV æª”æ¡ˆï¼"
            st.markdown(response)
            st.session_state.messages.append({"role": "assistant", "content": response})
    else:
        # æ§‹å»ºè±å¯Œä¸Šä¸‹æ–‡
        df = st.session_state.df
        context = f"""
        Dataset Summary:
        - {len(df)} rows Ã— {len(df.columns)} columns
        - Columns: {', '.join(df.columns.tolist())}
        - Memory: {df.memory_usage(deep=True).sum() / 1024**2:.2f} MB

        Data Preview:
        {df.head(3).to_string()}
        """

        with st.chat_message("assistant"):
            try:
                with st.status("Analyzing...", expanded=False) as status:
                    status.write("Reading context...")

                    response = client.models.generate_content_stream(
                        model="gemini-2.0-flash",
                        contents=[{"role": "user", "parts": [{"text": f"{context}\n\nUser: {prompt}"}]}],
                    )

                    full_text = ""
                    for chunk in response:
                        if chunk.text:
                            full_text += chunk.text

                    status.update(label="Complete!", state="complete")

                st.markdown(full_text)
                st.session_state.messages.append({"role": "assistant", "content": full_text})

            except Exception as e:
                st.error(f"Error: {e}")
```

**æ”¹é€²ä¹‹è™•**ï¼š

- âœ“ æ›´å¥½çš„ä¸Šä¸‹æ–‡æº–å‚™
- âœ“ å´é‚Šæ¬„æª”æ¡ˆä¸Šå‚³
- âœ“ ç¼ºå°‘æ•¸æ“šçš„éŒ¯èª¤è™•ç†
- âœ“ é€²åº¦ç‹€æ…‹å®¹å™¨
- âœ“ è¨˜æ†¶é«”ä½¿ç”¨è³‡è¨Š

---

### Level 3ï¼šä½¿ç”¨å¸¶æœ‰ Runners çš„ ADK

ç¾åœ¨è®“æˆ‘å€‘ä½¿ç”¨å¸¶æœ‰å·¥å…·å’Œ runners çš„å¯¦éš› ADK agentsã€‚é€™æ˜¯ç”Ÿç”¢æ¨¡å¼ç‰ˆæœ¬ï¼š

**æ­¥é©Ÿ 1ï¼šå‰µå»ºæ‚¨çš„ agents** (`data_analysis_agent/agent.py`)ï¼š

```python
"""
æ•¸æ“šåˆ†æ Agent - ä¸»è¦åˆ†æç·¨æ’è€…
ä½¿ç”¨å¸¶æœ‰å·¥å…·å‘¼å«çš„ ADK Agent æ¡†æ¶
"""

from typing import Any, Dict
from google.adk.agents import Agent


def analyze_column(column_name: str, analysis_type: str) -> Dict[str, Any]:
    """åˆ†æç‰¹å®šæ¬„ä½ï¼ˆæ‘˜è¦ã€åˆ†ä½ˆã€ç•°å¸¸å€¼ï¼‰ã€‚"""
    try:
        if not column_name:
            return {"status": "error", "report": "Column name required"}

        return {
            "status": "success",
            "report": f"Analysis configured for {column_name}",
            "analysis_type": analysis_type,
            "column_name": column_name,
            "note": "Streamlit app will execute with real data"
        }
    except Exception as e:
        return {"status": "error", "report": str(e)}


def calculate_correlation(
    column1: str, column2: str
) -> Dict[str, Any]:
    """è¨ˆç®—æ¬„ä½ä¹‹é–“çš„ç›¸é—œæ€§ã€‚"""
    try:
        if not column1 or not column2:
            return {"status": "error", "report": "Two columns required"}

        return {
            "status": "success",
            "report": f"Correlation calculation configured",
            "column1": column1,
            "column2": column2
        }
    except Exception as e:
        return {"status": "error", "report": str(e)}


def filter_data(
    column_name: str, operator: str, value: str
) -> Dict[str, Any]:
    """æ ¹æ“šæ¢ä»¶éæ¿¾æ•¸æ“šé›†ã€‚"""
    try:
        return {
            "status": "success",
            "report": f"Filter: {column_name} {operator} {value}",
            "column_name": column_name,
            "operator": operator,
            "value": value
        }
    except Exception as e:
        return {"status": "error", "report": str(e)}


# å‰µå»º ADK Agent
root_agent = Agent(
    name="data_analysis_agent",
    model="gemini-2.0-flash",
    description="ä½¿ç”¨å·¥å…·å’Œæ´å¯Ÿåˆ†ææ•¸æ“šé›†",
    instruction="""ä½ æ˜¯ä¸€ä½å°ˆå®¶æ•¸æ“šåˆ†æå¸«ã€‚ä½ çš„è§’è‰²ï¼š
    1. å¹«åŠ©ä½¿ç”¨è€…ç†è§£ä»–å€‘çš„æ•¸æ“šé›†
    2. åˆ†ææ¬„ä½å’Œåˆ†ä½ˆ
    3. å°‹æ‰¾ç›¸é—œæ€§å’Œæ¨¡å¼
    4. è­˜åˆ¥ç•°å¸¸å€¼å’Œç•°å¸¸
    5. æä¾›å¯åŸ·è¡Œçš„æ´å¯Ÿ

    éœ€è¦åœ¨éœ€è¦æ™‚ä½¿ç”¨å¯ç”¨å·¥å…·ä¾†åˆ†ææ•¸æ“šã€‚
    å§‹çµ‚æ¸…æ™°åœ°è§£é‡‹çµæœä¸¦å»ºè­°å¾ŒçºŒåˆ†æã€‚""",
    tools=[analyze_column, calculate_correlation, filter_data]
)
```

**æ­¥é©Ÿ 2ï¼šåœ¨ Streamlit ä¸­ä½¿ç”¨ agent** (`app.py`)ï¼š

```python
"""
å¸¶æœ‰ ADK Agents çš„æ•¸æ“šåˆ†æåŠ©æ‰‹
å¤šæ¨¡å¼ï¼šADK agents ç”¨æ–¼åˆ†æï¼ŒStreamlit ç”¨æ–¼ UI
"""

import asyncio
import os
import streamlit as st
import pandas as pd
from dotenv import load_dotenv
from google import genai
from google.genai.types import Content, Part
from google.adk.runners import Runner
from google.adk.sessions import InMemorySessionService

# åŒ¯å…¥æ‚¨çš„ agent
from data_analysis_agent import root_agent

load_dotenv()
st.set_page_config(
    page_title="Data Analysis",
    page_icon="ğŸ“Š",
    layout="wide"
)

# ===== AGENT è¨­å®š =====

@st.cache_resource
def get_runner():
    """åˆå§‹åŒ–ç”¨æ–¼ agent åŸ·è¡Œçš„ ADK runnerã€‚"""
    session_service = InMemorySessionService()
    return Runner(
        agent=root_agent,
        app_name="data_analysis_assistant",
        session_service=session_service,
    ), session_service


runner, session_service = get_runner()

# ===== åˆå§‹åŒ– ADK SESSION =====

if "adk_session_id" not in st.session_state:
    async def init_session():
        session = await session_service.create_session(
            app_name="data_analysis_assistant",
            user_id="streamlit_user"
        )
        return session.id

    st.session_state.adk_session_id = asyncio.run(init_session())

# ===== ç‹€æ…‹ =====

if "messages" not in st.session_state:
    st.session_state.messages = []
if "df" not in st.session_state:
    st.session_state.df = None

# ===== UI =====

st.title("ğŸ“Š æ•¸æ“šåˆ†æåŠ©æ‰‹ (ADK)")

# å´é‚Šæ¬„
with st.sidebar:
    st.header("ğŸ“ ä¸Šå‚³æ•¸æ“š")
    uploaded_file = st.file_uploader(
        "é¸æ“‡ä¸€å€‹ CSV æª”æ¡ˆ",
        type=["csv"]
    )

    if uploaded_file is not None:
        try:
            st.session_state.df = pd.read_csv(uploaded_file)
            st.success(f"âœ… {len(st.session_state.df)} rows loaded")

            with st.expander("ğŸ“‹ é è¦½"):
                st.dataframe(
                    st.session_state.df.head(5),
                    use_container_width=True
                )
        except Exception as e:
            st.error(f"Error: {e}")

# èŠå¤©é¡¯ç¤º
for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

# èŠå¤©è¼¸å…¥
if prompt := st.chat_input(
    "è©¢å•æœ‰é—œæ‚¨çš„æ•¸æ“š..." if st.session_state.df is not None
    else "è«‹å…ˆä¸Šå‚³ CSV",
    disabled=st.session_state.df is None
):
    st.session_state.messages.append({"role": "user", "content": prompt})

    with st.chat_message("user"):
        st.markdown(prompt)

    # æº–å‚™ä¸Šä¸‹æ–‡
    if st.session_state.df is not None:
        df = st.session_state.df
        context = f"""
        **Dataset**: {len(df)} rows Ã— {len(df.columns)} columns
        **Columns**: {', '.join(df.columns.tolist())}

        **Preview**:
        {df.head(3).to_string()}

        **User Question**: {prompt}
        """
    else:
        context = f"User: {prompt}"

    with st.chat_message("assistant"):
        response_text = ""

        try:
            with st.status(
                "ğŸ” åˆ†æä¸­...",
                expanded=False
            ) as status:
                # å‰µå»º ADK è¨Šæ¯
                message = Content(
                    role="user",
                    parts=[Part.from_text(text=context)]
                )

                # åŸ·è¡Œ agent
                async def run_agent():
                    response = ""
                    async for event in runner.run_async(
                        user_id="streamlit_user",
                        session_id=st.session_state.adk_session_id,
                        new_message=message
                    ):
                        if (event.content and
                            event.content.parts):
                            for part in event.content.parts:
                                if part.text:
                                    response += part.text
                    return response

                response_text = asyncio.run(run_agent())
                status.update(
                    label="âœ… å®Œæˆ",
                    state="complete",
                    expanded=False
                )

        except Exception as e:
            response_text = f"âŒ Error: {str(e)}"
            st.error(response_text)

        st.markdown(response_text)
        st.session_state.messages.append({
            "role": "assistant",
            "content": response_text
        })
```

**èˆ‡ Level 2 çš„ä¸»è¦å€åˆ¥**ï¼š

- âœ“ ä½¿ç”¨ ADK Agent è€Œéç›´æ¥ API
- âœ“ ADK runner ç·¨æ’å·¥å…·å‘¼å«
- âœ“ å·¥å…·ç”± agent è‡ªå‹•å‘¼å«
- âœ“ æ­£ç¢ºçš„ async/await æ¨¡å¼
- âœ“ ç”Ÿç”¢å°±ç·’çš„éŒ¯èª¤è™•ç†
- âœ“ çµæ§‹åŒ–çš„ Content å’Œ Part ç‰©ä»¶

---

## é€²éšï¼šä½¿ç”¨ ADK çš„å¤š Agent ç³»çµ± (Multi-Agent Systems with ADK)

ADK çš„çœŸæ­£å¨åŠ›ä¾†è‡ª **å¤š Agent å”ä½œ**ã€‚è®“æˆ‘å€‘æ§‹å»ºä¸€å€‹å…·æœ‰å°ˆé–€ agents çš„ç³»çµ±ï¼š

### æ¶æ§‹ï¼šåˆ†æ Agent + è¦–è¦ºåŒ– Agent

```mermaid
graph TD
    Input[ä½¿ç”¨è€…è¼¸å…¥]

    subgraph AnalysisAgent [åˆ†æ Agent]
        direction TB
        Tool1[analyze_column]
        Tool2[calculate_correlation]
        Tool3[filter_data]
    end

    subgraph VisAgent [è¦–è¦ºåŒ– Agent]
        direction TB
        Feature1[BuiltInCodeExecutor]
        Feature2[ç”Ÿæˆ Python ç¨‹å¼ç¢¼]
        Feature3[å®‰å…¨åŸ·è¡Œ]
    end

    Input -->  AnalysisAgent
    Input --> VisAgent

    AnalysisAgent --> |å›æ‡‰æ´å¯Ÿ|Response[å›æ‡‰çµåˆå…©è€…:<br/>- ä¾†è‡ªåˆ†æ Agent çš„æ´å¯Ÿ<br/>- ä¾†è‡ªè¦–è¦ºåŒ– Agent çš„åœ–è¡¨]
    VisAgent --> |å›æ‡‰åœ–è¡¨|Response
```

### æ­¥é©Ÿ 1ï¼šå‰µå»ºè¦–è¦ºåŒ– Agent

**æª”æ¡ˆ**ï¼š`data_analysis_agent/visualization_agent.py`

```python
"""
è¦–è¦ºåŒ– Agent - é€šéç¨‹å¼ç¢¼åŸ·è¡Œç”Ÿæˆå‹•æ…‹åœ–è¡¨
ä½¿ç”¨ ADK çš„ BuiltInCodeExecutor å®‰å…¨é‹è¡Œ Python
"""

from google.adk.agents import Agent
from google.adk.code_executors import BuiltInCodeExecutor


code_executor = BuiltInCodeExecutor()

visualization_agent = Agent(
    name="visualization_agent",
    model="gemini-2.0-flash",
    description="ç”Ÿæˆæ•¸æ“šè¦–è¦ºåŒ–",
    instruction="""ä½ æ˜¯ä¸€ä½å°ˆå®¶æ•¸æ“šè¦–è¦ºåŒ–å°ˆå®¶ã€‚
    ä½ çš„è§’è‰²ï¼šå‰µå»ºæ¸…æ™°ã€è¨Šæ¯è±å¯Œçš„è¦–è¦ºåŒ–ï¼Œå¹«åŠ©ä½¿ç”¨è€…ç†è§£ä»–å€‘çš„æ•¸æ“šã€‚

    **é—œéµ**ï¼šä½ å¿…é ˆç”Ÿæˆ Python ç¨‹å¼ç¢¼ï¼Œè©²ç¨‹å¼ç¢¼ï¼š
    1. å¾æä¾›çš„ CSV æ•¸æ“šè¼‰å…¥ DataFrame
    2. ä½¿ç”¨ matplotlib/plotly å‰µå»ºè¦–è¦ºåŒ–
    3. å„²å­˜æˆ–å›å‚³åœ–è¡¨

**æ•¸æ“šè¼‰å…¥æ¨¡å¼**ï¼š
```python
import pandas as pd
from io import StringIO
csv_data = '''[CSV data from context]'''
df = pd.read_csv(StringIO(csv_data))
```

**è¦–è¦ºåŒ–ç¯„ä¾‹**ï¼š

```python
import matplotlib.pyplot as plt
plt.figure(figsize=(12, 6))
plt.hist(df['column_name'], bins=30)
plt.title('Distribution of column_name')
plt.show()
```

ç•¶è¢«è¦æ±‚é€²è¡Œè¦–è¦ºåŒ–æ™‚ï¼š

1. ä¸è¦å•æ¾„æ¸…å•é¡Œ
2. å¾ CSV è¼‰å…¥ DataFrame
3. ç«‹å³ç”Ÿæˆ Python ç¨‹å¼ç¢¼
4. é¸æ“‡é©ç•¶çš„åœ–è¡¨é¡å‹
5. å›å‚³å¯ç™¼å¸ƒçš„è¦–è¦ºåŒ–""",
   code_executor=code_executor, # å•Ÿç”¨ç¨‹å¼ç¢¼åŸ·è¡Œï¼
   )

### æ­¥é©Ÿ 2ï¼šæ›´æ–°ä¸» Agent æª”æ¡ˆ
**æª”æ¡ˆ**ï¼š`data_analysis_agent/agent.py`
```python
"""
Root Agent - åœ¨åˆ†æå’Œè¦–è¦ºåŒ– agents ä¹‹é–“è·¯ç”±
"""

from typing import Any, Dict
from google.adk.agents import Agent
from google.adk.tools.agent_tool import AgentTool

# åŒ¯å…¥å°ˆé–€ agents
from .visualization_agent import visualization_agent


def analyze_column(column_name: str, analysis_type: str) -> Dict[str, Any]:
    """åˆ†æä¸€å€‹æ¬„ä½ã€‚"""
    return {
        "status": "success",
        "report": f"Analysis of {column_name}: {analysis_type}",
        "column_name": column_name,
        "analysis_type": analysis_type
    }


def calculate_correlation(column1: str, column2: str) -> Dict[str, Any]:
    """è¨ˆç®—ç›¸é—œæ€§ã€‚"""
    return {
        "status": "success",
        "report": f"Correlation between {column1} and {column2}",
        "column1": column1,
        "column2": column2
    }


def filter_data(column: str, operator: str, value: str) -> Dict[str, Any]:
    """éæ¿¾æ•¸æ“šé›†ã€‚"""
    return {
        "status": "success",
        "report": f"Filter: {column} {operator} {value}",
        "column": column,
        "operator": operator,
        "value": value
    }


# Root analysis agent
root_agent = Agent(
    name="data_analysis_agent",
    model="gemini-2.0-flash",
    description="å¸¶æœ‰å·¥å…·çš„æ•¸æ“šåˆ†æ",
    instruction="""ä½ æ˜¯ä¸€ä½æ•¸æ“šåˆ†æå¸«ã€‚å¹«åŠ©ä½¿ç”¨è€…ï¼š
    1. ç†è§£ä»–å€‘çš„æ•¸æ“š
    2. å°‹æ‰¾æ¨¡å¼å’Œç›¸é—œæ€§
    3. è­˜åˆ¥å•é¡Œå’Œç•°å¸¸
    4. ç²å¾—å¯åŸ·è¡Œçš„æ´å¯Ÿ

    é©ç•¶æ™‚ä½¿ç”¨å·¥å…·ä¾†åˆ†ææ•¸æ“šã€‚""",
    tools=[analyze_column, calculate_correlation, filter_data]
)
```

### æ­¥é©Ÿ 3ï¼šæ›´æ–° Streamlit ä»¥æ”¯æ´è¦–è¦ºåŒ–

**æª”æ¡ˆ**ï¼š`app.py` (ä¿®æ”¹ agent åŸ·è¡Œéƒ¨åˆ†)

```python
# åœ¨æ‚¨çš„èŠå¤©è¼¸å…¥è™•ç†å¸¸å¼ä¸­ï¼Œagent åŸ·è¡Œå¾Œï¼š

async def run_analysis():
    """åŸ·è¡Œåˆ†æ agent ä¸¦å–å¾—å›æ‡‰ã€‚"""
    message = Content(
        role="user",
        parts=[Part.from_text(text=context)]
    )

    response = ""
    async for event in runner.run_async(
        user_id="streamlit_user",
        session_id=st.session_state.adk_session_id,
        new_message=message
    ):
        if event.content and event.content.parts:
            for part in event.content.parts:
                if part.text:
                    response += part.text

    return response


async def run_visualization():
    """å¦‚æœä½¿ç”¨è€…è¦æ±‚åœ–è¡¨ï¼ŒåŸ·è¡Œè¦–è¦ºåŒ– agentã€‚"""
    message = Content(
        role="user",
        parts=[Part.from_text(
            text=f"Create a visualization for: {prompt}\n{context}"
        )]
    )

    response = ""
    inline_data = []

    async for event in viz_runner.run_async(
        user_id="streamlit_user",
        session_id=st.session_state.viz_session_id,
        new_message=message
    ):
        if event.content and event.content.parts:
            for part in event.content.parts:
                if part.text:
                    response += part.text
                # è™•ç† inline data (è¦–è¦ºåŒ–)
                if hasattr(part, 'inline_data') and part.inline_data:
                    inline_data.append(part.inline_data)

    return response, inline_data


# åµæ¸¬è¦–è¦ºåŒ–è«‹æ±‚
if any(word in prompt.lower()
       for word in ['chart', 'plot', 'graph', 'visualiz', 'show']):
    response_text, viz_data = asyncio.run(run_visualization())

    # é¡¯ç¤º inline åœ–ç‰‡
    for viz in viz_data:
        try:
            import base64
            from io import BytesIO
            from PIL import Image

            if hasattr(viz, 'data'):
                image_bytes = (
                    base64.b64decode(viz.data)
                    if isinstance(viz.data, str)
                    else viz.data
                )
                image = Image.open(BytesIO(image_bytes))
                st.image(image, use_column_width=True)
        except Exception as e:
            st.warning(f"Could not display viz: {str(e)}")
else:
    response_text = asyncio.run(run_analysis())
```

### ä½•æ™‚ä½¿ç”¨å¤š Agent æ¨¡å¼ (When to Use Multi-Agent Patterns)

| å ´æ™¯ | æ¨¡å¼ | å¥½è™• |
| :--- | :--- | :--- |
| **ç°¡å–®å•ç­”** | å–®ä¸€ agent | å¿«é€Ÿï¼Œç°¡å–® |
| **åˆ†æ + åœ–è¡¨** | å¤š agent | æ›´å¥½çš„åˆ†é›¢ |
| **ç¨‹å¼ç¢¼ç”Ÿæˆ** | Agent + åŸ·è¡Œå™¨ | å®‰å…¨åŸ·è¡Œ |
| **è¤‡é›œå·¥ä½œæµç¨‹** | ç®¡é“ agents | å¯æ“´å±• |

**é—œéµæ´å¯Ÿ**ï¼šå¤š Agent ç³»çµ±è®“æ‚¨ï¼š

- âœ… æŒ‰åŠŸèƒ½å°ˆé–€åŒ– agents
- âœ… è·¨å°ˆæ¡ˆé‡ç”¨ agents
- âœ… ä½¿ç”¨åŸ·è¡Œå™¨å®‰å…¨åŸ·è¡Œç¨‹å¼ç¢¼
- âœ… è™•ç†è¤‡é›œå·¥ä½œæµç¨‹
- âœ… ç¨ç«‹æ–¼å‰ç«¯é€²è¡Œæ“´å±•

---

## æ§‹å»ºæ•¸æ“šåˆ†ææ‡‰ç”¨ç¨‹å¼ (Building a Data Analysis App)

### åŠŸèƒ½ 1ï¼šäº’å‹•å¼è¦–è¦ºåŒ– (Interactive Visualizations)

ä½¿ç”¨ Plotly åŠ å…¥åœ–è¡¨ç”Ÿæˆï¼š

```python
import plotly.express as px

def create_chart(chart_type: str, column_x: str, column_y: str = None,
                 title: str = None) -> dict:
    """å‰µå»ºè¦–è¦ºåŒ–åœ–è¡¨ã€‚"""
    if st.session_state.df is None:
        return {"error": "No dataset loaded"}

    df = st.session_state.df

    try:
        if chart_type == "histogram":
            fig = px.histogram(
                df,
                x=column_x,
                title=title or f"Distribution of {column_x}"
            )

        elif chart_type == "scatter":
            fig = px.scatter(
                df,
                x=column_x,
                y=column_y,
                title=title or f"{column_y} vs {column_x}",
                trendline="ols"
            )

        elif chart_type == "bar":
            if column_y:
                data = df.groupby(column_x)[column_y].sum().reset_index()
                fig = px.bar(data, x=column_x, y=column_y,
                           title=title or f"{column_y} by {column_x}")
            else:
                fig = px.bar(df[column_x].value_counts().head(10),
                           title=title or f"Top 10 {column_x}")

        else:
            return {"error": "Unknown chart type"}

        st.session_state.last_chart = fig
        return {"success": True, "chart_type": chart_type}

    except Exception as e:
        return {"error": f"Chart error: {str(e)}"}
```

**ç”¨æ³•**ï¼š

```python
# åœ¨æ‚¨çš„ assistant å›æ‡‰è™•ç†å¸¸å¼ä¸­
if "show me a histogram" in prompt.lower():
    create_chart("histogram", "price")
    st.plotly_chart(st.session_state.last_chart)
```

---

### åŠŸèƒ½ 2ï¼šäº’å‹•å¼è¦–è¦ºåŒ– (Interactive Visualizations)

åŠ å…¥åœ–è¡¨ç”Ÿæˆï¼š

```python
def create_chart(chart_type: str, column_x: str, column_y: str = None, title: str = None) -> dict:
    """
    å‰µå»ºè¦–è¦ºåŒ–åœ–è¡¨ã€‚

    Args:
        chart_type: åœ–è¡¨é¡å‹ (bar, line, scatter, histogram, box)
        column_x: X è»¸æ¬„ä½
        column_y: Y è»¸æ¬„ä½ (æŸäº›ç›´æ–¹åœ–å¯é¸)
        title: åœ–è¡¨æ¨™é¡Œ

    Returns:
        åŒ…å«åœ–è¡¨æ•¸æ“šæˆ–éŒ¯èª¤çš„å­—å…¸
    """
    if st.session_state.dataframe is None:
        return {"error": "No dataset loaded"}

    df = st.session_state.dataframe

    # å¦‚æœæœ‰çš„è©±ï¼Œä½¿ç”¨éæ¿¾å¾Œçš„æ•¸æ“š
    if st.session_state.filtered_dataframe is not None:
        df = st.session_state.filtered_dataframe

    try:
        if chart_type == "histogram":
            if column_x not in df.columns:
                return {"error": f"Column '{column_x}' not found"}

            fig = px.histogram(
                df,
                x=column_x,
                title=title or f"Distribution of {column_x}"
            )

        elif chart_type == "bar":
            if column_x not in df.columns:
                return {"error": f"Column '{column_x}' not found"}

            # ç‚ºé•·æ¢åœ–èšåˆæ•¸æ“š
            if column_y:
                chart_data = df.groupby(column_x)[column_y].sum().reset_index()
                fig = px.bar(
                    chart_data,
                    x=column_x,
                    y=column_y,
                    title=title or f"{column_y} by {column_x}"
                )
            else:
                value_counts = df[column_x].value_counts().head(10)
                fig = px.bar(
                    x=value_counts.index,
                    y=value_counts.values,
                    title=title or f"Top 10 {column_x}",
                    labels={"x": column_x, "y": "Count"}
                )

        elif chart_type == "scatter":
            if not column_y:
                return {"error": "Scatter plot requires both x and y columns"}

            if column_x not in df.columns or column_y not in df.columns:
                return {"error": "Column not found"}

            fig = px.scatter(
                df,
                x=column_x,
                y=column_y,
                title=title or f"{column_y} vs {column_x}",
                trendline="ols"
            )

        elif chart_type == "box":
            if column_x not in df.columns:
                return {"error": f"Column '{column_x}' not found"}

            fig = px.box(
                df,
                y=column_x,
                title=title or f"Distribution of {column_x}"
            )

        elif chart_type == "line":
            if not column_y:
                return {"error": "Line plot requires both x and y columns"}

            if column_x not in df.columns or column_y not in df.columns:
                return {"error": "Column not found"}

            fig = px.line(
                df,
                x=column_x,
                y=column_y,
                title=title or f"{column_y} over {column_x}"
            )

        else:
            return {"error": "Unknown chart type"}

        # å°‡åœ–è¡¨å„²å­˜åœ¨ session state ä¸­ä»¥ä¾›é¡¯ç¤º
        st.session_state.last_chart = fig

        return {
            "success": True,
            "chart_type": chart_type,
            "description": f"Created {chart_type} chart with {len(df)} data points"
        }

    except Exception as e:
        return {"error": f"Chart error: {str(e)}"}

# åŠ å…¥åˆ° agent å·¥å…·
FunctionDeclaration(
    name="create_chart",
    description="Create a visualization chart from the dataset",
    parameters={
        "type": "object",
        "properties": {
            "chart_type": {
                "type": "string",
                "description": "Type of chart to create",
                "enum": ["bar", "line", "scatter", "histogram", "box"]
            },
            "column_x": {
                "type": "string",
                "description": "Column for x-axis"
            },
            "column_y": {
                "type": "string",
                "description": "Column for y-axis (optional for some chart types)"
            },
            "title": {
                "type": "string",
                "description": "Chart title"
            }
        },
        "required": ["chart_type", "column_x"]
    }
)

# æ›´æ–°å·¥å…·å°æ˜ 
TOOLS = {
    "analyze_column": analyze_column,
    "calculate_correlation": calculate_correlation,
    "filter_data": filter_data,
    "create_chart": create_chart
}

# åœ¨èŠå¤©ä¸­é¡¯ç¤ºåœ–è¡¨
for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

        # æª¢æŸ¥æ˜¯å¦æ‡‰åœ¨æ­¤è¨Šæ¯å¾Œé¡¯ç¤ºåœ–è¡¨
        if message["role"] == "assistant" and "last_chart" in st.session_state:
            st.plotly_chart(st.session_state.last_chart, use_container_width=True)
            # é¡¯ç¤ºå¾Œæ¸…é™¤åœ–è¡¨
            del st.session_state.last_chart
```

**è©¦è©¦çœ‹ï¼š**
- `"å‰µå»º price æ¬„ä½çš„ç›´æ–¹åœ–"`
- `"é¡¯ç¤º price èˆ‡ sales çš„æ•£ä½ˆåœ–"`
- `"è£½ä½œå„ category çš„ revenue é•·æ¢åœ–"`

æ¼‚äº®çš„åœ–è¡¨æœƒå…§åµŒé¡¯ç¤ºï¼ ğŸ“ˆ

---

## ADK Runner èˆ‡ Streamlit æ•´åˆ (ADK Runner Integration with Streamlit)

ç¾åœ¨è®“æˆ‘å€‘æ·±å…¥äº†è§£å¦‚ä½•å°‡ ADK Runners èˆ‡ Streamlit çš„åŸ·è¡Œæ¨¡å‹æ­£ç¢ºæ•´åˆã€‚

### ç†è§£ Session ç®¡ç† (Understanding Session Management)

ADK Runners éœ€è¦ Session ç®¡ç†ä¾†é€²è¡Œæœ‰ç‹€æ…‹çš„å°è©±ï¼š

```python
from google.adk.runners import Runner
from google.adk.sessions import InMemorySessionService
import asyncio
import uuid

# ===== è¨­å®š =====

# é¸é … 1ï¼šè¨˜æ†¶é«”å…§ Sessions (é–‹ç™¼ç”¨)
session_service = InMemorySessionService()

# é¸é … 2ï¼šæŒä¹…åŒ– Sessions (ç”Ÿç”¢ç”¨)
# from google.cloud import firestore
# session_service = FirestoreSessionService(db)

runner = Runner(
    agent=root_agent,
    app_name="my_analysis_app",
    session_service=session_service
)

# ===== STREAMLIT æ•´åˆ =====

@st.cache_resource
def get_runner_and_service():
    """å¿«å– runner å’Œ session serviceã€‚"""
    session_service = InMemorySessionService()
    runner = Runner(
        agent=root_agent,
        app_name="data_analysis_assistant",
        session_service=session_service,
    )
    return runner, session_service


runner, session_service = get_runner_and_service()

# é¦–æ¬¡è¼‰å…¥æ™‚åˆå§‹åŒ– session
if "adk_session_id" not in st.session_state:
    async def create_session():
        session = await session_service.create_session(
            app_name="data_analysis_assistant",
            user_id="streamlit_user"
        )
        return session.id

    st.session_state.adk_session_id = asyncio.run(create_session())
```

### Async åŸ·è¡Œæ¨¡å¼ (Async Execution Pattern)

ADK agents æ˜¯ async å„ªå…ˆçš„ã€‚ä»¥ä¸‹æ˜¯å¦‚ä½•åœ¨ Streamlit ä¸­æ­£ç¢ºåŸ·è¡Œå®ƒå€‘ï¼š

```python
from google.genai.types import Content, Part
import asyncio

async def run_agent_query(message_text: str) -> str:
    """åŸ·è¡Œ agent æŸ¥è©¢ä¸¦å›å‚³å›æ‡‰ã€‚"""

    # å‰µå»ºçµæ§‹åŒ–è¨Šæ¯
    message = Content(
        role="user",
        parts=[Part.from_text(text=message_text)]
    )

    # æ”¶é›†å›æ‡‰
    response = ""

    # åŸ·è¡Œ agent
    async for event in runner.run_async(
        user_id="streamlit_user",
        session_id=st.session_state.adk_session_id,
        new_message=message
    ):
        # è™•ç†ä¸²æµäº‹ä»¶
        if event.content and event.content.parts:
            for part in event.content.parts:
                # è™•ç†æ–‡å­—å›æ‡‰
                if part.text:
                    response += part.text

                # è™•ç† inline data (åœ–ç‰‡/åœ–è¡¨)
                if hasattr(part, 'inline_data') and part.inline_data:
                    st.image(part.inline_data.data)

                # è™•ç†ç¨‹å¼ç¢¼åŸ·è¡Œçµæœ
                if hasattr(part, 'code_execution_result'):
                    result = part.code_execution_result
                    if result.outcome == "SUCCESS":
                        st.success(f"Code executed: {result.output}")

    return response


# åœ¨æ‚¨çš„èŠå¤©è™•ç†å¸¸å¼ä¸­
if prompt := st.chat_input("Ask..."):
    with st.chat_message("assistant"):
        with st.status("Processing...", expanded=False) as status:
            try:
                # åŸ·è¡Œ async agent
                response = asyncio.run(run_agent_query(prompt))
                status.update(label="âœ… Done", state="complete")
            except Exception as e:
                status.update(label="âŒ Error", state="error")
                st.error(str(e))
                response = f"Error: {str(e)}"

        st.markdown(response)
```

### å¿«å–æœ€ä½³å¯¦è¸ (Caching Best Practices)

å„ªåŒ– Streamlit + ADK æ•ˆèƒ½ï¼š

```python
import hashlib

# å¿«å– agent åŸ·è¡Œçµæœ
@st.cache_data
def cached_agent_run(
    prompt: str,
    df_hash: str,
    _runner
) -> str:
    """æ ¹æ“šè¼¸å…¥é›œæ¹Šå¿«å– agent å›æ‡‰ã€‚"""
    return asyncio.run(run_agent_query(prompt))


# åœ¨æ‚¨çš„è™•ç†å¸¸å¼ä¸­
if st.session_state.df is not None:
    # å‰µå»º dataframe çš„é›œæ¹Š (å¿«å–éµ)
    df_hash = hashlib.md5(
        st.session_state.df.to_json().encode()
    ).hexdigest()

    # ä½¿ç”¨å¿«å–åŸ·è¡Œ
    response = cached_agent_run(
        prompt=prompt,
        df_hash=df_hash,
        _runner=runner  # åº•ç·šé˜²æ­¢å¿«å–
    )
```

### éŒ¯èª¤è™•ç† (Error Handling)

ADK Runner æ“ä½œéœ€è¦å¼·å¤§çš„éŒ¯èª¤è™•ç†ï¼š

```python
from google.adk.runners import TimeoutError
from google.genai import APIError

async def run_agent_safely(message_text: str) -> tuple[str, bool]:
    """å®‰å…¨åœ°åŸ·è¡Œ agent ä¸¦è™•ç†éŒ¯èª¤ã€‚

    Returns:
        (response_text, success: bool)
    """
    try:
        message = Content(
            role="user",
            parts=[Part.from_text(text=message_text)]
        )

        response = ""

        async for event in runner.run_async(
            user_id="streamlit_user",
            session_id=st.session_state.adk_session_id,
            new_message=message,
            timeout=30  # 30 ç§’é€¾æ™‚
        ):
            if event.content and event.content.parts:
                for part in event.content.parts:
                    if part.text:
                        response += part.text

        return response, True

    except TimeoutError:
        return (
            "â±ï¸ Request timed out. Try a simpler query.",
            False
        )
    except APIError as e:
        return (
            f"âŒ API Error: {str(e)}",
            False
        )
    except Exception as e:
        return (
            f"âŒ Unexpected error: {type(e).__name__}: {str(e)}",
            False
        )


# ç”¨æ³•
response, success = asyncio.run(run_agent_safely(prompt))

if not success:
    st.error(response)
else:
    st.markdown(response)
```

### ç‹€æ…‹æŒä¹…åŒ–æ¨¡å¼ (State Persistence Patterns)

æ­£ç¢ºå„²å­˜å°è©±æ­·å²ï¼š

```python
# é¸é … 1ï¼šStreamlit Session State
# åœ¨å–®ä¸€ç€è¦½å™¨ session å…§æŒä¹…åŒ–
if "messages" not in st.session_state:
    st.session_state.messages = []

st.session_state.messages.append({
    "role": "user",
    "content": prompt
})

# é¸é … 2ï¼šè³‡æ–™åº«æŒä¹…åŒ–
# è·¨ session ç‚ºä½¿ç”¨è€…æŒä¹…åŒ–
import json
from datetime import datetime

def save_to_database(message):
    """å°‡è¨Šæ¯å„²å­˜åˆ° Firestore æˆ–é¡ä¼¼æœå‹™ã€‚"""
    db.collection("conversations").add({
        "user_id": "streamlit_user",
        "session_id": st.session_state.adk_session_id,
        "timestamp": datetime.now(),
        "message": message
    })

# é¸é … 3ï¼šå¤š Session ç‹€æ…‹
# æ¯å€‹åˆ†é ä¸åŒçš„å°è©±
if "tab_sessions" not in st.session_state:
    st.session_state.tab_sessions = {}

active_tab = st.tabs(["Chat", "Analysis", "Visualizations"])[0]
if "current_tab" not in st.session_state:
    st.session_state.current_tab = "Chat"

# æ¯å€‹åˆ†é å‰µå»ºç¨ç«‹ session
tab_key = f"session_{st.session_state.current_tab}"
if tab_key not in st.session_state:
    session = asyncio.run(session_service.create_session(
        app_name="multi_tab_app",
        user_id="streamlit_user"
    ))
    st.session_state[tab_key] = session.id
```

### æ•ˆèƒ½å„ªåŒ– (Performance Optimization)

é—œéµå„ªåŒ–æ¨¡å¼ï¼š

```python
# 1. å°æ–¼é•·å›æ‡‰ä½¿ç”¨ä¸²æµ
async def stream_agent_response():
    """åœ¨å€å¡Šåˆ°é”æ™‚ä¸²æµå›æ‡‰ã€‚"""
    message_placeholder = st.empty()
    full_response = ""

    async for event in runner.run_async(...):
        if event.content and event.content.parts:
            for part in event.content.parts:
                if part.text:
                    full_response += part.text
                    # å³æ™‚æ›´æ–° UI
                    message_placeholder.markdown(
                        full_response + " â–Œ"  # é–ƒçˆæ¸¸æ¨™
                    )

    return full_response


# 2. æ‰¹æ¬¡è™•ç†å¤šå€‹æŸ¥è©¢
async def batch_queries(queries: list[str]) -> list[str]:
    """æœ‰æ•ˆç‡åœ°åŸ·è¡Œå¤šå€‹ agent æŸ¥è©¢ã€‚"""
    tasks = [
        run_agent_query(q)
        for q in queries
    ]
    return await asyncio.gather(*tasks)


# 3. å¯¦ä½œæŒ‡æ•¸å›é€€ (Exponential Backoff)
async def run_with_retry(
    message: str,
    max_retries: int = 3
) -> str:
    """å¸¶æœ‰è‡ªå‹•é‡è©¦åœ°åŸ·è¡Œ agentã€‚"""
    for attempt in range(max_retries):
        try:
            return asyncio.run(run_agent_query(message))
        except Exception as e:
            if attempt == max_retries - 1:
                raise

            wait_time = 2 ** attempt  # æŒ‡æ•¸å›é€€
            st.warning(f"Retry in {wait_time}s...")
            await asyncio.sleep(wait_time)
```

---

## é€²éšåŠŸèƒ½ (Advanced Features)

### åŠŸèƒ½ 1ï¼šå¤šæ•¸æ“šé›†æ”¯æ´ (Multi-Dataset Support)

å…è¨±ä½¿ç”¨è€…ä½¿ç”¨å¤šå€‹æ•¸æ“šé›†ï¼š

```python
# å¢å¼·çš„ session state
if "datasets" not in st.session_state:
    st.session_state.datasets = {}

if "active_dataset" not in st.session_state:
    st.session_state.active_dataset = None

# å´é‚Šæ¬„
with st.sidebar:
    st.header("ğŸ“ Datasets")

    # æª”æ¡ˆä¸Šå‚³å™¨
    uploaded_file = st.file_uploader(
        "Upload CSV",
        type=["csv"],
        key="uploader"
    )

    if uploaded_file is not None:
        dataset_name = st.text_input(
            "Dataset name",
            value=uploaded_file.name.replace(".csv", "")
        )

        if st.button("Load Dataset"):
            try:
                df = pd.read_csv(uploaded_file)
                st.session_state.datasets[dataset_name] = df
                st.session_state.active_dataset = dataset_name
                st.success(f"âœ… Loaded '{dataset_name}'")
                st.rerun()
            except Exception as e:
                st.error(f"Error: {e}")

    # æ•¸æ“šé›†é¸æ“‡å™¨
    if st.session_state.datasets:
        st.subheader("Active Dataset")
        active = st.selectbox(
            "Select dataset",
            options=list(st.session_state.datasets.keys()),
            index=list(st.session_state.datasets.keys()).index(
                st.session_state.active_dataset
            ) if st.session_state.active_dataset else 0
        )
        st.session_state.active_dataset = active

        # é¡¯ç¤ºé—œæ–¼æ´»å‹•æ•¸æ“šé›†çš„è³‡è¨Š
        df = st.session_state.datasets[active]
        st.write(f"**Rows:** {len(df)}")
        st.write(f"**Columns:** {len(df.columns)}")

        # é è¦½
        with st.expander("Preview"):
            st.dataframe(df.head(), use_container_width=True)

# æ›´æ–°å·¥å…·ä»¥ä½¿ç”¨æ´»å‹•æ•¸æ“šé›†
def get_active_dataframe():
    """å–å¾—ç•¶å‰æ´»å‹•çš„æ•¸æ“šé›†ã€‚"""
    if st.session_state.active_dataset and st.session_state.active_dataset in st.session_state.datasets:
        return st.session_state.datasets[st.session_state.active_dataset]
    return None

# æ›´æ–°å·¥å…·å‡½æ•¸ä»¥ä½¿ç”¨ get_active_dataframe()
```

---

### åŠŸèƒ½ 2ï¼šåŒ¯å‡ºåˆ†æçµæœ (Export Analysis Results)

è®“ä½¿ç”¨è€…ä¸‹è¼‰åˆ†æçµæœï¼š

```python
import json
from datetime import datetime

# åœ¨å´é‚Šæ¬„åŠ å…¥åŒ¯å‡ºæŒ‰éˆ•
if st.session_state.messages:
    st.sidebar.markdown("---")
    st.sidebar.subheader("ğŸ’¾ Export")

    if st.sidebar.button("Export Conversation"):
        # å‰µå»ºåŒ¯å‡ºæ•¸æ“š
        export_data = {
            "timestamp": datetime.now().isoformat(),
            "dataset": st.session_state.active_dataset,
            "conversation": st.session_state.messages
        }

        # è½‰æ›ç‚º JSON
        json_str = json.dumps(export_data, indent=2)

        # ä¸‹è¼‰æŒ‰éˆ•
        st.sidebar.download_button(
            label="Download JSON",
            data=json_str,
            file_name=f"analysis_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json",
            mime="application/json"
        )

    # åŒ¯å‡ºéæ¿¾å¾Œçš„æ•¸æ“š
    if st.session_state.filtered_dataframe is not None:
        if st.sidebar.button("Export Filtered Data"):
            csv = st.session_state.filtered_dataframe.to_csv(index=False)

            st.sidebar.download_button(
                label="Download CSV",
                data=csv,
                file_name=f"filtered_data_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv",
                mime="text/csv"
            )
```

---

### åŠŸèƒ½ 3ï¼šæ•ˆèƒ½å¿«å– (Caching for Performance)

ä½¿ç”¨ Streamlit å¿«å–é€²è¡Œå„ªåŒ–ï¼š

```python
# å¿«å–æ˜‚è²´è¨ˆç®—
@st.cache_data
def load_dataset(file):
    """è¼‰å…¥ä¸¦å¿«å–æ•¸æ“šé›†ã€‚"""
    return pd.read_csv(file)

@st.cache_data
def compute_statistics(df_hash, column_name):
    """å¿«å–æ¬„ä½çµ±è¨ˆæ•¸æ“šã€‚"""
    # df_hash ç”¨ä½œå¿«å–éµ
    df = st.session_state.dataframe
    return df[column_name].describe().to_dict()

# å¿«å–è¦–è¦ºåŒ–
@st.cache_data
def create_cached_chart(chart_type, column_x, column_y, data_hash):
    """å¿«å–åœ–è¡¨ç”Ÿæˆã€‚"""
    df = st.session_state.dataframe
    # ... å‰µå»ºåœ–è¡¨
    return fig

# åœ¨å·¥å…·ä¸­ä½¿ç”¨
def analyze_column(column_name, analysis_type):
    df = st.session_state.dataframe

    # ä½¿ç”¨å¿«å–è¨ˆç®—
    df_hash = hash(df.to_json())  # ç°¡å–®é›œæ¹Šç”¨æ–¼å¿«å–
    stats = compute_statistics(df_hash, column_name)

    return stats
```

é€™ä½¿å¾—é‡è¤‡æŸ¥è©¢è®Šå¾—æ¥µå¿«ï¼ âš¡

---

## ç”Ÿç”¢éƒ¨ç½² (Production Deployment)

### é¸é … 1ï¼šStreamlit Cloud (æœ€ç°¡å–®)

#### æ­¥é©Ÿ 1ï¼šæº–å‚™ Repository

```bash
# å‰µå»º requirements.txt
cat > requirements.txt << EOF
streamlit==1.39.0
google-genai==1.41.0
pandas==2.2.0
plotly==5.24.0
EOF

# å‰µå»º .streamlit/config.toml ä»¥ç²å¾—æ›´å¥½çš„ UX
mkdir .streamlit
cat > .streamlit/config.toml << EOF
[theme]
primaryColor = "#FF4B4B"
backgroundColor = "#FFFFFF"
secondaryBackgroundColor = "#F0F2F6"
textColor = "#262730"
font = "sans serif"

[server]
maxUploadSize = 200
EOF

# å‰µå»º .streamlit/secrets.toml ç”¨æ–¼ API é‡‘é‘°
cat > .streamlit/secrets.toml << EOF
GOOGLE_API_KEY = "your_api_key_here"
EOF

# åŠ å…¥åˆ° .gitignore
echo ".streamlit/secrets.toml" >> .gitignore
```

**æ›´æ–° `app.py` ä»¥ä½¿ç”¨ secrets**ï¼š

#### æ­¥é©Ÿ 2ï¼šéƒ¨ç½²

```python
import os
import streamlit as st

# å¾ secrets æˆ– environment ç²å– API é‡‘é‘°
api_key = st.secrets.get("GOOGLE_API_KEY") or os.getenv("GOOGLE_API_KEY")

if not api_key:
    st.error("Please configure GOOGLE_API_KEY in Streamlit secrets")
    st.stop()

client = genai.Client(
    api_key=api_key,
    http_options={'api_version': 'v1alpha'}
)
```

#### æ­¥é©Ÿ 2ï¼šéƒ¨ç½² (Streamlit Cloud)

1. æ¨é€ç¨‹å¼ç¢¼åˆ° GitHub
2. å‰å¾€ [share.streamlit.io](https://share.streamlit.io)
3. é»æ“Š "New app"
4. é¸æ“‡æ‚¨çš„ repository
5. è¨­å®šä¸»è¦æª”æ¡ˆï¼š`app.py`
6. åŠ å…¥ secretï¼š`GOOGLE_API_KEY = your_key`
7. é»æ“Š "Deploy"ï¼

**æ‚¨çš„æ‡‰ç”¨ç¨‹å¼å·²ä¸Šç·šï¼** ğŸ‰

URL: `https://your-app.streamlit.app`

---

### é¸é … 2ï¼šGoogle Cloud Run

ç²å¾—æ›´å¤šæ§åˆ¶æ¬Šå’Œè‡ªå®šç¾©ç¶²åŸŸï¼š

#### æ­¥é©Ÿ 1ï¼šå‰µå»º Dockerfile

```dockerfile
FROM python:3.11-slim

WORKDIR /app

# å®‰è£ä¾è³´
COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt

# è¤‡è£½æ‡‰ç”¨ç¨‹å¼
COPY app.py .
COPY .streamlit/ .streamlit/

# æš´éœ² Streamlit åŸ 
EXPOSE 8501

# å¥åº·æª¢æŸ¥
HEALTHCHECK CMD curl --fail http://localhost:8501/_stcore/health || exit 1

# åŸ·è¡Œæ‡‰ç”¨ç¨‹å¼
CMD ["streamlit", "run", "app.py", "--server.port=8501", "--server.address=0.0.0.0"]
```

#### æ­¥é©Ÿ 2ï¼šéƒ¨ç½² (Cloud Run)

```bash
# å»ºç½®ä¸¦éƒ¨ç½²
gcloud run deploy data-analysis-agent \
  --source=. \
  --region=us-central1 \
  --allow-unauthenticated \
  --set-env-vars="GOOGLE_API_KEY=your_api_key" \
  --port=8501

# è¼¸å‡ºï¼š
# Service URL: https://data-analysis-agent-abc123.run.app
```

#### æ­¥é©Ÿ 3ï¼šè‡ªå®šç¾©ç¶²åŸŸ (å¯é¸)

```bash
# å°æ˜ è‡ªå®šç¾©ç¶²åŸŸ
gcloud run domain-mappings create \
  --service=data-analysis-agent \
  --domain=analyze.yourdomain.com \
  --region=us-central1
```

---

### ç”Ÿç”¢æœ€ä½³å¯¦è¸ (Production Best Practices)

#### 1. é€Ÿç‡é™åˆ¶ (Rate Limiting)

```python
import time
from collections import defaultdict

# ç°¡å–®é€Ÿç‡é™åˆ¶å™¨
class RateLimiter:
    def __init__(self, max_requests=10, window=60):
        self.max_requests = max_requests
        self.window = window
        self.requests = defaultdict(list)

    def is_allowed(self, user_id):
        now = time.time()
        # æ¸…é™¤èˆŠè«‹æ±‚
        self.requests[user_id] = [
            req_time for req_time in self.requests[user_id]
            if now - req_time < self.window
        ]

        if len(self.requests[user_id]) < self.max_requests:
            self.requests[user_id].append(now)
            return True
        return False

# åœ¨æ‡‰ç”¨ç¨‹å¼ä¸­ä½¿ç”¨
rate_limiter = RateLimiter(max_requests=20, window=60)

if prompt := st.chat_input("Ask me..."):
    # ç°¡å–®ä½¿ç”¨è€… ID (ç”Ÿç”¢ç’°å¢ƒä¸­ä½¿ç”¨å¯¦éš›é©—è­‰)
    user_id = st.session_state.get("session_id", "default")

    if not rate_limiter.is_allowed(user_id):
        st.error("Too many requests. Please wait a minute.")
        st.stop()

    # ... è™•ç†è«‹æ±‚
```

#### 2. éŒ¯èª¤è™•ç† (Error Handling)

```python
import logging

# è¨­å®šæ—¥èªŒ
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

# åŒ…è£ agent å‘¼å«
try:
    # å¸¶æœ‰ InMemoryRunner çš„æ­£ç¢º ADK åŸ·è¡Œæ¨¡å¼
    import asyncio
    from google.genai import types

    async def get_response(message: str):
        """åœ¨ async ä¸Šä¸‹æ–‡ä¸­åŸ·è¡Œ agent çš„è¼”åŠ©å‡½æ•¸ã€‚"""
        new_message = types.Content(role='user', parts=[types.Part(text=message)])

        response_text = ""
        async for event in runner.run_async(
            user_id=st.session_state.get("user_id", "streamlit_user"),
            session_id=st.session_state.session_id,
            new_message=new_message
        ):
            if event.content and event.content.parts:
                response_text += event.content.parts[0].text

        return response_text

    response = asyncio.run(get_response(message))
    # ... è™•ç†å›æ‡‰
except Exception as e:
    logger.error(f"Agent error: {e}", exc_info=True)
    st.error("I encountered an error. Our team has been notified.")

    # ä¸è¦å‘ä½¿ç”¨è€…æš´éœ²å…§éƒ¨éŒ¯èª¤
    if os.getenv("ENVIRONMENT") == "development":
        st.exception(e)
```

#### 3. ç›£æ§ (Monitoring)

```python
from google.cloud import monitoring_v3
import time

def log_metric(metric_name, value):
    """å°‡æŒ‡æ¨™è¨˜éŒ„åˆ° Cloud Monitoringã€‚"""
    if os.getenv("ENVIRONMENT") != "production":
        return

    client = monitoring_v3.MetricServiceClient()
    project_name = f"projects/{os.getenv('GCP_PROJECT')}"

    series = monitoring_v3.TimeSeries()
    series.metric.type = f"custom.googleapis.com/{metric_name}"

    now = time.time()
    seconds = int(now)
    nanos = int((now - seconds) * 10 ** 9)
    interval = monitoring_v3.TimeInterval(
        {"end_time": {"seconds": seconds, "nanos": nanos}}
    )
    point = monitoring_v3.Point(
        {"interval": interval, "value": {"double_value": value}}
    )
    series.points = [point]

    client.create_time_series(name=project_name, time_series=[series])

# åœ¨æ‡‰ç”¨ç¨‹å¼ä¸­ä½¿ç”¨
start_time = time.time()

# æ­£ç¢º ADK åŸ·è¡Œæ¨¡å¼
import asyncio
from google.genai import types

async def get_response(message: str):
    """åœ¨ async ä¸Šä¸‹æ–‡ä¸­åŸ·è¡Œ agent çš„è¼”åŠ©å‡½æ•¸ã€‚"""
    new_message = types.Content(role='user', parts=[types.Part(text=message)])

    response_text = ""
    async for event in runner.run_async(
        user_id=st.session_state.get("user_id", "streamlit_user"),
        session_id=st.session_state.session_id,
        new_message=new_message
    ):
        if event.content and event.content.parts:
            response_text += event.content.parts[0].text

    return response_text

response = asyncio.run(get_response(message))

latency = time.time() - start_time

log_metric("agent_latency", latency)
log_metric("agent_requests", 1)
```

#### 4. Session ç®¡ç† (Session Management)

```python
import uuid

# ç”Ÿæˆå”¯ä¸€ session ID
if "session_id" not in st.session_state:
    st.session_state.session_id = str(uuid.uuid4())

# åœ¨è³‡æ–™åº«ä¸­å„²å­˜ sessions (ä½¿ç”¨ Firestore ç¯„ä¾‹)
from google.cloud import firestore

db = firestore.Client()

def save_session():
    """å°‡ session å„²å­˜åˆ° Firestoreã€‚"""
    doc_ref = db.collection("sessions").document(st.session_state.session_id)
    doc_ref.set({
        "messages": st.session_state.messages,
        "timestamp": firestore.SERVER_TIMESTAMP,
        "dataset": st.session_state.active_dataset
    })

def load_session(session_id):
    """å¾ Firestore è¼‰å…¥ sessionã€‚"""
    doc_ref = db.collection("sessions").document(session_id)
    doc = doc_ref.get()

    if doc.exists:
        data = doc.to_dict()
        st.session_state.messages = data.get("messages", [])
        st.session_state.active_dataset = data.get("dataset")

# è®Šæ›´æ™‚è‡ªå‹•å„²å­˜
if st.session_state.messages:
    save_session()
```

---

## ç–‘é›£æ’è§£ (Troubleshooting)

### å¸¸è¦‹å•é¡Œ (Common Issues)

#### å•é¡Œ 1ï¼š"Please set GOOGLE_API_KEY"

**è§£æ±ºæ–¹æ¡ˆ**ï¼š

```bash
# æœ¬åœ°é–‹ç™¼
export GOOGLE_API_KEY="your_key"
streamlit run app.py

# æˆ–å‰µå»º .streamlit/secrets.toml
echo 'GOOGLE_API_KEY = "your_key"' > .streamlit/secrets.toml
```

---

#### å•é¡Œ 2ï¼šæª”æ¡ˆä¸Šå‚³ç„¡æ•ˆ

**æƒ…å¢ƒ**ï¼š

- ä¸Šå‚³æŒ‰éˆ•æ²’åæ‡‰
- é¡¯ç¤ºæª”æ¡ˆä½†æ•¸æ“šæœªè¼‰å…¥

**è§£æ±ºæ–¹æ¡ˆ**ï¼š

```python
# æª¢æŸ¥æª”æ¡ˆç·¨ç¢¼
uploaded_file = st.file_uploader("Upload CSV", type=["csv"])

if uploaded_file is not None:
    try:
        # å…ˆå˜—è©¦ UTF-8
        df = pd.read_csv(uploaded_file, encoding='utf-8')
    except UnicodeDecodeError:
        # å›é€€åˆ° latin-1
        df = pd.read_csv(uploaded_file, encoding='latin-1')
    except Exception as e:
        st.error(f"Error loading file: {e}")
        st.stop()
```

---

#### å•é¡Œ 3ï¼šAgent æœªä½¿ç”¨å·¥å…·

**æƒ…å¢ƒ**ï¼š

- Agent å›æ‡‰ç± çµ±
- æœªåŸ·è¡Œä»»ä½•å‡½æ•¸å‘¼å«

**è§£æ±ºæ–¹æ¡ˆ**ï¼š

```python
from google.adk.agents import Agent

# é©—è­‰å·¥å…·è¨»å†Š
agent = Agent(
    model="gemini-2.0-flash-exp",
    name="data_analysis_agent",
    instruction="...",
    tools=[analyze_column, calculate_correlation, filter_data, get_dataset_summary]  # âœ… ç›´æ¥å‚³éå‡½æ•¸
)

# ADK è‡ªå‹•è™•ç†å‡½æ•¸å‘¼å«è¨­å®š
# åœ¨ AUTO æ¨¡å¼ä¸‹ï¼Œå·¥å…·é è¨­å•Ÿç”¨

# æª¢æŸ¥å·¥å…·åç¨±æ˜¯å¦èˆ‡å‡½æ•¸åç¨±åŒ¹é…
TOOLS = {
    "analyze_column": analyze_column,  # âœ… å‡½æ•¸åç¨±åŒ¹é…
    "analyzeColumn": analyze_column,   # âŒ åç¨±éŒ¯èª¤
}
```

---

#### å•é¡Œ 4ï¼šåœ–è¡¨ç”Ÿæˆç·©æ…¢

**æƒ…å¢ƒ**ï¼š

- åœ–è¡¨è¼‰å…¥éœ€è¦ 5 ç§’ä»¥ä¸Š
- æ‡‰ç”¨ç¨‹å¼æ„Ÿè¦ºå¡é “

**è§£æ±ºæ–¹æ¡ˆ**ï¼š

```python
# ä½¿ç”¨å¿«å–
@st.cache_data
def create_cached_chart(chart_type, x_col, y_col, data_hash):
    """å¿«å–æ˜‚è²´çš„åœ–è¡¨æ“ä½œã€‚"""
    df = st.session_state.dataframe

    if chart_type == "scatter":
        # å–æ¨£å¤§å‹æ•¸æ“šé›†
        if len(df) > 10000:
            df = df.sample(n=10000)

    fig = px.scatter(df, x=x_col, y=y_col)
    return fig

# ä½¿ç”¨é›œæ¹Šä½œç‚ºå¿«å–éµ
df_hash = hash(df.to_json())  # æˆ–ä½¿ç”¨ df.shape + df.columns
fig = create_cached_chart("scatter", "x", "y", df_hash)
st.plotly_chart(fig)
```

---

#### å•é¡Œ 5ï¼šé‡æ–°æ•´ç†å¾Œ Session State éºå¤±

**æƒ…å¢ƒ**ï¼š

- é é¢é‡æ–°æ•´ç†å¾Œå°è©±æ¶ˆå¤±
- ä¸Šå‚³çš„æ•¸æ“šéºå¤±

**è§£æ±ºæ–¹æ¡ˆ**ï¼š

```python
# é¸é … 1ï¼šä½¿ç”¨æŸ¥è©¢åƒæ•¸ä½œç‚º session ID
import streamlit as st

# å¾ URL ç²å– session ID
query_params = st.query_params
session_id = query_params.get("session", str(uuid.uuid4()))

# è¨­å®šåˆ° URL
st.query_params["session"] = session_id

# å¾è³‡æ–™åº«è¼‰å…¥
load_session(session_id)

# é¸é … 2ï¼šä½¿ç”¨ cookies (éœ€è¦ streamlit-cookies)
# pip install streamlit-cookies-manager
from streamlit_cookies_manager import EncryptedCookieManager

cookies = EncryptedCookieManager(
    prefix="myapp",
    password=os.environ["COOKIE_PASSWORD"]
)

if not cookies.ready():
    st.stop()

# å°‡ session ID å„²å­˜åœ¨ cookie ä¸­
if "session_id" not in cookies:
    cookies["session_id"] = str(uuid.uuid4())
    cookies.save()

session_id = cookies["session_id"]
```
---

### æ‚¨å·²æŒæ¡ Streamlit + ADKï¼ ğŸ‰

æ‚¨ç¾åœ¨çŸ¥é“å¦‚ä½•ï¼š

âœ… ä½¿ç”¨ ADK æ§‹å»ºç´” Python æ•¸æ“šæ‡‰ç”¨ç¨‹å¼
âœ… ç›´æ¥æ•´åˆ agents (ç„¡ HTTP é–‹éŠ·ï¼)
âœ… ä½¿ç”¨ Streamlit å‰µå»ºäº’å‹•å¼èŠå¤©ä»‹é¢
âœ… åŠ å…¥æ•¸æ“šåˆ†æå·¥å…·å’Œè¦–è¦ºåŒ–
âœ… éƒ¨ç½²åˆ° Streamlit Cloud å’Œ Cloud Run
âœ… ä½¿ç”¨å¿«å–å’ŒéŒ¯èª¤è™•ç†é€²è¡Œå„ªåŒ–

### æ¯”è¼ƒæ•´åˆæ–¹æ³• (Compare Integration Approaches)

| åŠŸèƒ½ | Streamlit | Next.js | React Vite |
| :--- | :--- | :--- | :--- |
| **èªè¨€** | åƒ…é™ Python | TypeScript + Python | TypeScript + Python |
| **è¨­å®šæ™‚é–“** | <5 åˆ†é˜ | ~15 åˆ†é˜ | ~10 åˆ†é˜ |
| **æ¶æ§‹** | ç¨‹åºå…§ | HTTP | HTTP |
| **å»¶é²** | ~0ms | ~50ms | ~50ms |
| **è‡ªå®šç¾©** | ä¸­ç­‰ | é«˜ | é«˜ |
| **æ•¸æ“šå·¥å…·** | å„ªç§€ | è‰¯å¥½ | è‰¯å¥½ |
| **æœ€é©åˆ** | æ•¸æ“šæ‡‰ç”¨ç¨‹å¼ | Web æ‡‰ç”¨ç¨‹å¼ | è¼•é‡ç´šæ‡‰ç”¨ç¨‹å¼ |

### é¡å¤–è³‡æº (Additional Resources)

- [Streamlit æ–‡ä»¶](https://docs.streamlit.io)
- [ADK æ–‡ä»¶](https://google.github.io/adk-docs/)
- [Streamlit ç•«å»Š](https://streamlit.io/gallery) - éˆæ„Ÿ
- [Streamlit çµ„ä»¶](https://streamlit.io/components) - æ“´å……åŠŸèƒ½

---

## ç¨‹å¼ç¢¼å¯¦ç¾ (Code Implementation)

- data-analysis-agentï¼š[ç¨‹å¼ç¢¼é€£çµ](../../../python/agents/data-analysis-agent/)