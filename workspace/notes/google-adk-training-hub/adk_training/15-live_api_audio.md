# æ•™å­¸ 15ï¼šLive API èˆ‡é›™å‘ä¸²æµ (Live API & Bidirectional Streaming with Audio)


**æœ¬æ•™å­¸å·²é€²è¡Œç°¡åŒ–ï¼Œå°ˆæ³¨æ–¼ Live API çš„æœ‰æ•ˆæ–¹æ³•ï¼šADK Web ä»‹é¢ã€‚**

**ä¸»è¦æ›´æ–° (2025 å¹´ 1 æœˆ 12 æ—¥)**:
- âœ… **å»ºè­°æ–¹æ³•**: ä½¿ç”¨ `adk web` é€²è¡Œ Live API é›™å‘ä¸²æµ
- âœ… **åŸå› **: `runner.run_live()` éœ€è¦ WebSocket ä¼ºæœå™¨æƒ…å¢ƒ (åœ¨ `adk web` ä¸­é‹ä½œï¼Œè€Œéç¨ç«‹è…³æœ¬)
- âœ… **æ ¸å¿ƒå…ƒä»¶**: ç”¨æ–¼ç¨‹å¼åŒ–ä½¿ç”¨çš„ä»£ç†ç¨‹å¼å®šç¾©å’ŒéŸ³è¨Šå·¥å…·
- âœ… **ç°¡åŒ–**: ç§»é™¤äº†ç„¡æ•ˆçš„ç¨ç«‹ç¤ºç¯„è…³æœ¬
- âœ… **ç„¦é»**: å–®ä¸€æ¸…æ™°è·¯å¾‘ - å•Ÿå‹• ADK ç¶²é ä¼ºæœå™¨ä¸¦ä½¿ç”¨ç€è¦½å™¨ä»‹é¢


**å¿«é€Ÿå…¥é–€**:
```bash
cd tutorial_implementation/tutorial15
make setup  # å®‰è£ä¾è³´é …
make dev    # å•Ÿå‹• ADK ç¶²é ä»‹é¢
# é–‹å•Ÿ http://localhost:8000 ä¸¦é¸æ“‡ 'voice_assistant'
```

**ç›®æ¨™**: æŒæ¡ Live API ä»¥å¯¦ç¾é›™å‘ä¸²æµï¼Œå¾è€Œèˆ‡æ‚¨çš„ AI ä»£ç†ç¨‹å¼é€²è¡Œå³æ™‚èªéŸ³å°è©±ã€éŸ³è¨Šè¼¸å…¥/è¼¸å‡ºä»¥åŠäº’å‹•å¼å¤šæ¨¡æ…‹é«”é©—ã€‚

**å…ˆæ±ºæ¢ä»¶**:

- æ•™å­¸ 01 (Hello World ä»£ç†ç¨‹å¼)
- æ•™å­¸ 14 (ä½¿ç”¨ SSE é€²è¡Œä¸²æµ)
- å° async/await æœ‰åŸºæœ¬äº†è§£
- ç”¨æ–¼éŸ³è¨Šç¯„ä¾‹çš„éº¥å…‹é¢¨å­˜å–æ¬Šé™

**æ‚¨å°‡å­¸åˆ°**:

- ä½¿ç”¨ `StreamingMode.BIDI` å¯¦ç¾é›™å‘ä¸²æµ
- ä½¿ç”¨ `LiveRequestQueue` é€²è¡Œå³æ™‚é€šè¨Š
- è¨­å®šéŸ³è¨Šè¼¸å…¥/è¼¸å‡ºèˆ‡èªéŸ³è¾¨è­˜
- å»ºç«‹èªéŸ³åŠ©ç†
- è™•ç†å½±ç‰‡ä¸²æµ
- äº†è§£ä¸»å‹•æ€§å’Œæƒ…æ„Ÿå°è©±
- Live API æ¨¡å‹é¸æ“‡èˆ‡ç›¸å®¹æ€§

**å®Œæˆæ™‚é–“**: 60-75 åˆ†é˜

---

## ç‚ºä½• Live API å¦‚æ­¤é‡è¦ (Why Live API Matters)

å‚³çµ±çš„ä»£ç†ç¨‹å¼æ˜¯**å›åˆåˆ¶**çš„â€”â€”å‚³é€è¨Šæ¯ï¼Œç­‰å¾…å®Œæ•´å›æ‡‰ã€‚è€Œ **Live API** å‰‡å¯¦ç¾äº†**å³æ™‚ã€é›™å‘**çš„é€šè¨Šï¼š

**å›åˆåˆ¶ (å‚³çµ±)**:

```mermaid
sequenceDiagram
    participant User as ä½¿ç”¨è€…
    participant Agent as ä»£ç†ç¨‹å¼
    User->>Agent: èªªè©± â†’ [ä¸Šå‚³å®Œæ•´éŸ³è¨Š]
    Agent->>Agent: æ€è€ƒ â†’ [è™•ç†å®Œæ•´éŸ³è¨Š]
    Agent-->>User: å›æ‡‰ â†’ [ç”Ÿæˆå®Œæ•´å›æ‡‰]
    User->>Agent: å†æ¬¡èªªè©±...
```

**Live API (é›™å‘)**:

```mermaid
sequenceDiagram
    participant User as ä½¿ç”¨è€…
    participant Agent as ä»£ç†ç¨‹å¼
    User-->>Agent: èªªè©± âŸ· ä»£ç†ç¨‹å¼å³æ™‚è½åˆ°
    Agent-->>User: âŸ· ä»£ç†ç¨‹å¼å¯ä»¥æ‰“æ–·
    Agent-->>User: âŸ· ä»£ç†ç¨‹å¼åœ¨è†è½æ™‚å›æ‡‰
    Note over User, Agent: âŸ· è‡ªç„¶çš„å°è©±æµç¨‹
```

**å„ªé»**:

- ğŸ™ï¸ **å³æ™‚éŸ³è¨Š**: åœ¨æ‚¨èªªè©±æ™‚ä¸²æµéŸ³è¨Š
- ğŸ—£ï¸ **è‡ªç„¶å°è©±**: ä¸­æ–·ã€è¼ªæµç™¼è¨€
- ğŸ­ **æƒ…æ„Ÿå°è©±**: åµæ¸¬èªéŸ³ä¸­çš„æƒ…ç·’
- ğŸ“¹ **å½±ç‰‡ä¸²æµ**: å³æ™‚å½±ç‰‡åˆ†æ
- âš¡ **ä½å»¶é²**: ç«‹å³å›æ‡‰
- ğŸ¤– **ä¸»å‹•æ€§**: ä»£ç†ç¨‹å¼å¯ä»¥ç™¼èµ·å°è©±

---

## å…¥é–€ï¼šADK ç¶²é ä»‹é¢ (Getting Started: ADK Web Interface)

### å»ºè­°åšæ³•
**ADK ç¶²é ä»‹é¢** (`adk web`) æ˜¯å¯¦ç¾ Live API é›™å‘ä¸²æµçš„å»ºè­°ä¸”æœ‰æ•ˆçš„æ–¹æ³•ã€‚æ­¤æ–¹æ³•ï¼š

- âœ… ä½¿ç”¨å®˜æ–¹çš„ `/run_live` WebSocket ç«¯é»
- âœ… æä¾›å®Œæ•´çš„é›™å‘éŸ³è¨Šä¸²æµ
- âœ… å¯ç›´æ¥èˆ‡ç€è¦½å™¨ä»‹é¢æ­é…ä½¿ç”¨
- âœ… åŒ…å«æ‰€æœ‰ ADK ä»£ç†ç¨‹å¼åŠŸèƒ½ (å·¥å…·ã€ç‹€æ…‹ç­‰)

**ç‚ºä½•ä¸ä½¿ç”¨ç¨ç«‹è…³æœ¬ï¼Ÿ** `runner.run_live()` æ–¹æ³•éœ€è¦ä¸€å€‹å¸¶æœ‰å·²é€£æ¥å®¢æˆ¶ç«¯çš„æ´»èº WebSocket ä¼ºæœå™¨æƒ…å¢ƒã€‚ç¨ç«‹çš„ Python è…³æœ¬ç„¡æ³•æä¾›æ­¤ç’°å¢ƒï¼Œé€™å°±æ˜¯ç‚ºä»€éº¼ `adk web` æ˜¯å®˜æ–¹çš„æœ‰æ•ˆæ¨¡å¼ã€‚


### ä½¿ç”¨ ADK Web å¿«é€Ÿå…¥é–€ (Quick Start with ADK Web)

**æ­¥é©Ÿ 1ï¼šè¨­å®š**

```bash
cd tutorial_implementation/tutorial15
make setup  # å®‰è£ä¾è³´é …å’Œå¥—ä»¶
```

**æ­¥é©Ÿ 2ï¼šè¨­å®šç’°å¢ƒ**

```bash
export GOOGLE_GENAI_USE_VERTEXAI=1
export GOOGLE_CLOUD_PROJECT=your-project-id
export GOOGLE_CLOUD_LOCATION=us-central1
export VOICE_ASSISTANT_LIVE_MODEL=gemini-2.0-flash-live-preview-04-09
```

**æ­¥é©Ÿ 3ï¼šå•Ÿå‹• ADK Web**

```bash
make dev  # åœ¨ http://localhost:8000 å•Ÿå‹•ç¶²é ä¼ºæœå™¨
```

**æ­¥é©Ÿ 4ï¼šåœ¨ç€è¦½å™¨ä¸­ä½¿ç”¨**

1. é–‹å•Ÿ http://localhost:8000
2. å¾ä¸‹æ‹‰é¸å–®ä¸­é¸æ“‡ `voice_assistant`
3. é»æ“Š**éŸ³è¨Š/éº¥å…‹é¢¨æŒ‰éˆ•** (ğŸ¤)
4. é–‹å§‹æ‚¨çš„å°è©±ï¼

### é‹ä½œåŸç† (How It Works)

ADK ç¶²é ä»‹é¢æä¾›ä¸€å€‹ `/run_live` WebSocket ç«¯é»ï¼Œå…¶é‹ä½œæ–¹å¼å¦‚ä¸‹ï¼š

```mermaid
sequenceDiagram
    participant Browser as ç€è¦½å™¨ (å‰ç«¯)
    participant ADKWebServer as ADK ç¶²é ä¼ºæœå™¨
    participant GeminiLiveAPI as Gemini Live API

    Browser->>ADKWebServer: WebSocket é€£æ¥
    Browser->>ADKWebServer: LiveRequest (éŸ³è¨Š)
    ADKWebServer->>GeminiLiveAPI: è™•ç†éŸ³è¨Š
    GeminiLiveAPI-->>ADKWebServer: Event (å›æ‡‰)
    ADKWebServer-->>Browser: Event (éŸ³è¨Š/æ–‡å­—)
```

**é—œéµå…ƒä»¶**:

- **å‰ç«¯**: åŸºæ–¼ç€è¦½å™¨çš„ UIï¼Œå…·æœ‰éº¥å…‹é¢¨/æšè²å™¨å­˜å–æ¬Šé™
- **WebSocket**: ç”¨æ–¼é›™å‘é€šè¨Šçš„ `/run_live` ç«¯é»
- **Live Request Queue**: ç®¡ç†å®¢æˆ¶ç«¯å’Œä»£ç†ç¨‹å¼ä¹‹é–“çš„è¨Šæ¯æµ
- **ä¸¦è¡Œä»»å‹™**: `forward_events()` å’Œ `process_messages()` åŒæ™‚é‹è¡Œ

---

## 1. Live API åŸºç¤ (Live API Basics)

### ä»€éº¼æ˜¯é›™å‘ä¸²æµï¼Ÿ (What is Bidirectional Streaming?)

**BIDI ä¸²æµ**å¯¦ç¾äº†ä½¿ç”¨è€…å’Œä»£ç†ç¨‹å¼ä¹‹é–“çš„**åŒæ™‚**é›™å‘é€šè¨Šã€‚èˆ‡ SSE (å–®å‘) ä¸åŒï¼ŒBIDI å…è¨±ï¼š

- ä½¿ç”¨è€…åœ¨ä»£ç†ç¨‹å¼å›æ‡‰æ™‚å‚³é€è³‡æ–™
- ä»£ç†ç¨‹å¼åœ¨ä½¿ç”¨è€…çµæŸå‰å³å¯å›æ‡‰
- ç„¡éœ€è¼ªæµç™¼è¨€çš„å³æ™‚äº’å‹•


### åŸºæœ¬ Live API è¨­å®š (Basic Live API Setup)

```python
# åŒ¯å…¥å¿…è¦çš„æ¨¡çµ„
import asyncio
from google.adk.agents import Agent, Runner, RunConfig, StreamingMode, LiveRequestQueue
from google.genai import types

# å»ºç«‹ç”¨æ–¼å³æ™‚äº’å‹•çš„ä»£ç†ç¨‹å¼
agent = Agent(
    model='gemini-2.0-flash-live-preview-04-09',  # Live API æ¨¡å‹ (Vertex)
    name='live_assistant',
    instruction='æ‚¨æ˜¯ä¸€ä½æ¨‚æ–¼åŠ©äººçš„èªéŸ³åŠ©ç†ã€‚è«‹è‡ªç„¶åœ°å›æ‡‰ä½¿ç”¨è€…æŸ¥è©¢ã€‚'
)

# è¨­å®šå³æ™‚ä¸²æµ
run_config = RunConfig(
    streaming_mode=StreamingMode.BIDI,
    speech_config=types.SpeechConfig(
        voice_config=types.VoiceConfig(
            prebuilt_voice_config=types.PrebuiltVoiceConfig(
                voice_name='Puck'  # å¯ç”¨è²éŸ³ï¼šPuck, Charon, Kore, Fenrir, Aoede
            )
        )
    )
)

async def live_session():
    """åŸ·è¡Œå³æ™‚é›™å‘æœƒè©±ã€‚"""

    # å»ºç«‹ç”¨æ–¼å³æ™‚é€šè¨Šçš„è«‹æ±‚ä½‡åˆ—
    queue = LiveRequestQueue()

    # ä½¿ç”¨æ‡‰ç”¨ç¨‹å¼æˆ–ä»£ç†ç¨‹å¼å»ºç«‹åŸ·è¡Œå™¨
    from google.adk.apps import App
    app = App(name='live_app', root_agent=agent)
    runner = Runner(app=app)

    # å»ºç«‹æˆ–å–å¾—æœƒè©±
    user_id = 'test_user'
    session = await runner.session_service.create_session(
        app_name=app.name,
        user_id=user_id
    )

    # ä½¿ç”¨æ­£ç¢ºçš„åƒæ•¸å•Ÿå‹•å³æ™‚æœƒè©±
    async for event in runner.run_live(
        live_request_queue=queue,
        user_id=user_id,
        session_id=session.id,
        run_config=run_config
    ):
        if event.content and event.content.parts:
            # è™•ç†ä»£ç†ç¨‹å¼å›æ‡‰
            for part in event.content.parts:
                if part.text:
                    print(f"ä»£ç†ç¨‹å¼: {part.text}")

# åŸ·è¡ŒéåŒæ­¥å‡½å¼
asyncio.run(live_session())
```

### Live API æ¨¡å‹ (Live API Models)

**VertexAI API**:

```python
# âœ… Vertex Live API æ¨¡å‹
agent = Agent(model='gemini-2.0-flash-live-preview-04-09')
```

**AI Studio API**:

```python
# âœ… AI Studio Live API æ¨¡å‹
agent = Agent(model='gemini-live-2.5-flash-preview')
```

**é‡è¦**: ä¸€èˆ¬çš„ Gemini æ¨¡å‹ä¸æ”¯æ´ Live APIï¼š

```python
# âŒ é€™äº›ä¸æ”¯æ´ Live API
agent = Agent(model='gemini-2.0-flash')  # ä¸€èˆ¬æ¨¡å‹
agent = Agent(model='gemini-1.5-flash')  # è¼ƒèˆŠçš„æ¨¡å‹
```

---

## 2. LiveRequestQueueï¼šå³æ™‚é€šè¨Š (LiveRequestQueue: Real-Time Communication)

### äº†è§£ LiveRequestQueue (Understanding LiveRequestQueue)

`LiveRequestQueue` ç®¡ç†é›™å‘é€šè¨Šâ€”â€”åŒæ™‚å‚³é€ä½¿ç”¨è€…è¼¸å…¥å’Œæ¥æ”¶ä»£ç†ç¨‹å¼å›æ‡‰ã€‚

**ä¾†æº**: `google/adk/agents/live_request_queue.py`

### å‚³é€æ–‡å­— (Sending Text)

```python
# åŒ¯å…¥å¿…è¦çš„æ¨¡çµ„
from google.adk.agents import LiveRequestQueue
from google.genai import types

# å»ºç«‹è«‹æ±‚ä½‡åˆ—
queue = LiveRequestQueue()

# ä½¿ç”¨ send_content å‚³é€æ–‡å­—è¨Šæ¯ (è€Œé send_realtime)
queue.send_content(
    types.Content(
        role='user',
        parts=[types.Part.from_text(text="ä½ å¥½ï¼Œä½ å¥½å—ï¼Ÿ")]
    )
)

# ç¹¼çºŒå°è©±
queue.send_content(
    types.Content(
        role='user',
        parts=[types.Part.from_text(text="è·Ÿæˆ‘èªªèªªé‡å­è¨ˆç®—")]
    )
)

# çµæŸæœƒè©±
queue.close()
```

### å‚³é€éŸ³è¨Š (Sending Audio)

```python
# åŒ¯å…¥ wave æ¨¡çµ„
import wave

# è¼‰å…¥éŸ³è¨Šæª”æ¡ˆ
with wave.open('audio_input.wav', 'rb') as audio_file:
    audio_data = audio_file.readframes(audio_file.getnframes())

# ä½¿ç”¨ send_realtime å°‡éŸ³è¨Šå‚³é€çµ¦ä»£ç†ç¨‹å¼ (ç”¨æ–¼å³æ™‚éŸ³è¨Šè¼¸å…¥)
queue.send_realtime(
    blob=types.Blob(
        data=audio_data,
        mime_type='audio/pcm;rate=16000'  # æŒ‡å®šå–æ¨£ç‡
    )
)
```

### å‚³é€å½±ç‰‡ (Sending Video)

```python
# å‚³é€å½±ç‰‡å½±æ ¼
queue.send_realtime(
    blob=types.Blob(
        data=video_frame_bytes,
        mime_type='video/mp4'
    )
)
```

### ä½‡åˆ—ç®¡ç† (Queue Management)

```python
# å®Œæˆå¾Œé—œé–‰ä½‡åˆ—
queue.close()

# ä½‡åˆ—æœƒè‡ªå‹•ç®¡ç†ï¼š
# - ç·©è¡
# - åŒæ­¥
# - èƒŒå£“
```

---

## 3. éŸ³è¨Šè¨­å®š (Audio Configuration)

### èªéŸ³è¾¨è­˜ (è¼¸å…¥) (Speech Recognition (Input))

```python
# åŒ¯å…¥å¿…è¦çš„æ¨¡çµ„
from google.genai import types

run_config = RunConfig(
    streaming_mode=StreamingMode.BIDI,

    # éŸ³è¨Šè¼¸å…¥/è¼¸å‡ºè¨­å®š
    speech_config=types.SpeechConfig(
        # èªéŸ³è¼¸å‡ºè¨­å®š
        voice_config=types.VoiceConfig(
            prebuilt_voice_config=types.PrebuiltVoiceConfig(
                voice_name='Puck'  # ä»£ç†ç¨‹å¼çš„è²éŸ³
            )
        )
    ),

    # å›æ‡‰æ ¼å¼ - æ¯å€‹æœƒè©±åªèƒ½æœ‰ä¸€ç¨®æ¨¡æ…‹
    response_modalities=['audio']  # ç”¨æ–¼éŸ³è¨Šå›æ‡‰
    # æˆ–
    # response_modalities=['text']  # ç”¨æ–¼æ–‡å­—å›æ‡‰
)
```

### å¯ç”¨è²éŸ³ (Available Voices)

```python
# å¯ç”¨çš„é å»ºè²éŸ³ï¼š
voices = [
    'Puck',    # å‹å–„ã€å°è©±å¼
    'Charon',  # æ·±æ²‰ã€æ¬Šå¨
    'Kore',    # æº«æš–ã€å°ˆæ¥­
    'Fenrir',  # å……æ»¿æ´»åŠ›ã€å‹•æ„Ÿ
    'Aoede'    # å¹³éœã€èˆ’ç·©
]

# è¨­å®šè²éŸ³
run_config = RunConfig(
    streaming_mode=StreamingMode.BIDI,
    speech_config=types.SpeechConfig(
        voice_config=types.VoiceConfig(
            prebuilt_voice_config=types.PrebuiltVoiceConfig(
                voice_name='Charon'  # é¸æ“‡è²éŸ³
            )
        )
    )
)
```

### å›æ‡‰æ¨¡æ…‹ (Response Modalities)

```python
# åƒ…æ–‡å­— (ä½¿ç”¨å°å¯«ä»¥é¿å… Pydantic åºåˆ—åŒ–è­¦å‘Š)
response_modalities=['text']

# åƒ…éŸ³è¨Š (ä½¿ç”¨å°å¯«ä»¥é¿å… Pydantic åºåˆ—åŒ–è­¦å‘Š)
response_modalities=['audio']

# é—œéµï¼šæ¯å€‹æœƒè©±åªèƒ½è¨­å®šä¸€ç¨®æ¨¡æ…‹
# åŸç”ŸéŸ³è¨Šæ¨¡å‹éœ€è¦ 'audio' æ¨¡æ…‹
# æ”¯æ´æ–‡å­—çš„æ¨¡å‹å¯ä»¥ä½¿ç”¨ 'text' æ¨¡æ…‹
# åŒæ™‚è¨­å®š ['text', 'audio'] æœƒå°è‡´éŒ¯èª¤
```

---

## 4. å»ºç«‹æ‚¨çš„èªéŸ³åŠ©ç† (Building Your Voice Assistant)

### å°ˆæ¡ˆçµæ§‹ (Project Structure)

æ•™å­¸ 15 çš„å¯¦ä½œæä¾›äº†ä¸€å€‹ä¹¾æ·¨ã€æœ€å°åŒ–çš„çµæ§‹ï¼š

```
tutorial_implementation/tutorial15/
â”œâ”€â”€ voice_assistant/
â”‚   â”œâ”€â”€ __init__.py           # å¥—ä»¶åŒ¯å‡º
â”‚   â”œâ”€â”€ agent.py              # æ ¸å¿ƒä»£ç†ç¨‹å¼èˆ‡ VoiceAssistant é¡åˆ¥
â”‚   â””â”€â”€ audio_utils.py        # AudioPlayer å’Œ AudioRecorder å·¥å…·
â”œâ”€â”€ tests/                    # å…¨é¢çš„æ¸¬è©¦å¥—ä»¶
â”œâ”€â”€ Makefile                  # é–‹ç™¼æŒ‡ä»¤
â”œâ”€â”€ requirements.txt          # ä¾è³´é …
â””â”€â”€ pyproject.toml           # å¥—ä»¶è¨­å®š
```

### æ ¸å¿ƒä»£ç†ç¨‹å¼å¯¦ä½œ (Core Agent Implementation)

`voice_assistant/agent.py` æª”æ¡ˆå®šç¾©äº† ADK web ç™¼ç¾çš„æ ¹ä»£ç†ç¨‹å¼ï¼š

```python
"""Live API çš„èªéŸ³åŠ©ç†ä»£ç†ç¨‹å¼"""

# åŒ¯å…¥å¿…è¦çš„æ¨¡çµ„
import os
from google.adk.agents import Agent
from google.genai import types

# ç’°å¢ƒè¨­å®š
LIVE_MODEL = os.getenv(
    "VOICE_ASSISTANT_LIVE_MODEL",
    "gemini-2.0-flash-live-preview-04-09"
)

# æ ¹ä»£ç†ç¨‹å¼ - ADK web å°‡æœƒç™¼ç¾æ­¤ä»£ç†ç¨‹å¼
root_agent = Agent(
    model=LIVE_MODEL,
    name="voice_assistant",
    description="æ”¯æ´ Live API çš„å³æ™‚èªéŸ³åŠ©ç†",
    instruction="""
æ‚¨æ˜¯ä¸€ä½æ¨‚æ–¼åŠ©äººçš„èªéŸ³åŠ©ç†ã€‚æŒ‡å—ï¼š

- è‡ªç„¶ä¸”å°è©±å¼åœ°å›æ‡‰
- ä¿æŒå›æ‡‰ç°¡æ½”ä»¥åˆ©èªéŸ³äº’å‹•
- éœ€è¦æ™‚æå‡ºæ¾„æ¸…å•é¡Œ
- å‹å–„ä¸”å¼•äººå…¥å‹
- ä½¿ç”¨é©åˆå£èªå°è©±çš„ä¼‘é–’èªè¨€
    """.strip(),
    generate_content_config=types.GenerateContentConfig(
        temperature=0.8,  # è‡ªç„¶ã€å°è©±å¼çš„èªæ°£
        max_output_tokens=200  # ç°¡æ½”ä»¥åˆ©èªéŸ³
    )
)
```

**å°±æ˜¯é€™æ¨£ï¼** ä»£ç†ç¨‹å¼ç¾åœ¨å¯ä»¥è¢« `adk web` ç™¼ç¾äº†ã€‚

### ä½¿ç”¨èªéŸ³åŠ©ç† (Using the Voice Assistant)

ä¸€æ—¦æ‚¨å»ºç«‹äº†ä»£ç†ç¨‹å¼ä¸¦åŸ·è¡Œ `make dev`ï¼ŒADK ç¶²é ä¼ºæœå™¨æœƒï¼š

1.  **ç™¼ç¾** `voice_assistant/agent.py` ä¸­çš„ `root_agent`
2.  **å»ºç«‹**ä¸€å€‹ `/run_live` WebSocket ç«¯é»
3.  **è‡ªå‹•è™•ç†**é›™å‘éŸ³è¨Šä¸²æµ
4.  **ç®¡ç†** LiveRequestQueue å’Œä¸¦è¡Œäº‹ä»¶è™•ç†

**åœ¨ç€è¦½å™¨ä¸­**:
- å¾ä¸‹æ‹‰é¸å–®ä¸­é¸æ“‡ `voice_assistant`
- é»æ“ŠéŸ³è¨Š/éº¥å…‹é¢¨æŒ‰éˆ•
- é–‹å§‹èªªè©±æˆ–æ‰“å­—
- ä»£ç†ç¨‹å¼æœƒä»¥éŸ³è¨Šè¼¸å‡ºå³æ™‚å›æ‡‰

### éŸ³è¨Šå·¥å…· (å¯é¸) (AudioUtilities (Optional))

å°æ–¼ç¨‹å¼åŒ–çš„éŸ³è¨Šè™•ç†ï¼Œ`voice_assistant/audio_utils.py` æä¾›äº†ï¼š

```python
# åŒ¯å…¥éŸ³è¨Šå·¥å…·
from voice_assistant.audio_utils import AudioPlayer, AudioRecorder

# æ’­æ”¾ PCM éŸ³è¨Š
player = AudioPlayer()
player.play_pcm_bytes(audio_data)
player.save_to_wav(audio_data, "output.wav")
player.close()

# å¾éº¥å…‹é¢¨éŒ„éŸ³
recorder = AudioRecorder()
audio_data = recorder.record(duration_seconds=5)
recorder.save_to_wav(audio_data, "input.wav")
recorder.close()
```

### è¨­å®šé¸é … (Configuration Options)

**ç’°å¢ƒè®Šæ•¸**:

```bash
# æ¨¡å‹é¸æ“‡
export VOICE_ASSISTANT_LIVE_MODEL=gemini-2.0-flash-live-preview-04-09

# Vertex AI è¨­å®š
export GOOGLE_GENAI_USE_VERTEXAI=1
export GOOGLE_CLOUD_PROJECT=your-project
export GOOGLE_CLOUD_LOCATION=us-central1
```

**è²éŸ³é¸æ“‡** (ä¿®æ”¹ agent.py):

```python
# åœ¨ VoiceAssistant é¡åˆ¥ä¸­å°‡ speech_config åŠ å…¥ run_config
run_config = RunConfig(
    streaming_mode=StreamingMode.BIDI,
    speech_config=types.SpeechConfig(
        voice_config=types.VoiceConfig(
            prebuilt_voice_config=types.PrebuiltVoiceConfig(
                voice_name='Charon'  # é¸é …ï¼šPuck, Charon, Kore, Fenrir, Aoede
            )
        )
    )
)
```

### æ¸¬è©¦ (Testing)

åŸ·è¡Œå…¨é¢çš„æ¸¬è©¦å¥—ä»¶ï¼š

```bash
make test
```

æ¸¬è©¦é©—è­‰ï¼š
- âœ… ä»£ç†ç¨‹å¼è¨­å®š
- âœ… VoiceAssistant é¡åˆ¥åŠŸèƒ½
- âœ… å¥—ä»¶çµæ§‹èˆ‡åŒ¯å…¥
- âœ… éŸ³è¨Šå·¥å…·å¯ç”¨æ€§

---

## 5. é€²éš Live API åŠŸèƒ½ (Advanced Live API Features)

### ä¸»å‹•æ€§ (Proactivity)

å…è¨±ä»£ç†ç¨‹å¼ç™¼èµ·å°è©±ï¼š

```python
# åŒ¯å…¥å¿…è¦çš„æ¨¡çµ„
from google.genai import types

run_config = RunConfig(
    streaming_mode=StreamingMode.BIDI,

    # å•Ÿç”¨ä¸»å‹•å›æ‡‰ (éœ€è¦ v1alpha API)
    # æ³¨æ„ï¼šä¸»å‹•éŸ³è¨Šåƒ…æ”¯æ´åŸç”ŸéŸ³è¨Šæ¨¡å‹
    proactivity=types.ProactivityConfig(
        proactive_audio=True
    ),

    speech_config=types.SpeechConfig(
        voice_config=types.VoiceConfig(
            prebuilt_voice_config=types.PrebuiltVoiceConfig(
                voice_name='Puck'
            )
        )
    )
)

# ä»£ç†ç¨‹å¼ç¾åœ¨å¯ä»¥åœ¨ä¸ç­‰å¾…ä½¿ç”¨è€…è¼¸å…¥çš„æƒ…æ³ä¸‹èªªè©±
# é©ç”¨æ–¼ï¼šé€šçŸ¥ã€æé†’ã€å»ºè­°
```

### æƒ…æ„Ÿå°è©± (æƒ…ç·’åµæ¸¬) (Affective Dialog (Emotion Detection))

å¾èªéŸ³ä¸­åµæ¸¬ä½¿ç”¨è€…æƒ…ç·’ï¼š

```python
run_config = RunConfig(
    streaming_mode=StreamingMode.BIDI,

    # å•Ÿç”¨æƒ…ç·’åµæ¸¬
    enable_affective_dialog=True,

    speech_config=types.SpeechConfig(
        voice_config=types.VoiceConfig(
            prebuilt_voice_config=types.PrebuiltVoiceConfig(
                voice_name='Kore'  # å¯Œæœ‰åŒç†å¿ƒçš„è²éŸ³
            )
        )
    )
)

# ä»£ç†ç¨‹å¼æ¥æ”¶æƒ…ç·’è¨Šè™Ÿï¼š
# - é–‹å¿ƒã€æ‚²å‚·ã€ç”Ÿæ°£ã€ä¸­æ€§ç­‰
# - å¯ä»¥ç›¸æ‡‰åœ°èª¿æ•´å›æ‡‰èªæ°£
```

### å½±ç‰‡ä¸²æµ (Video Streaming)

ä¸²æµå½±ç‰‡ä»¥é€²è¡Œå³æ™‚åˆ†æï¼š

```python
# åŒ¯å…¥å¿…è¦çš„æ¨¡çµ„
import cv2
import asyncio

# æ•æ‰å½±ç‰‡
cap = cv2.VideoCapture(0)

queue = LiveRequestQueue()

while True:
    ret, frame = cap.read()

    if not ret:
        break

    # å°‡å½±æ ¼è½‰æ›ç‚ºä½å…ƒçµ„
    _, buffer = cv2.imencode('.jpg', frame)
    frame_bytes = buffer.tobytes()

    # å°‡å½±æ ¼å‚³é€çµ¦ä»£ç†ç¨‹å¼
    queue.send_realtime(
        blob=types.Blob(
            data=frame_bytes,
            mime_type='image/jpeg'
        )
    )

    await asyncio.sleep(0.1)  # ç´„ 10 FPS

queue.send_end()

# ä»£ç†ç¨‹å¼å¯ä»¥å³æ™‚åˆ†æå½±ç‰‡
# ä½¿ç”¨æ¡ˆä¾‹ï¼šæ‰‹å‹¢è¾¨è­˜ã€ç‰©é«”åµæ¸¬ã€ç›£æ§
```

---

## 6. å¤šä»£ç†ç¨‹å¼å³æ™‚æœƒè©± (Multi-Agent Live Sessions)

åœ¨å³æ™‚å°è©±ä¸­çµåˆå¤šå€‹ä»£ç†ç¨‹å¼ï¼š

```python
"""
å¤šä»£ç†ç¨‹å¼èªéŸ³å°è©±ã€‚
"""

# åŒ¯å…¥å¿…è¦çš„æ¨¡çµ„
from google.adk.agents import Agent, Runner, RunConfig, StreamingMode, LiveRequestQueue
from google.genai import types

# å»ºç«‹å°ˆé–€çš„ä»£ç†ç¨‹å¼
greeter = Agent(
    model='gemini-2.0-flash-live-preview-04-09',
    name='greeter',
    instruction='ç†±æƒ…åœ°å•å€™ä½¿ç”¨è€…ï¼Œä¸¦è©¢å•å¦‚ä½•æä¾›å”åŠ©ã€‚'
)

expert = Agent(
    model='gemini-2.0-flash-live-preview-04-09',
    name='expert',
    instruction='æä¾›è©³ç´°çš„å°ˆå®¶ç´šå•é¡Œè§£ç­”ã€‚'
)

# å”èª¿è€…ä»£ç†ç¨‹å¼
orchestrator = Agent(
    model='gemini-2.0-flash-live-preview-04-09',
    name='orchestrator',
    instruction="""
æ‚¨åœ¨å¤šå€‹ä»£ç†ç¨‹å¼ä¹‹é–“é€²è¡Œå”èª¿ï¼š
- ä½¿ç”¨ 'greeter' é€²è¡Œåˆæ¬¡æ¥è§¸
- ä½¿ç”¨ 'expert' å›ç­”è©³ç´°å•é¡Œ
- ç¢ºä¿å°è©±æµæš¢
    """,
    sub_agents=[greeter, expert],
    flow='sequential'
)

run_config = RunConfig(
    streaming_mode=StreamingMode.BIDI,
    speech_config=types.SpeechConfig(
        voice_config=types.VoiceConfig(
            prebuilt_voice_config=types.PrebuiltVoiceConfig(
                voice_name='Puck'
            )
        )
    )
)

async def multi_agent_voice():
    """åŸ·è¡Œå¤šä»£ç†ç¨‹å¼èªéŸ³æœƒè©±ã€‚"""

    queue = LiveRequestQueue()

    # è¨­å®šæ‡‰ç”¨ç¨‹å¼å’ŒåŸ·è¡Œå™¨
    from google.adk.apps import App
    app = App(name='multi_agent_voice', root_agent=orchestrator)
    runner = Runner(app=app)

    # å»ºç«‹æœƒè©±
    user_id = 'multi_agent_user'
    session = await runner.session_service.create_session(
        app_name=app.name,
        user_id=user_id
    )

    # ä½¿ç”¨è€…èªªè©± (ä½¿ç”¨ send_content å‚³é€æ–‡å­—)
    queue.send_content(
        types.Content(
            role='user',
            parts=[types.Part.from_text(
                text="ä½ å¥½ï¼Œæˆ‘æœ‰ä¸€å€‹é—œæ–¼é‡å­è¨ˆç®—çš„å•é¡Œ"
            )]
        )
    )
    queue.close()

    # å”èª¿è€…å”èª¿ä»£ç†ç¨‹å¼
    async for event in runner.run_live(
        live_request_queue=queue,
        user_id=user_id,
        session_id=session.id,
        run_config=run_config
    ):
        if event.content and event.content.parts:
            for part in event.content.parts:
                if part.text:
                    print(f"{event.author}: {part.text}")

# åŸ·è¡ŒéåŒæ­¥å‡½å¼
asyncio.run(multi_agent_voice())
```

---

## 7. æœ€ä½³å¯¦è¸ (Best Practices)

### âœ… æ‡‰åšï¼šä½¿ç”¨ Live API æ¨¡å‹ (DO: Use Live API Models)

```python
# âœ… è‰¯å¥½ - Live API æ¨¡å‹
agent = Agent(model='gemini-2.0-flash-live-preview-04-09')  # Vertex
agent = Agent(model='gemini-live-2.5-flash-preview')  # AI Studio

# âŒ ä¸è‰¯ - ä¸€èˆ¬æ¨¡å‹ä¸æ”¯æ´ Live API
agent = Agent(model='gemini-2.0-flash')
agent = Agent(model='gemini-1.5-flash')
```

### âœ… æ‡‰åšï¼šä¿æŒèªéŸ³å›æ‡‰ç°¡æ½” (DO: Keep Voice Responses Concise)

```python
# âœ… è‰¯å¥½ - ç°¡æ½”ä»¥åˆ©èªéŸ³
agent = Agent(
    model='gemini-2.0-flash-live-preview-04-09',
    instruction='ä¿æŒå›æ‡‰ç°¡çŸ­ä¸”å°è©±å¼ï¼Œä»¥åˆ©èªéŸ³äº’å‹•ã€‚',
    generate_content_config=types.GenerateContentConfig(
        max_output_tokens=150
    )
)

# âŒ ä¸è‰¯ - å°æ–¼èªéŸ³è€Œè¨€éæ–¼å†—é•·
agent = Agent(
    model='gemini-2.0-flash-live-preview-04-09',
    generate_content_config=types.GenerateContentConfig(
        max_output_tokens=4096  # å°æ–¼èªéŸ³è€Œè¨€å¤ªé•·
    )
)
```

### âœ… æ‡‰åšï¼šæ­£ç¢ºè™•ç†éŸ³è¨Šæ ¼å¼ (DO: Handle Audio Formats Properly)

```python
# âœ… è‰¯å¥½ - æ­£ç¢ºçš„éŸ³è¨Šæ ¼å¼èˆ‡å–æ¨£ç‡
queue.send_realtime(
    blob=types.Blob(
        data=audio_data,
        mime_type='audio/pcm;rate=16000'  # æŒ‡å®šå–æ¨£ç‡
    )
)

# âŒ ä¸è‰¯ - éŒ¯èª¤çš„æ ¼å¼æˆ–ç¼ºå°‘å–æ¨£ç‡
queue.send_realtime(
    blob=types.Blob(
        data=audio_data,
        mime_type='text/plain'  # éŒ¯èª¤çš„é¡å‹
    )
)
```

### âœ… æ‡‰åšï¼šå‹™å¿…é—œé–‰ä½‡åˆ— (DO: Always Close Queue)

```python
# âœ… è‰¯å¥½ - æ­£ç¢ºé—œé–‰ä½‡åˆ—
queue = LiveRequestQueue()

try:
    queue.send_content(types.Content(
        role='user',
        parts=[types.Part.from_text(text="ä½ å¥½")]
    ))
    # ... è™•ç†å›æ‡‰
finally:
    queue.close()  # å‹™å¿…é—œé–‰

# âŒ ä¸è‰¯ - å¿˜è¨˜é—œé–‰
queue = LiveRequestQueue()
queue.send_content(types.Content(
    role='user',
    parts=[types.Part.from_text(text="ä½ å¥½")]
))
# ä½‡åˆ—ä¿æŒé–‹å•Ÿ
```

### âœ… æ‡‰åšï¼šä½¿ç”¨åˆé©çš„è²éŸ³ (DO: Use Appropriate Voices)

```python
# âœ… è‰¯å¥½ - è²éŸ³ç¬¦åˆä½¿ç”¨æ¡ˆä¾‹
customer_service = Agent(
    model='gemini-2.0-flash-live-preview-04-09',
    instruction='æ¨‚æ–¼åŠ©äººçš„å®¢æˆ¶æœå‹™ä»£ç†ç¨‹å¼'
)

run_config = RunConfig(
    streaming_mode=StreamingMode.BIDI,
    speech_config=types.SpeechConfig(
        voice_config=types.VoiceConfig(
            prebuilt_voice_config=types.PrebuiltVoiceConfig(
                voice_name='Kore'  # æº«æš–ã€å°ˆæ¥­
            )
        )
    )
)
```

---

## 8. ç–‘é›£æ’è§£ (Troubleshooting)

### éŒ¯èª¤ï¼š"æ¨¡å‹ä¸æ”¯æ´ Live API" (Error: "Model doesn't support Live API")

**å•é¡Œ**: ä½¿ç”¨é Live API æ¨¡å‹

**è§£æ±ºæ–¹æ¡ˆ**:

```python
# âŒ éŒ¯èª¤çš„æ¨¡å‹
agent = Agent(model='gemini-2.0-flash')

# âœ… ä½¿ç”¨ Live API æ¨¡å‹
agent = Agent(model='gemini-2.0-flash-live-preview-04-09')  # Vertex
# æˆ–
agent = Agent(model='gemini-live-2.5-flash-preview')  # AI Studio
```

### å•é¡Œï¼š"å›æ‡‰ä¸­æ²’æœ‰éŸ³è¨Š" (Issue: "No audio in response")

**å•é¡Œ**: éŸ³è¨Šè¨­å®šä¸æ­£ç¢º

**è§£æ±ºæ–¹æ¡ˆ**:

1.  **è¨­å®šå›æ‡‰æ¨¡æ…‹**:

```python
run_config = RunConfig(
    streaming_mode=StreamingMode.BIDI,
    response_modalities=['TEXT', 'AUDIO'],  # åŒ…å« AUDIO
    speech_config=types.SpeechConfig(...)
)
```

2.  **è¨­å®šè²éŸ³**:

```python
speech_config=types.SpeechConfig(
    voice_config=types.VoiceConfig(
        prebuilt_voice_config=types.PrebuiltVoiceConfig(
            voice_name='Puck'  # å¿…é ˆè¨­å®šè²éŸ³
        )
    )
)
```

### å•é¡Œï¼š"ä½‡åˆ—é€¾æ™‚" (Issue: "Queue timeout")

**å•é¡Œ**: ä½‡åˆ—æœªæ­£ç¢ºé—œé–‰

**è§£æ±ºæ–¹æ¡ˆ**:

```python
# âœ… å‹™å¿… close() ä½‡åˆ—
queue = LiveRequestQueue()
queue.send_content(types.Content(
    role='user',
    parts=[types.Part.from_text(text="ä½ å¥½")]
))
queue.close()  # é‡è¦ï¼
```

---

## ç¸½çµ (Summary)

**å°æ–¼ç”Ÿç”¢ç’°å¢ƒçš„ Live API æ‡‰ç”¨**: ä½¿ç”¨æœ¬æ•™å­¸ä¸­ç¤ºç¯„çš„ `adk web` ä»‹é¢ã€‚`/run_live` WebSocket ç«¯é»æ˜¯å®˜æ–¹æ¸¬è©¦éçš„é›™å‘éŸ³è¨Šä¸²æµæ¨¡å¼ã€‚

**ç‚ºä½• ADK Web èƒ½é‹ä½œ**:
- ç€è¦½å™¨å’Œä¼ºæœå™¨ä¹‹é–“æœ‰æ´»èºçš„ WebSocket é€£æ¥
- ä¸¦è¡Œä»»å‹™ç®¡ç† (`forward_events()` + `process_messages()`)
- æ­£ç¢ºçš„ LiveRequestQueue è™•ç†
- å®Œæ•´çš„ ADK ä»£ç†ç¨‹å¼åŠŸèƒ½ (å·¥å…·ã€ç‹€æ…‹ã€è¨˜æ†¶é«”)

**æ›¿ä»£æ–¹æ¡ˆ**: å°æ–¼éœ€è¦ç›´æ¥ API å­˜å–è€Œç„¡éœ€ ADK æ¡†æ¶çš„æ‡‰ç”¨ï¼Œè«‹ç›´æ¥ä½¿ç”¨ `google.genai.Client.aio.live.connect()` (ç¹é ADK Runner)ã€‚


æ‚¨å·²æŒæ¡ä½¿ç”¨ Live API é€²è¡Œå³æ™‚èªéŸ³äº’å‹•ï¼š

**é‡é»å›é¡§**:

- âœ… `StreamingMode.BIDI` å¯¦ç¾é›™å‘ä¸²æµ
- âœ… `LiveRequestQueue` ç®¡ç†å³æ™‚é€šè¨Š
- âœ… ä½¿ç”¨ `speech_config` é€²è¡ŒéŸ³è¨Šè¼¸å…¥/è¼¸å‡º
- âœ… æä¾›å¤šç¨®è²éŸ³ (Puck, Charon, Kore ç­‰)
- âœ… ä¸»å‹•æ€§è®“ä»£ç†ç¨‹å¼èƒ½ç™¼èµ·å°è©±
- âœ… æƒ…æ„Ÿå°è©±ç”¨æ–¼æƒ…ç·’åµæ¸¬
- âœ… æ”¯æ´å½±ç‰‡ä¸²æµ
- âœ… Live API æ¨¡å‹: `gemini-2.0-flash-live-preview-04-09` (Vertex), `gemini-live-2.5-flash-preview` (AI Studio)

**ç”Ÿç”¢æª¢æŸ¥æ¸…å–®**:

- [ ] ä½¿ç”¨èˆ‡ Live API ç›¸å®¹çš„æ¨¡å‹
- [ ] å·²è¨­å®š `StreamingMode.BIDI`
- [ ] åŒ…å«è²éŸ³é¸æ“‡çš„èªéŸ³è¨­å®š
- [ ] æ­£ç¢ºè¨­å®šéŸ³è¨Šæ ¼å¼ (audio/pcm;rate=16000)
- [ ] ä½¿ç”¨ `close()` æ­£ç¢ºé—œé–‰ä½‡åˆ—
- [ ] èªéŸ³å›æ‡‰ç°¡æ½” (max_output_tokens=150-200)
- [ ] è™•ç†éŸ³è¨Š/ç¶²è·¯å•é¡Œçš„éŒ¯èª¤è™•ç†
- [ ] ä½¿ç”¨å¯¦éš›éŸ³è¨Šè¨­å‚™é€²è¡Œæ¸¬è©¦
- [ ] æ¯å€‹æœƒè©±åªæœ‰ä¸€ç¨®å›æ‡‰æ¨¡æ…‹ (TEXT æˆ– AUDIOï¼Œè€Œéå…©è€…)
- [ ] æ­£ç¢ºçš„ `run_live()` åƒæ•¸ (live_request_queue, user_id, session_id)

**è³‡æº**

- [Live API æ–‡ä»¶](https://cloud.google.com/vertex-ai/generative-ai/docs/model-reference/gemini-live)
- [éŸ³è¨Šè¨­å®šæŒ‡å—](https://cloud.google.com/vertex-ai/generative-ai/docs/speech)
- [ç¯„ä¾‹: live_bidi_streaming_single_agent](https://github.com/google/adk-python/tree/main/contributing/samples/live_bidi_streaming_single_agent/)

---

## ç¨‹å¼ç¢¼å¯¦ç¾ (Code Implementation)
- voice_assistantï¼š[ç¨‹å¼ç¢¼é€£çµ](../../../python/agents/voice-assistant/)
