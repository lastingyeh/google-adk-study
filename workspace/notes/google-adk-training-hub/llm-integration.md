# LLM æ•´åˆ (LLM Integration)

**ğŸ¯ ç›®çš„**: ç²¾é€šæç¤º (prompting)ã€æ¥åœ° (grounding) å’Œæ¨ç† (reasoning) æŠ€è¡“ï¼Œä»¥å¾èªè¨€æ¨¡å‹ä¸­ç²å¾—æœ€ä½³æ€§èƒ½ã€‚

**ğŸ“š çœŸå¯¦ä¾†æº**: [google/adk-python/src/google/adk/models/](https://github.com/google/adk-python/tree/main/src/google/adk/models/) (ADK 1.15) + [google/adk-python/src/google/adk/planners/](https://github.com/google/adk-python/tree/main/src/google/adk/planners/) (ADK 1.15)

---

## ğŸ“ æç¤ºå·¥ç¨‹åŸºç¤ (Prompt Engineering Fundamentals)

### The Prompt = Program Model (æç¤º = ç¨‹å¼æ¨¡å‹)

**å¿ƒæ™ºæ¨¡å‹**: ä¸€å€‹æç¤º (Prompt) å°±åƒæ˜¯ç‚ºå¤§å‹èªè¨€æ¨¡å‹ (LLM) **ç·¨å¯«ç¨‹å¼**ã€‚å®ƒç”±ä¸åŒçš„éƒ¨åˆ†çµ„æˆï¼Œæ¯å€‹éƒ¨åˆ†éƒ½æœ‰å…¶ç¨ç‰¹çš„åŠŸèƒ½ã€‚

**æç¤ºçš„çµæ§‹ (PROMPT ANATOMY)**
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ æç¤ºçš„çµæ§‹ (PROMPT ANATOMY)                                  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                              â”‚
â”‚ [INSTR] ç³»çµ±/æŒ‡ä»¤ (ä½œæ¥­ç³»çµ±)                                 â”‚
â”‚ "ä½ æ˜¯ä¸€ä½æ¨‚æ–¼åŠ©äººçš„ç ”ç©¶åŠ©ç†..."                              â”‚
â”‚ â†’ å®šç¾©ä»£ç†äººçš„å€‹æ€§å’Œè¡Œç‚º                                     â”‚
â”‚ â†’ è¨­å®šç´„æŸå’Œè¦å‰‡                                             â”‚
â”‚ â†’ æä¾›è§’è‰²ä¸Šä¸‹æ–‡                                             â”‚
â”‚                                                              â”‚
â”‚ [MEM] ä¸Šä¸‹æ–‡ (ç¨‹å¼è³‡æ–™)                                      â”‚
â”‚ "ç›®å‰ç‹€æ…‹: {topic}, å…ˆå‰æ­·å²: {history}"                     â”‚
â”‚ â†’ å¾æœƒè©±ç‹€æ…‹ä¸­æ³¨å…¥                                           â”‚
â”‚ â†’ é€é {key} èªæ³•å‚³å…¥å‹•æ…‹è³‡æ–™                                â”‚
â”‚ â†’ å¯ç”¨çš„å·¥å…·åˆ—è¡¨                                             â”‚
â”‚                                                              â”‚
â”‚ [USER] ä½¿ç”¨è€…è¨Šæ¯ (å‡½å¼å‘¼å«)                                 â”‚
â”‚ "ç ”ç©¶é‡å­è¨ˆç®—çš„è¶¨å‹¢"                                         â”‚
â”‚ â†’ å¯¦éš›çš„ä»»å‹™æˆ–æŸ¥è©¢                                           â”‚
â”‚ â†’ å¯ä»¥æ˜¯æ–‡å­—ã€åœ–ç‰‡ã€éŸ³è¨Šã€å½±ç‰‡                               â”‚
â”‚                                                              â”‚
â”‚ [TOOLS] å·¥å…·çµæœ (å›å‚³å€¼)                                    â”‚
â”‚ "search_result: {...}"                                       â”‚
â”‚ â†’ ä¾†è‡ªå·¥å…·åŸ·è¡Œçš„åé¥‹                                         â”‚
â”‚ â†’ å¤šè¼ªå°è©±                                                   â”‚
â”‚                                                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Instruction Patterns (æŒ‡ä»¤æ¨¡å¼)

**åŸºæ–¼è§’è‰²çš„æŒ‡ä»¤ (Role-Based Instructions)**: æ¸…æ™°åœ°å®šç¾©ä»£ç†äººçš„è§’è‰²ä»¥å¼•å°å…¶è¡Œç‚ºã€‚
```python
# æ¸…æ™°çš„è§’è‰²å®šç¾©
instruction = """
ä½ æ˜¯ä¸€ä½è³‡æ·±è»Ÿé«”å·¥ç¨‹å¸«ï¼Œå…·å‚™ä»¥ä¸‹ç‰¹é»ï¼š
- ç·¨å¯«ä¹¾æ·¨ã€å¯ç¶­è­·çš„ç¨‹å¼ç¢¼
- éµå¾ª Python æœ€ä½³å¯¦è¸
- æ·»åŠ æœ‰å¹«åŠ©çš„è¨»è§£
- æ¸…æ™°åœ°è§£é‡‹è¤‡é›œæ¦‚å¿µ
"""

# ç‰¹å®šä»»å‹™çš„è§’è‰²
instruction = """
ä½ æ˜¯ä¸€ä½ç ”ç©¶åˆ†æå¸«ï¼Œå°ˆé•·æ–¼ï¼š
- æ•¸æ“šé©…å‹•çš„æ´å¯Ÿ
- çµ±è¨ˆåˆ†æ
- æ¸…æ™°çš„è¦–è¦ºåŒ–å»ºè­°
- æ’°å¯«é«˜éšä¸»ç®¡æ‘˜è¦
"""
```

**åŸºæ–¼ç´„æŸçš„æŒ‡ä»¤ (Constraint-Based Instructions)**: è¨­å®šè¦å‰‡ä¾†é™åˆ¶æ¨¡å‹çš„è¡Œç‚ºå’Œè¼¸å‡ºæ ¼å¼ã€‚
```python
# è¡Œç‚ºç´„æŸ
instruction = """
ä½ å¿…é ˆéµå®ˆä»¥ä¸‹è¦å‰‡ï¼š
- å¼•ç”¨äº‹å¯¦æ™‚å¿…é ˆæä¾›ä¾†æº
- å¦‚æœä¸ç¢ºå®šï¼Œå›ç­”ã€Œæˆ‘ä¸çŸ¥é“ã€ï¼Œè€Œä¸æ˜¯çŒœæ¸¬
- é™¤éè¢«è¦æ±‚æä¾›ç´°ç¯€ï¼Œå¦å‰‡å›æ‡‰é•·åº¦æ‡‰åœ¨ä¸‰æ®µä»¥å…§
- è§£é‡‹æ¦‚å¿µæ™‚ä½¿ç”¨ç¯„ä¾‹
- ç•¶è¼¸å…¥ä¸æ˜ç¢ºæ™‚ï¼Œæå‡ºæ¾„æ¸…å•é¡Œ
"""

# è¼¸å‡ºæ ¼å¼ç´„æŸ
instruction = """
å›æ‡‰æ ¼å¼ï¼š
1. é«˜éšä¸»ç®¡æ‘˜è¦ (2-3 å¥è©±)
2. ä¸»è¦ç™¼ç¾ (é»åˆ—å¼)
3. å»ºè­° (ç·¨è™Ÿåˆ—è¡¨)
4. å¾ŒçºŒæ­¥é©Ÿ (å¦‚æœé©ç”¨)
"""
```

**ç‹€æ…‹æ„ŸçŸ¥æŒ‡ä»¤ (State-Aware Instructions)**: å‹•æ…‹åœ°å°‡ä¸Šä¸‹æ–‡è³‡è¨Šæ³¨å…¥æç¤ºä¸­ã€‚
```python
# å‹•æ…‹ä¸Šä¸‹æ–‡æ³¨å…¥
instruction = """
ä½ æ­£åœ¨å”åŠ© {user:name} è™•ç† {current_task}ã€‚
å…ˆå‰çš„ä¸Šä¸‹æ–‡ï¼š{conversation_summary}
å¯ç”¨çš„å·¥å…·ï¼š{tool_list}

æŒ‡å°æ–¹é‡ï¼š
- åœ¨ç›¸é—œæ™‚åƒè€ƒå…ˆå‰çš„å·¥ä½œ
- ç‚ºä»»å‹™ä½¿ç”¨é©ç•¶çš„å·¥å…·
- èˆ‡å…ˆå‰çš„å›æ‡‰ä¿æŒä¸€è‡´æ€§
"""
```

---

## ğŸŒ æ¥åœ°æŠ€è¡“ (Grounding Techniques)

### Web Grounding (Real-World Facts) (ç¶²è·¯æ¥åœ° - çœŸå¯¦ä¸–ç•Œäº‹å¯¦)

**å¿ƒæ™ºæ¨¡å‹**: æ¥åœ°æŠ€è¡“å°‡ LLM çš„**æƒ³åƒèˆ‡ç¾å¯¦**è¯ç¹«èµ·ä¾†ï¼Œç¢ºä¿å›æ‡‰åŸºæ–¼äº‹å¯¦ã€‚

```python
# ä½¿ç”¨ Gemini 2.0+ çš„è‡ªå‹•æ¥åœ°åŠŸèƒ½
# è©²æ¨¡å‹å…§å»ºäº†æœå°‹åŠŸèƒ½
grounded_agent = Agent(
    name="researcher",
    model="gemini-2.0-flash", # å…§å»ºæœå°‹
    instruction="ä½¿ç”¨ç¶²è·¯æœå°‹ä¾†ç ”ç©¶ç•¶å‰è³‡è¨Š"
)

# æ˜ç¢ºçš„æœå°‹æ•´åˆ
# é€é tools åƒæ•¸å‚³å…¥å¤–éƒ¨æœå°‹å·¥å…·
search_agent = Agent(
    name="web_researcher",
    model="gemini-2.5-flash",
    tools=[google_search],
    instruction="å°‹æ‰¾ä¸¦åˆ†æç•¶å‰è³‡è¨Š"
)
```

### Data Grounding (Internal Knowledge) (è³‡æ–™æ¥åœ° - å…§éƒ¨çŸ¥è­˜)

**å¿ƒæ™ºæ¨¡å‹**: å°‡ LLM é€£æ¥åˆ°æ‚¨è‡ªå·±çš„å…§éƒ¨è³‡æ–™ä¾†æºï¼Œä¾‹å¦‚å…¬å¸è³‡æ–™åº«æˆ–å…§éƒ¨æ–‡ä»¶ã€‚

```python
# è³‡æ–™åº«æ¥åœ°
db_agent = Agent(
    name="data_analyst",
    model="gemini-2.5-flash",
    tools=[database_tool, analysis_tool], # å‚³å…¥è³‡æ–™åº«å’Œåˆ†æå·¥å…·
    instruction="åˆ†æå…¬å¸æ•¸æ“šä»¥å›ç­”å•é¡Œ"
)

# æ–‡ä»¶æ¥åœ°
doc_agent = Agent(
    name="knowledge_assistant",
    model="gem-2.5-flash",
    tools=[document_search_tool], # å‚³å…¥æ–‡ä»¶æœå°‹å·¥å…·
    instruction="åœ¨å…¬å¸æ–‡ä»¶ä¸­å°‹æ‰¾ç›¸é—œè³‡è¨Š"
)
```

### Location Grounding (Spatial Intelligence) (ä½ç½®æ¥åœ° - ç©ºé–“æ™ºæ…§)

**å¿ƒæ™ºæ¨¡å‹**: è³¦äºˆæ¨¡å‹åœ°ç†æ„ŸçŸ¥å’Œç©ºé–“æ¨ç†èƒ½åŠ›ã€‚

```python
# åœ°åœ–æ•´åˆ
location_agent = Agent(
    name="location_assistant",
    model="gemini-2.5-flash",
    tools=[google_maps_grounding], # æ•´åˆ Google åœ°åœ–ä½œç‚ºæ¥åœ°å·¥å…·
    instruction="å”åŠ©è™•ç†åŸºæ–¼ä½ç½®çš„æŸ¥è©¢å’Œæ–¹å‘"
)

# èƒ½åŠ›ï¼š
# - åœ°å€è§£æ
# - è·é›¢è¨ˆç®—
# - èˆˆè¶£é»æŸ¥è©¢
# - è·¯ç·šå„ªåŒ–
```

---

## [BRAIN] æ€è€ƒèˆ‡æ¨ç†æ¡†æ¶ (Thinking & Reasoning Frameworks)

### Built-in Thinking (Native Model Capability) (å…§å»ºæ€è€ƒ - æ¨¡å‹åŸç”Ÿèƒ½åŠ›)

**å¿ƒæ™ºæ¨¡å‹**: æ¨¡å‹åœ¨å…§éƒ¨é€æ­¥æ€è€ƒï¼Œä¸¦å¯ä»¥é¸æ“‡æ€§åœ°å°‡æ€è€ƒéç¨‹å±•ç¤ºå‡ºä¾†ã€‚

```python
# Gemini 2.0+ çš„æ€è€ƒåŠŸèƒ½
thinking_agent = Agent(
    name="reasoning_assistant",
    model="gemini-2.0-flash",
    instruction="ç”¨æ¸…æ™°çš„æ¨ç†ä¾†è§£æ±ºè¤‡é›œå•é¡Œ",
    thinking_config=ThinkingConfig(
        include_thoughts=True, # åœ¨å›æ‡‰ä¸­é¡¯ç¤ºæ€è€ƒéç¨‹
        max_thoughts=10
    )
)

# æ€è€ƒéç¨‹æœƒå‡ºç¾åœ¨å›æ‡‰ä¸­ï¼š
# "è®“æˆ‘ä¸€æ­¥ä¸€æ­¥åœ°æ€è€ƒé€™å€‹å•é¡Œï¼š
# 1. é¦–å…ˆï¼Œæˆ‘éœ€è¦ç†è§£å•é¡Œ...
# 2. ç„¶å¾Œï¼Œæˆ‘æ‡‰è©²è€ƒæ…®é™åˆ¶æ¢ä»¶...
# 3. æœ€å¾Œï¼Œæˆ‘å°‡æä¾›è§£æ±ºæ–¹æ¡ˆ..."
```

### Plan-ReAct Pattern (Structured Reasoning) (è¨ˆç•«-åæ‡‰æ¨¡å¼ - çµæ§‹åŒ–æ¨ç†)

**å¿ƒæ™ºæ¨¡å‹**: ä¸€å€‹æ˜ç¢ºçš„è¨ˆç•«èˆ‡è¡Œå‹•æ¡†æ¶ï¼Œè®“ä»£ç†äººèƒ½å¤ é€²è¡Œçµæ§‹åŒ–çš„æ¨ç†ã€‚

```python
from google.adk.planners import PlanReActPlanner

# çµæ§‹åŒ–æ¨ç†ä»£ç†äºº
reasoning_agent = Agent(
    name="strategic_planner",
    model="gemini-2.5-flash",
    planner=PlanReActPlanner(), # ä½¿ç”¨ Plan-ReAct è¦åŠƒå™¨
    tools=[research_tool, analysis_tool],
    instruction="è¨ˆç•«ä¸¦åŸ·è¡Œè¤‡é›œçš„å¤šæ­¥é©Ÿä»»å‹™"
)

# åŸ·è¡Œæ¨¡å¼ï¼š
# [PLANNING] 1. ç ”ç©¶ä¸»é¡Œ 2. åˆ†ææ•¸æ“š 3. å»ºç«‹å ±å‘Š
# [REASONING] æˆ‘æ‡‰è©²å¾ç ”ç©¶é–‹å§‹ï¼Œä»¥æ”¶é›†äº‹å¯¦...
# [ACTION] å‘¼å« research_tool("é‡å­è¨ˆç®—")
# [OBSERVATION] æ‰¾åˆ°äº† 15 ç¯‡ç›¸é—œè«–æ–‡...
# [REPLANNING] ç¾åœ¨ä¾†åˆ†ææ•¸æ“š...
```

### When to Use Each Approach (ä½•æ™‚ä½¿ç”¨å„ç¨®æ–¹æ³•)

| æƒ…å¢ƒ | å…§å»ºæ€è€ƒ (Built-in Thinking) | è¨ˆç•«-åæ‡‰ (Plan-ReAct) | ç„¡ (None) |
| :--- | :---: | :---: | :---: |
| éœ€è¦è¤‡é›œæ¨ç† | âœ… | âœ… | âŒ |
| å¸Œæœ›çœ‹åˆ°æ¨ç†éç¨‹ | âœ… | âœ… | âŒ |
| å¤šæ­¥é©Ÿå•é¡Œ | âœ… | âœ… | ğŸ¤” |
| éœ€è¦é‡æ–°è¨ˆç•« | âŒ | âœ… | âŒ |
| ç°¡å–®æŸ¥è©¢ | âŒ | âŒ | âœ… |
| é€Ÿåº¦è‡³é—œé‡è¦ | âŒ | âŒ | âœ… |

---

## [FLOW] å¤šè¼ªå°è©± (Multi-Turn Conversations)

### Context Management (ä¸Šä¸‹æ–‡ç®¡ç†)

**å¿ƒæ™ºæ¨¡å‹**: åœ¨å¤šè¼ªå°è©±ä¸­ç¶­æŒå°è©±ç‹€æ…‹ï¼Œä»¥ç¢ºä¿é€£è²«æ€§ã€‚

```python
# ç‹€æ…‹æ„ŸçŸ¥ä»£ç†äºº
conversational_agent = Agent(
    name="assistant",
    model="gemini-2.5-flash",
    instruction="""
    ä½ æ˜¯ä¸€ä½æ¨‚æ–¼åŠ©äººçš„åŠ©ç†ã€‚å…ˆå‰çš„å°è©±ï¼š
    {conversation_history}

    ç›®å‰ä½¿ç”¨è€…ï¼š{user:name}
    ç›®å‰ä»»å‹™ï¼š{current_task}
    """,
    output_key="response"
)

# ç‹€æ…‹è¿½è¹¤å°è©±æµç¨‹
state['conversation_history'] += f"ä½¿ç”¨è€…: {user_input}\nåŠ©ç†: {response}\n"
state['current_task'] = extract_task(user_input)
```

### Tool Call Chains (å·¥å…·å‘¼å«éˆ)

**å¿ƒæ™ºæ¨¡å‹**: LLM å¯ä»¥åœ¨ä¸€å€‹å›åˆä¸­æŒ‰é †åºå‘¼å«å¤šå€‹å·¥å…·ä¾†å®Œæˆè¤‡é›œä»»å‹™ã€‚

```python
# å¤šå·¥å…·ä»£ç†äºº
research_agent = Agent(
    name="comprehensive_researcher",
    model="gemini-2.5-flash",
    tools=[web_search, database_query, analysis_tool],
    instruction="""
    ä½¿ç”¨æ‰€æœ‰å¯ç”¨å·¥å…·é€²è¡Œå¾¹åº•ç ”ç©¶ï¼š
    1. æœå°‹ç¶²è·¯ä»¥ç²å–ç•¶å‰è³‡è¨Š
    2. æŸ¥è©¢å…§éƒ¨è³‡æ–™åº«ä»¥ç²å–å…¬å¸æ•¸æ“š
    3. åˆ†æä¸¦ç¶œåˆç ”ç©¶çµæœ
    """
)

# LLM å¯ä»¥ç”Ÿæˆå¤šå€‹å·¥å…·å‘¼å«ï¼š
# 1. web_search("ä¸»é¡Œæ¦‚è¦½")
# 2. database_query("å…§éƒ¨æ•¸æ“š")
# 3. analysis_tool("åˆä½µçµæœ")
```

### Error Recovery (éŒ¯èª¤æ¢å¾©)

**å¿ƒæ™ºæ¨¡å‹**: å„ªé›…åœ°è™•ç†å¤±æ•—ä¸¦å¾ä¸­æ¢å¾©ï¼Œç¢ºä¿ç³»çµ±çš„ç©©å¥æ€§ã€‚

```python
# å…·æœ‰éŒ¯èª¤è™•ç†èƒ½åŠ›çš„ç©©å¥ä»£ç†äºº
robust_agent = Agent(
    name="reliable_assistant",
    model="gemini-2.5-flash",
    instruction="""
    å¦‚æœå·¥å…·å¤±æ•—ï¼Œå˜—è©¦æ›¿ä»£æ–¹æ³•ï¼š
    - å¦‚æœè³‡æ–™åº«æ•…éšœï¼Œå‰‡ä½¿ç”¨ç¶²è·¯æœå°‹
    - å¦‚æœè©³ç´°æ•¸æ“šä¸å¯ç”¨ï¼Œå‰‡é€²è¡Œç°¡åŒ–åˆ†æ
    - æ¸…æ™°åœ°è§£é‡‹é™åˆ¶

    å³ä½¿åªæœ‰éƒ¨åˆ†è³‡è¨Šï¼Œä¹Ÿè¦å§‹çµ‚æä¾›åƒ¹å€¼ã€‚
    """,
    tools=[primary_tool, fallback_tool] # æä¾›ä¸»è¦å’Œå‚™ç”¨å·¥å…·
)
```

---

## ğŸ¨ é€²éšæç¤ºæŠ€è¡“ (Advanced Prompting Techniques)

### Chain of Thought Prompting (æ€ç¶­éˆæç¤º)

**å¿ƒæ™ºæ¨¡å‹**: åœ¨æç¤ºä¸­æ˜ç¢ºæŒ‡ç¤ºï¼Œå¼•å°æ¨¡å‹é€²è¡Œé€æ­¥æ¨ç†ã€‚

```python
# æ˜ç¢ºçš„æ¨ç†æ­¥é©Ÿ
reasoning_instruction = """
è«‹æŒ‰æ­¥é©Ÿè§£æ±ºé€™å€‹å•é¡Œï¼š

1. ç†è§£å•é¡Œï¼šå•é¡Œè¦æ±‚çš„æ˜¯ä»€éº¼ï¼Ÿ
2. è­˜åˆ¥é—œéµè³‡è¨Šï¼šæˆ‘æœ‰å“ªäº›æ•¸æ“šï¼Ÿ
3. è€ƒæ…®æ–¹æ³•ï¼šå“ªäº›æ–¹æ³•å¯è¡Œï¼Ÿ
4. è©•ä¼°é¸é …ï¼šå“ªç¨®æ–¹æ³•æœ€å¥½ï¼Ÿ
5. åŸ·è¡Œè§£æ±ºæ–¹æ¡ˆï¼šå¯¦æ–½æ‰€é¸æ–¹æ³•
6. é©—è­‰çµæœï¼šé€™æ˜¯å¦åˆç†ï¼Ÿ

åœ¨æ¯ä¸€æ­¥éƒ½å±•ç¤ºä½ çš„å·¥ä½œã€‚
"""
```

### Few-Shot Learning (å°‘æ¨£æœ¬å­¸ç¿’)

**å¿ƒæ™ºæ¨¡å‹**: è®“æ¨¡å‹å¾æç¤ºä¸­æä¾›çš„å¹¾å€‹ç¯„ä¾‹ä¸­å­¸ç¿’ï¼Œä»¥æ‡‰å°æ–°ä»»å‹™ã€‚

```python
# åŸºæ–¼ç¯„ä¾‹çš„æŒ‡ä»¤
few_shot_instruction = """
å°‡æ–‡æœ¬çš„æƒ…æ„Ÿåˆ†é¡ç‚ºæ­£é¢ã€è² é¢æˆ–ä¸­æ€§ã€‚

ç¯„ä¾‹ï¼š
æ–‡æœ¬ï¼š"æˆ‘å–œæ­¡é€™å€‹ç”¢å“ï¼" â†’ æ­£é¢
æ–‡æœ¬ï¼š"é€™å“è³ªå¤ªå·®äº†" â†’ è² é¢
æ–‡æœ¬ï¼š"é‚„è¡Œï¼Œæ²’ä»€éº¼ç‰¹åˆ¥çš„" â†’ ä¸­æ€§

ç¾åœ¨åˆ†é¡ï¼š"{user_text}"
"""
```

### Meta-Prompting (å…ƒæç¤º)

**å¿ƒæ™ºæ¨¡å‹**: æç¤ºæ¨¡å‹å¦‚ä½•é€²è¡Œæç¤ºï¼Œè®“æ¨¡å‹å­¸æœƒè‡ªæˆ‘æ”¹é€²å’Œç­–ç•¥é¸æ“‡ã€‚

```python
# è‡ªæˆ‘æ”¹é€²çš„æç¤º
meta_instruction = """
é¦–å…ˆï¼Œåˆ†æé€™æ˜¯ä¸€å€‹ä»€éº¼é¡å‹çš„å•é¡Œï¼š
- äº‹å¯¦å‹ï¼šå°‹æ‰¾ç‰¹å®šè³‡è¨Š
- åˆ†æå‹ï¼šåˆ†è§£çµ„æˆéƒ¨åˆ†
- å‰µæ„å‹ï¼šç”¢ç”Ÿæ–°ç©çš„æƒ³æ³•
- å»ºè­°å‹ï¼šæä¾›å»ºè­°

ç„¶å¾Œï¼Œé¸æ“‡é©ç•¶çš„å›æ‡‰ç­–ç•¥ï¼š
- äº‹å¯¦å‹ï¼šå¼•ç”¨ä¾†æºï¼ŒåŠ›æ±‚ç²¾ç¢º
- åˆ†æå‹ï¼šç”¨ç« ç¯€çµæ§‹åŒ–
- å‰µæ„å‹ï¼šè…¦åŠ›æ¿€ç›ªå¤šå€‹é¸é …
- å»ºè­°å‹ï¼šè€ƒæ…®åˆ©å¼Šï¼Œæä¾›ç†ç”±

å•é¡Œï¼š{user_question}
"""
```

---

## ğŸš€ æ€§èƒ½å„ªåŒ– (Performance Optimization)

### Model Selection Strategy (æ¨¡å‹é¸æ“‡ç­–ç•¥)

**å¿ƒæ™ºæ¨¡å‹**: ç‚ºæ­£ç¢ºçš„ä»»å‹™é¸æ“‡æ­£ç¢ºçš„æ¨¡å‹ï¼Œä»¥å¹³è¡¡æˆæœ¬ã€é€Ÿåº¦å’Œæ€§èƒ½ã€‚

```python
# æ ¹æ“šè¤‡é›œåº¦é€²è¡Œæ¨¡å‹è·¯ç”±
def select_model(query):
    if len(query.split()) < 10: # ç°¡å–®æŸ¥è©¢
        return "gemini-2.5-flash" # å¿«é€Ÿã€ä¾¿å®œ
    elif "analyze" in query.lower(): # è¤‡é›œæŸ¥è©¢
        return "gemini-2.5-pro" # æ›´å¥½çš„æ¨ç†èƒ½åŠ›
    else:
        return "gemini-2.0-flash" # å¹³è¡¡å‹

# å‹•æ…‹æ¨¡å‹é¸æ“‡
agent = Agent(
    name="adaptive_assistant",
    model=select_model(user_query), # å‹•æ…‹é¸æ“‡
    instruction="ç‚ºæ­¤æŸ¥è©¢é¡å‹æä¾›æœ€ä½³å›æ‡‰"
)
```

### Context Window Management (ä¸Šä¸‹æ–‡è¦–çª—ç®¡ç†)

**å¿ƒæ™ºæ¨¡å‹**: åœ¨æœ‰é™çš„ä¸Šä¸‹æ–‡è¦–çª—ä¸­ï¼Œä¿ç•™ç›¸é—œè³‡è¨Šï¼Œä¸Ÿæ£„ä¸ç›¸é—œçš„è³‡è¨Šã€‚

```python
# ä¸Šä¸‹æ–‡ä¿®å‰ª
def prune_context(history, max_tokens=4000):
    """ä¿ç•™æœ€è¿‘å’Œç›¸é—œçš„è¨Šæ¯"""
    relevant = []
    total_tokens = 0

    for msg in reversed(history):
        if total_tokens + len(msg) > max_tokens:
            break
        if is_relevant(msg): # è‡ªè¨‚çš„ç›¸é—œæ€§åˆ¤æ–·å‡½å¼
            relevant.insert(0, msg)
            total_tokens += len(msg)

    return relevant

# é«˜æ•ˆçš„ä¸Šä¸‹æ–‡ä½¿ç”¨
agent = Agent(
    name="efficient_assistant",
    model="gemini-2.5-flash",
    instruction="é«˜æ•ˆåœ°ä½¿ç”¨ä¸Šä¸‹æ–‡ï¼š{pruned_history}"
)
```

### Caching Strategies (å¿«å–ç­–ç•¥)

**å¿ƒ-æ™ºæ¨¡å‹**: å°æ–¼å¸¸è¦‹çš„æŸ¥è©¢é‡ç”¨è¨ˆç®—çµæœï¼Œä»¥é™ä½å»¶é²å’Œæˆæœ¬ã€‚

```python
# å›æ‡‰å¿«å–
cache = {}

def get_cached_response(query):
    key = hash(query)
    if key in cache:
        return cache[key]

    response = agent.run(query)
    cache[key] = response
    return response

# èªç¾©å¿«å–
def semantic_cache(query):
    """åŸºæ–¼èªç¾©è€Œéç²¾ç¢ºæ–‡æœ¬é€²è¡Œå¿«å–"""
    intent = extract_intent(query)
    if intent in cache:
        return adapt_cached_response(cache[intent], query)
```

---

## ğŸ” èª¿è©¦ LLM æ•´åˆ (Debugging LLM Integration)

### Response Analysis (å›æ‡‰åˆ†æ)

**è¿½è¹¤ LLM è¡Œç‚º**: å•Ÿç”¨è©³ç´°æ—¥èªŒè¨˜éŒ„ä¾†æª¢æŸ¥æ¨¡å‹çš„è¼¸å…¥ã€è¼¸å‡ºå’Œæ±ºç­–éç¨‹ã€‚

```python
# å•Ÿç”¨è©³ç´°æ—¥èªŒè¨˜éŒ„
import logging
logging.getLogger('google.adk.models').setLevel(logging.DEBUG)

# æª¢æŸ¥ LLM å‘¼å«
result = await runner.run_async(query)
for event in result.events:
    if event.type == 'llm_request':
        print(f"æç¤º: {event.prompt}")
        print(f"æ¨¡å‹: {event.model}")
    elif event.type == 'llm_response':
        print(f"å›æ‡‰: {event.response}")
        print(f"Token æ•¸é‡: {event.token_count}")
```

### Prompt Iteration (æç¤ºè¿­ä»£)

**A/B æ¸¬è©¦æç¤º**: æ¯”è¼ƒä¸åŒæç¤ºç‰ˆæœ¬çš„æ€§èƒ½ï¼Œä»¥æ‰¾åˆ°æœ€ä½³æ–¹æ¡ˆã€‚

```python
# æ¸¬è©¦ä¸åŒç‰ˆæœ¬çš„æç¤º
prompts = {
    'concise': "ç°¡è¦å›ç­”ï¼š{query}",
    'detailed': "æä¾›å…¨é¢çš„å›ç­”ï¼š{query}",
    'structured': "ç”¨ç« ç¯€çµæ§‹åŒ–å›ç­”ï¼š{query}"
}

for version, prompt in prompts.items():
    agent = Agent(model="gemini-2.5-flash", instruction=prompt)
    result = agent.run(test_query)
    score = evaluate_response(result) # è©•ä¼°å›æ‡‰å“è³ªçš„å‡½å¼
    print(f"{version}: {score}")
```

### Common Issues & Solutions (å¸¸è¦‹å•é¡Œèˆ‡è§£æ±ºæ–¹æ¡ˆ)

| å•é¡Œ | ç—‡ç‹€ | è§£æ±ºæ–¹æ¡ˆ |
| :--- | :--- | :--- |
| å¹»è¦º (Hallucinations) | æé€ äº‹å¯¦ | æ·»åŠ æ¥åœ°å·¥å…·ã€äº‹å¯¦æŸ¥æ ¸ |
| å›æ‡‰å†—é•· | æ–‡å­—éå¤š | è¨­å®šé•·åº¦é™åˆ¶ã€çµæ§‹åŒ–æ ¼å¼ |
| é›¢é¡Œå›ç­” | å¿½ç•¥ç´„æŸ | æ¸…æ™°çš„æŒ‡ä»¤ã€è§’è‰²å®šç¾© |
| é¢¨æ ¼ä¸ä¸€è‡´ | å›æ‡‰é¢¨æ ¼å¤šè®Š | ä¸€è‡´çš„è§’è‰²è¨­å®šã€æä¾›ç¯„ä¾‹ |
| å·¥å…·èª¤ç”¨ | ç‚ºä»»å‹™é¸æ“‡éŒ¯èª¤å·¥å…· | æ›´å¥½çš„å·¥å…·æè¿°ã€æä¾›ç¯„ä¾‹ |
| ä¸Šä¸‹æ–‡ä¸Ÿå¤± | å¿˜è¨˜å°è©±å…§å®¹ | ç‹€æ…‹ç®¡ç†ã€ä¸Šä¸‹æ–‡æ³¨å…¥ |

---

**ğŸ”— ä¸‹ä¸€æ­¥**: å­¸ç¿’ [Production & Deployment (ç”Ÿç”¢èˆ‡éƒ¨ç½²)](/adk_training/docs/production-deployment) ä»¥å¤§è¦æ¨¡é‹è¡Œé€™äº›æ•´åˆã€‚
