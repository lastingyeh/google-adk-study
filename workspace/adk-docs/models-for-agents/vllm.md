# ç‚º ADK ä»£ç†ç¨‹å¼è¨—ç®¡ vLLM æ¨¡å‹

> ğŸ”” `æ›´æ–°æ—¥æœŸï¼š2026-01-23`
>
> ğŸ”— `è³‡æ–™ä¾†æº`ï¼šhttps://google.github.io/adk-docs/agents/models/vllm/

[`ADK æ”¯æ´`: `Python v0.1.0`]

[vLLM](https://github.com/vllm-project/vllm) ç­‰å·¥å…·å¯è®“æ‚¨é«˜æ•ˆåœ°è¨—ç®¡æ¨¡å‹ï¼Œä¸¦å°‡å…¶ä½œç‚ºèˆ‡ OpenAI ç›¸å®¹çš„ API ç«¯é»ã€‚æ‚¨å¯ä»¥é€é Python çš„ [LiteLLM](./litellm.md) å‡½å¼åº«ä½¿ç”¨ vLLM æ¨¡å‹ã€‚

## è¨­å®š

1. **éƒ¨ç½²æ¨¡å‹ï¼š** ä½¿ç”¨ vLLMï¼ˆæˆ–é¡ä¼¼å·¥å…·ï¼‰éƒ¨ç½²æ‚¨é¸æ“‡çš„æ¨¡å‹ã€‚è«‹è¨˜ä¸‹ API åŸºç¤ URLï¼ˆä¾‹å¦‚ï¼š`https://your-vllm-endpoint.run.app/v1`ï¼‰ã€‚
    * *å° ADK å·¥å…·çš„é‡è¦æ€§ï¼š* éƒ¨ç½²æ™‚ï¼Œè«‹ç¢ºä¿æœå‹™å·¥å…·æ”¯æ´ä¸¦å•Ÿç”¨èˆ‡ OpenAI ç›¸å®¹çš„å·¥å…·/å‡½å¼å‘¼å«ã€‚å°æ–¼ vLLMï¼Œé€™å¯èƒ½æ¶‰åŠ `--enable-auto-tool-choice` ç­‰æ¨™è¨˜ï¼Œä»¥åŠæ ¹æ“šæ¨¡å‹å¯èƒ½éœ€è¦çš„ç‰¹å®š `--tool-call-parser`ã€‚è«‹åƒé–± vLLM é—œæ–¼å·¥å…·ä½¿ç”¨çš„æ–‡ä»¶ã€‚
2. **èº«ä»½é©—è­‰ï¼š** ç¢ºå®šæ‚¨çš„ç«¯é»å¦‚ä½•è™•ç†èº«ä»½é©—è­‰ï¼ˆä¾‹å¦‚ï¼šAPI é‡‘é‘°ã€è¼‰é«”ä»¤ç‰Œ (bearer token)ï¼‰ã€‚

## æ•´åˆç¯„ä¾‹

ä»¥ä¸‹ç¯„ä¾‹å±•ç¤ºäº†å¦‚ä½•å°‡ vLLM ç«¯é»èˆ‡ ADK ä»£ç†ç¨‹å¼é…åˆä½¿ç”¨ã€‚

```python
import subprocess
from google.adk.agents import LlmAgent
from google.adk.models.lite_llm import LiteLlm

# --- ä½¿ç”¨è¨—ç®¡åœ¨ vLLM ç«¯é»ä¸Šçš„æ¨¡å‹çš„ä»£ç†ç¨‹å¼ç¯„ä¾‹ ---

# ç”±æ‚¨çš„ vLLM éƒ¨ç½²æä¾›çš„ç«¯é» URL
api_base_url = "https://your-vllm-endpoint.run.app/v1"

# æ‚¨çš„ vLLM ç«¯é»é…ç½®æ‰€è¾¨è­˜çš„æ¨¡å‹åç¨±
model_name_at_endpoint = "hosted_vllm/google/gemma-3-4b-it" # ä¾†è‡ª vllm_test.py çš„ç¯„ä¾‹

# èº«ä»½é©—è­‰ï¼ˆç¯„ä¾‹ï¼šé‡å° Cloud Run éƒ¨ç½²ä½¿ç”¨ gcloud èº«ä»½ä»¤ç‰Œï¼‰
# è«‹æ ¹æ“šæ‚¨çš„ç«¯é»å®‰å…¨æ€§é€²è¡Œèª¿æ•´
try:
    # å–å¾— gcloud èº«ä»½ä»¤ç‰Œ
    gcloud_token = subprocess.check_output(
        ["gcloud", "auth", "print-identity-token", "-q"]
    ).decode().strip()
    auth_headers = {"Authorization": f"Bearer {gcloud_token}"}
except Exception as e:
    # å¦‚æœç„¡æ³•å–å¾—æ¬Šé™ï¼Œè¼¸å‡ºè­¦å‘Š
    print(f"è­¦å‘Šï¼šç„¡æ³•å–å¾— gcloud ä»¤ç‰Œ - {e}ã€‚ç«¯é»å¯èƒ½æœªå—ä¿è­·æˆ–éœ€è¦ä¸åŒçš„é©—è­‰æ–¹å¼ã€‚")
    auth_headers = None # æˆ–é€²è¡Œé©ç•¶çš„éŒ¯èª¤è™•ç†

# åˆå§‹åŒ– LlmAgent
agent_vllm = LlmAgent(
    model=LiteLlm(
        model=model_name_at_endpoint,
        api_base=api_base_url,
        # å¦‚æœéœ€è¦ï¼Œå‚³éèº«ä»½é©—è­‰æ¨™é ­
        extra_headers=auth_headers
        # æˆ–è€…ï¼Œå¦‚æœç«¯é»ä½¿ç”¨ API é‡‘é‘°ï¼š
        # api_key="YOUR_ENDPOINT_API_KEY"
    ),
    name="vllm_agent",
    instruction="æ‚¨æ˜¯é‹è¡Œåœ¨è‡ªè¡Œè¨—ç®¡çš„ vLLM ç«¯é»ä¸Šçš„æ¨‚æ–¼åŠ©äººçš„åŠ©ç†ã€‚",
    # ... å…¶ä»–ä»£ç†ç¨‹å¼åƒæ•¸
)
```